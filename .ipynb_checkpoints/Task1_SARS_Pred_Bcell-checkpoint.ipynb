{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2T3T0</td>\n",
       "      <td>MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>SASFT</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0V2I4</td>\n",
       "      <td>MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>LCLKI</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75508</td>\n",
       "      <td>MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>AHRET</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O84462</td>\n",
       "      <td>MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>SNYDD</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00918</td>\n",
       "      <td>MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>DGTYR</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0            A2T3T0  MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...   \n",
       "1            F0V2I4  MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...   \n",
       "2            O75508  MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...   \n",
       "3            O84462  MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...   \n",
       "4            P00918  MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...   \n",
       "\n",
       "   start_position  end_position peptide_seq  chou_fasman  emini  \\\n",
       "0             161           165       SASFT        1.016  0.703   \n",
       "1             251           255       LCLKI        0.770  0.179   \n",
       "2             145           149       AHRET        0.852  3.427   \n",
       "3             152           156       SNYDD        1.410  2.548   \n",
       "4              85            89       DGTYR        1.214  1.908   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.018    2.22           5.810364     0.103275   \n",
       "1                1.199   -3.86           6.210876     0.065476   \n",
       "2                0.960    4.28           8.223938     0.091787   \n",
       "3                0.936    6.32           4.237976     0.044776   \n",
       "4                0.937    4.64           6.867493     0.103846   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.143829  40.273300       1  \n",
       "1       -0.036905  24.998512       1  \n",
       "2        0.879227  27.863333       1  \n",
       "3       -0.521393  30.765373       1  \n",
       "4       -0.578846  21.684615       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcell_df = pd.read_csv(os.path.join('data','input_bcell.csv'))\n",
    "bcell_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>MFIFLLFLTLTSGSDLD</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.159</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>MFIFLLFLTLTSGSD</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>FIFLLFLTL</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-7.467</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>LFLTLTSGSDLDRCT</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>TLTSGSDLDRCTTFDDV</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "1          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "2          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "3          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "4          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "\n",
       "   start_position  end_position        peptide_seq  chou_fasman  emini  \\\n",
       "0               1            17  MFIFLLFLTLTSGSDLD        0.887  0.040   \n",
       "1               1            15    MFIFLLFLTLTSGSD        0.869  0.047   \n",
       "2               2            10          FIFLLFLTL        0.621  0.042   \n",
       "3               6            20    LFLTLTSGSDLDRCT        1.021  0.230   \n",
       "4               9            25  TLTSGSDLDRCTTFDDV        1.089  0.627   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.056  -2.159           5.569763     0.116335   \n",
       "1                1.056  -2.500           5.569763     0.116335   \n",
       "2                1.148  -7.467           5.569763     0.116335   \n",
       "3                1.049   0.927           5.569763     0.116335   \n",
       "4                1.015   3.165           5.569763     0.116335   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.061116  33.205116       0  \n",
       "1       -0.061116  33.205116       0  \n",
       "2       -0.061116  33.205116       0  \n",
       "3       -0.061116  33.205116       0  \n",
       "4       -0.061116  33.205116       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars_df = pd.read_csv(os.path.join('data','input_sars.csv'))\n",
    "sars_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein feature Engineering and experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq_example = bcell_df.protein_seq.values.reshape(-1,1)[0]\n",
    "peptide_seq_example = bcell_df.peptide_seq.values.reshape(-1,1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEFQTGGIGNLPIRNWNFNFGLLGTTLLNLDANYVETARNTIDYFVDFVDNVCMDEMVRESQRNGIAPQSDSLRKLSAIKFKRINFDNSSEYIENWNLQNRRQRTGFTFHKPNIFPYSASFTLNRSQPAHDNLMGTMWLNAGSEIQVAGFDYSCAINAPANIQQFEHIVPLRRVLTTATITLLPDAERFSFPRVINSADGATTWFFNPVILRPNNVEVEFLLNGQIINTYQARFGTIVARNFDTIRLSFQLMRPPNMTPAVAVLFPNAQPFEHHATVGLTLRIESAVCESVLADASETLLANVTSVRQEYAIPVGPVFPPGMNWTDLITNYSPSREDNLQRVFTVASIRSMLIK'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SASFT'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_seq_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biophysical quantitative properties that are also Features that need to be made from protein and peptides\n",
    "* mass\n",
    "* length\n",
    "The rest have been provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dictionary of protein mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_dict = {'A':89, 'R':174, 'N':132, 'D':133,\n",
    "                'B':133, 'C':121, 'Q':146, 'E':147,\n",
    "                'Z':147, 'G':75, 'H':155, 'I':131,\n",
    "                'L':131, 'K':146, 'M':149, 'F':165,\n",
    "                'P':115, 'S':105, 'T':119, 'W':204,\n",
    "                'Y':181, 'V':117}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass maker function\n",
    "def mass_list_maker(df_and_column):\n",
    "    mass_lst = []\n",
    "    for i in df_and_column:\n",
    "        mass = 0\n",
    "        for j in i:\n",
    "            mass = mass + protein_dict[j]\n",
    "        mass_lst.append(mass)\n",
    "    return mass_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_list_maker(df_and_column):\n",
    "    return [len(i) for i in df_and_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass of protien Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51950, 42734, 25675, 120095, 33875, 33875, 33875, 33875, 33875, 49762]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_mass_lst = mass_list_maker(bcell_df.protein_seq)\n",
    "protein_mass_lst[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of protein testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[397, 336, 207, 1005, 260, 260, 260, 260, 260, 386]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_length_lst=[len(i) for i in bcell_df.protein_seq]\n",
    "protein_length_lst[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass of Peptide Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_length_lst=[len(i) for i in bcell_df.peptide_seq]\n",
    "peptide_length_lst[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length of Peptide testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[583, 660, 684, 684, 682, 615, 588, 686, 620, 721]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_mass_lst = mass_list_maker(bcell_df.peptide_seq)\n",
    "peptide_mass_lst[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features in the sars and bcell dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>MFIFLLFLTLTSGSDLD</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.159</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>MFIFLLFLTLTSGSD</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>FIFLLFLTL</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-7.467</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>LFLTLTSGSDLDRCT</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>TLTSGSDLDRCTTFDDV</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "1          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "2          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "3          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "4          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "\n",
       "   start_position  end_position        peptide_seq  chou_fasman  emini  \\\n",
       "0               1            17  MFIFLLFLTLTSGSDLD        0.887  0.040   \n",
       "1               1            15    MFIFLLFLTLTSGSD        0.869  0.047   \n",
       "2               2            10          FIFLLFLTL        0.621  0.042   \n",
       "3               6            20    LFLTLTSGSDLDRCT        1.021  0.230   \n",
       "4               9            25  TLTSGSDLDRCTTFDDV        1.089  0.627   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.056  -2.159           5.569763     0.116335   \n",
       "1                1.056  -2.500           5.569763     0.116335   \n",
       "2                1.148  -7.467           5.569763     0.116335   \n",
       "3                1.049   0.927           5.569763     0.116335   \n",
       "4                1.015   3.165           5.569763     0.116335   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.061116  33.205116       0  \n",
       "1       -0.061116  33.205116       0  \n",
       "2       -0.061116  33.205116       0  \n",
       "3       -0.061116  33.205116       0  \n",
       "4       -0.061116  33.205116       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars_df.head() # This is the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "      <th>protein_seq_mass</th>\n",
       "      <th>protein_seq_length</th>\n",
       "      <th>peptide_seq_mass</th>\n",
       "      <th>peptide_seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>MFIFLLFLTLTSGSDLD</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.159</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>2219</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>MFIFLLFLTLTSGSD</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>1955</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>FIFLLFLTL</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-7.467</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>1269</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>LFLTLTSGSDLDRCT</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>1892</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>TLTSGSDLDRCTTFDDV</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>2132</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "1          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "2          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "3          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "4          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "\n",
       "   start_position  end_position        peptide_seq  chou_fasman  emini  \\\n",
       "0               1            17  MFIFLLFLTLTSGSDLD        0.887  0.040   \n",
       "1               1            15    MFIFLLFLTLTSGSD        0.869  0.047   \n",
       "2               2            10          FIFLLFLTL        0.621  0.042   \n",
       "3               6            20    LFLTLTSGSDLDRCT        1.021  0.230   \n",
       "4               9            25  TLTSGSDLDRCTTFDDV        1.089  0.627   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.056  -2.159           5.569763     0.116335   \n",
       "1                1.056  -2.500           5.569763     0.116335   \n",
       "2                1.148  -7.467           5.569763     0.116335   \n",
       "3                1.049   0.927           5.569763     0.116335   \n",
       "4                1.015   3.165           5.569763     0.116335   \n",
       "\n",
       "   hydrophobicity  stability  target  protein_seq_mass  protein_seq_length  \\\n",
       "0       -0.061116  33.205116       0            161643                1255   \n",
       "1       -0.061116  33.205116       0            161643                1255   \n",
       "2       -0.061116  33.205116       0            161643                1255   \n",
       "3       -0.061116  33.205116       0            161643                1255   \n",
       "4       -0.061116  33.205116       0            161643                1255   \n",
       "\n",
       "   peptide_seq_mass  peptide_seq_length  \n",
       "0              2219                  17  \n",
       "1              1955                  15  \n",
       "2              1269                   9  \n",
       "3              1892                  15  \n",
       "4              2132                  17  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars_df['protein_seq_mass'] = mass_list_maker(sars_df.protein_seq)\n",
    "sars_df['protein_seq_length'] = len_list_maker(sars_df.protein_seq)\n",
    "\n",
    "sars_df['peptide_seq_mass'] = mass_list_maker(sars_df.peptide_seq)\n",
    "sars_df['peptide_seq_length'] = len_list_maker(sars_df.peptide_seq)\n",
    "\n",
    "sars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2T3T0</td>\n",
       "      <td>MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>SASFT</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0V2I4</td>\n",
       "      <td>MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>LCLKI</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75508</td>\n",
       "      <td>MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>AHRET</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O84462</td>\n",
       "      <td>MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>SNYDD</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00918</td>\n",
       "      <td>MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>DGTYR</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0            A2T3T0  MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...   \n",
       "1            F0V2I4  MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...   \n",
       "2            O75508  MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...   \n",
       "3            O84462  MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...   \n",
       "4            P00918  MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...   \n",
       "\n",
       "   start_position  end_position peptide_seq  chou_fasman  emini  \\\n",
       "0             161           165       SASFT        1.016  0.703   \n",
       "1             251           255       LCLKI        0.770  0.179   \n",
       "2             145           149       AHRET        0.852  3.427   \n",
       "3             152           156       SNYDD        1.410  2.548   \n",
       "4              85            89       DGTYR        1.214  1.908   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.018    2.22           5.810364     0.103275   \n",
       "1                1.199   -3.86           6.210876     0.065476   \n",
       "2                0.960    4.28           8.223938     0.091787   \n",
       "3                0.936    6.32           4.237976     0.044776   \n",
       "4                0.937    4.64           6.867493     0.103846   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.143829  40.273300       1  \n",
       "1       -0.036905  24.998512       1  \n",
       "2        0.879227  27.863333       1  \n",
       "3       -0.521393  30.765373       1  \n",
       "4       -0.578846  21.684615       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcell_df.head() # This is the training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "      <th>protein_seq_mass</th>\n",
       "      <th>protein_seq_length</th>\n",
       "      <th>peptide_seq_mass</th>\n",
       "      <th>peptide_seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2T3T0</td>\n",
       "      <td>MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>SASFT</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "      <td>1</td>\n",
       "      <td>51950</td>\n",
       "      <td>397</td>\n",
       "      <td>583</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0V2I4</td>\n",
       "      <td>MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>LCLKI</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "      <td>1</td>\n",
       "      <td>42734</td>\n",
       "      <td>336</td>\n",
       "      <td>660</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75508</td>\n",
       "      <td>MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>AHRET</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>1</td>\n",
       "      <td>25675</td>\n",
       "      <td>207</td>\n",
       "      <td>684</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O84462</td>\n",
       "      <td>MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>SNYDD</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "      <td>1</td>\n",
       "      <td>120095</td>\n",
       "      <td>1005</td>\n",
       "      <td>684</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00918</td>\n",
       "      <td>MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>DGTYR</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "      <td>1</td>\n",
       "      <td>33875</td>\n",
       "      <td>260</td>\n",
       "      <td>682</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0            A2T3T0  MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...   \n",
       "1            F0V2I4  MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...   \n",
       "2            O75508  MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...   \n",
       "3            O84462  MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...   \n",
       "4            P00918  MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...   \n",
       "\n",
       "   start_position  end_position peptide_seq  chou_fasman  emini  \\\n",
       "0             161           165       SASFT        1.016  0.703   \n",
       "1             251           255       LCLKI        0.770  0.179   \n",
       "2             145           149       AHRET        0.852  3.427   \n",
       "3             152           156       SNYDD        1.410  2.548   \n",
       "4              85            89       DGTYR        1.214  1.908   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.018    2.22           5.810364     0.103275   \n",
       "1                1.199   -3.86           6.210876     0.065476   \n",
       "2                0.960    4.28           8.223938     0.091787   \n",
       "3                0.936    6.32           4.237976     0.044776   \n",
       "4                0.937    4.64           6.867493     0.103846   \n",
       "\n",
       "   hydrophobicity  stability  target  protein_seq_mass  protein_seq_length  \\\n",
       "0       -0.143829  40.273300       1             51950                 397   \n",
       "1       -0.036905  24.998512       1             42734                 336   \n",
       "2        0.879227  27.863333       1             25675                 207   \n",
       "3       -0.521393  30.765373       1            120095                1005   \n",
       "4       -0.578846  21.684615       1             33875                 260   \n",
       "\n",
       "   peptide_seq_mass  peptide_seq_length  \n",
       "0               583                   5  \n",
       "1               660                   5  \n",
       "2               684                   5  \n",
       "3               684                   5  \n",
       "4               682                   5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcell_df['protein_seq_mass'] = mass_list_maker(bcell_df.protein_seq)\n",
    "bcell_df['protein_seq_length'] = len_list_maker(bcell_df.protein_seq)\n",
    "\n",
    "bcell_df['peptide_seq_mass'] = mass_list_maker(bcell_df.peptide_seq)\n",
    "bcell_df['peptide_seq_length'] = len_list_maker(bcell_df.peptide_seq)\n",
    "\n",
    "bcell_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the training, validation, and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       start_position  end_position  chou_fasman  emini  kolaskar_tongaonkar  \\\n",
       " 0                 161           165        1.016  0.703                1.018   \n",
       " 1                 251           255        0.770  0.179                1.199   \n",
       " 2                 145           149        0.852  3.427                0.960   \n",
       " 3                 152           156        1.410  2.548                0.936   \n",
       " 4                  85            89        1.214  1.908                0.937   \n",
       " ...               ...           ...          ...    ...                  ...   \n",
       " 14382             177           191        0.910  0.175                1.054   \n",
       " 14383             285           299        0.966  0.216                1.044   \n",
       " 14384             189           203        0.821  0.023                1.044   \n",
       " 14385            1479          1493        1.069  0.239                1.037   \n",
       " 14386            1647          1661        0.962  0.257                1.045   \n",
       " \n",
       "        parker  isoelectric_point  aromaticity  hydrophobicity  stability  \\\n",
       " 0       2.220           5.810364     0.103275       -0.143829  40.273300   \n",
       " 1      -3.860           6.210876     0.065476       -0.036905  24.998512   \n",
       " 2       4.280           8.223938     0.091787        0.879227  27.863333   \n",
       " 3       6.320           4.237976     0.044776       -0.521393  30.765373   \n",
       " 4       4.640           6.867493     0.103846       -0.578846  21.684615   \n",
       " ...       ...                ...          ...             ...        ...   \n",
       " 14382   0.820           4.894836     0.071719       -0.701083  46.875237   \n",
       " 14383   1.160           4.894836     0.071719       -0.701083  46.875237   \n",
       " 14384  -1.360           4.894836     0.071719       -0.701083  46.875237   \n",
       " 14385   2.180           9.553040     0.044338       -0.671001  29.494308   \n",
       " 14386   2.127           9.553040     0.044338       -0.671001  29.494308   \n",
       " \n",
       "        protein_seq_mass  protein_seq_length  peptide_seq_mass  \\\n",
       " 0                 51950                 397               583   \n",
       " 1                 42734                 336               660   \n",
       " 2                 25675                 207               684   \n",
       " 3                120095                1005               684   \n",
       " 4                 33875                 260               682   \n",
       " ...                 ...                 ...               ...   \n",
       " 14382             96654                 739              1991   \n",
       " 14383             96654                 739              1897   \n",
       " 14384             96654                 739              2026   \n",
       " 14385            191567                1669              1806   \n",
       " 14386            191567                1669              1870   \n",
       " \n",
       "        peptide_seq_length  \n",
       " 0                       5  \n",
       " 1                       5  \n",
       " 2                       5  \n",
       " 3                       5  \n",
       " 4                       5  \n",
       " ...                   ...  \n",
       " 14382                  15  \n",
       " 14383                  15  \n",
       " 14384                  15  \n",
       " 14385                  15  \n",
       " 14386                  15  \n",
       " \n",
       " [14387 rows x 14 columns],\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = bcell_df.drop(['parent_protein_id','protein_seq','peptide_seq','target'], axis=1), bcell_df.target.values.reshape(-1,1)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = sars_df.drop(['parent_protein_id','protein_seq','peptide_seq','target'], axis=1), sars_df.target.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Min, max\"-ing and Categorising the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_val_scaled = X_scaler.transform(X_val)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_val_categorical = to_categorical(y_val)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the nerual network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1048)              537624    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2048)              2148352   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8192)              33562624  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 57,420,634\n",
      "Trainable params: 57,420,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/250\n",
      " 1/90 [..............................] - ETA: 0s - loss: 0.6899 - accuracy: 0.7812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.0279s). Check your callbacks.\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5917 - accuracy: 0.7265 - val_loss: 0.5347 - val_accuracy: 0.7345\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.5359 - accuracy: 0.7304 - val_loss: 0.5175 - val_accuracy: 0.7627\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4869 - accuracy: 0.7637 - val_loss: 0.4608 - val_accuracy: 0.7794\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4345 - accuracy: 0.7948 - val_loss: 0.4372 - val_accuracy: 0.8033\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4001 - accuracy: 0.8208 - val_loss: 0.4197 - val_accuracy: 0.8079\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3754 - accuracy: 0.8254 - val_loss: 0.4198 - val_accuracy: 0.8033\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3500 - accuracy: 0.8414 - val_loss: 0.3775 - val_accuracy: 0.8301\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.3312 - accuracy: 0.8505 - val_loss: 0.3885 - val_accuracy: 0.8186\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.3271 - accuracy: 0.8565 - val_loss: 0.4038 - val_accuracy: 0.8151\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.3112 - accuracy: 0.8581 - val_loss: 0.3803 - val_accuracy: 0.8325\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2902 - accuracy: 0.8679 - val_loss: 0.3857 - val_accuracy: 0.8204\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2811 - accuracy: 0.8770 - val_loss: 0.3808 - val_accuracy: 0.8308\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2669 - accuracy: 0.8803 - val_loss: 0.3847 - val_accuracy: 0.8301\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2581 - accuracy: 0.8868 - val_loss: 0.3979 - val_accuracy: 0.8343\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2523 - accuracy: 0.8902 - val_loss: 0.4180 - val_accuracy: 0.8204\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2360 - accuracy: 0.8949 - val_loss: 0.4049 - val_accuracy: 0.8218\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2336 - accuracy: 0.8948 - val_loss: 0.4755 - val_accuracy: 0.8092\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2330 - accuracy: 0.8955 - val_loss: 0.4698 - val_accuracy: 0.8287\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2181 - accuracy: 0.9046 - val_loss: 0.4464 - val_accuracy: 0.8325\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2104 - accuracy: 0.9076 - val_loss: 0.4541 - val_accuracy: 0.8343\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2140 - accuracy: 0.9059 - val_loss: 0.4890 - val_accuracy: 0.8356\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2083 - accuracy: 0.9097 - val_loss: 0.4686 - val_accuracy: 0.8207\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2080 - accuracy: 0.9095 - val_loss: 0.4242 - val_accuracy: 0.8211\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2075 - accuracy: 0.9089 - val_loss: 0.4700 - val_accuracy: 0.8360\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1833 - accuracy: 0.9193 - val_loss: 0.4736 - val_accuracy: 0.8287\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1771 - accuracy: 0.9219 - val_loss: 0.4817 - val_accuracy: 0.8252\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1715 - accuracy: 0.9248 - val_loss: 0.5123 - val_accuracy: 0.8315\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1695 - accuracy: 0.9233 - val_loss: 0.5905 - val_accuracy: 0.8284\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1687 - accuracy: 0.9291 - val_loss: 0.5038 - val_accuracy: 0.8235\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1803 - accuracy: 0.9234 - val_loss: 0.4963 - val_accuracy: 0.8343\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1738 - accuracy: 0.9273 - val_loss: 0.5941 - val_accuracy: 0.8405\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1669 - accuracy: 0.9304 - val_loss: 0.5350 - val_accuracy: 0.8322\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1648 - accuracy: 0.9297 - val_loss: 0.7091 - val_accuracy: 0.8238\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1679 - accuracy: 0.9282 - val_loss: 0.5257 - val_accuracy: 0.8322\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1535 - accuracy: 0.9337 - val_loss: 0.7024 - val_accuracy: 0.8294\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1544 - accuracy: 0.9332 - val_loss: 0.4924 - val_accuracy: 0.8263\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1424 - accuracy: 0.9400 - val_loss: 0.5329 - val_accuracy: 0.8325\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1400 - accuracy: 0.9417 - val_loss: 0.5531 - val_accuracy: 0.8315\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1308 - accuracy: 0.9456 - val_loss: 0.6044 - val_accuracy: 0.8346\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1258 - accuracy: 0.9459 - val_loss: 0.6007 - val_accuracy: 0.8332\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1129 - accuracy: 0.9491 - val_loss: 0.8186 - val_accuracy: 0.8332\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1174 - accuracy: 0.9500 - val_loss: 0.6903 - val_accuracy: 0.8290\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1268 - accuracy: 0.9460 - val_loss: 0.5809 - val_accuracy: 0.8304\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1189 - accuracy: 0.9493 - val_loss: 0.6167 - val_accuracy: 0.8273\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1177 - accuracy: 0.9487 - val_loss: 0.5943 - val_accuracy: 0.8231\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1320 - accuracy: 0.9436 - val_loss: 0.6557 - val_accuracy: 0.8336\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1108 - accuracy: 0.9527 - val_loss: 0.6147 - val_accuracy: 0.8273\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1083 - accuracy: 0.9522 - val_loss: 0.7484 - val_accuracy: 0.8325\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1150 - accuracy: 0.9524 - val_loss: 0.7061 - val_accuracy: 0.8308\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1087 - accuracy: 0.9531 - val_loss: 0.6021 - val_accuracy: 0.8207\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1130 - accuracy: 0.9519 - val_loss: 0.8743 - val_accuracy: 0.8263\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0994 - accuracy: 0.9571 - val_loss: 0.9530 - val_accuracy: 0.8336\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0938 - accuracy: 0.9601 - val_loss: 0.7835 - val_accuracy: 0.8284\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0894 - accuracy: 0.9618 - val_loss: 0.8749 - val_accuracy: 0.8336\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1005 - accuracy: 0.9582 - val_loss: 0.7201 - val_accuracy: 0.8263\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1043 - accuracy: 0.9553 - val_loss: 0.8515 - val_accuracy: 0.8290\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0985 - accuracy: 0.9571 - val_loss: 0.8679 - val_accuracy: 0.8297\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0944 - accuracy: 0.9607 - val_loss: 0.6757 - val_accuracy: 0.8204\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1017 - accuracy: 0.9596 - val_loss: 0.6742 - val_accuracy: 0.8277\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0973 - accuracy: 0.9601 - val_loss: 0.8713 - val_accuracy: 0.8287\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0833 - accuracy: 0.9659 - val_loss: 0.9200 - val_accuracy: 0.8284\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0819 - accuracy: 0.9652 - val_loss: 0.7410 - val_accuracy: 0.8301\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0771 - accuracy: 0.9674 - val_loss: 1.0581 - val_accuracy: 0.8270\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0827 - accuracy: 0.9662 - val_loss: 0.6244 - val_accuracy: 0.8235\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0924 - accuracy: 0.9627 - val_loss: 0.6383 - val_accuracy: 0.8256\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0833 - accuracy: 0.9657 - val_loss: 0.8764 - val_accuracy: 0.8280\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0897 - accuracy: 0.9641 - val_loss: 0.6704 - val_accuracy: 0.8172\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0930 - accuracy: 0.9632 - val_loss: 0.8034 - val_accuracy: 0.8256\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0770 - accuracy: 0.9675 - val_loss: 0.8229 - val_accuracy: 0.8249\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0710 - accuracy: 0.9713 - val_loss: 1.1590 - val_accuracy: 0.8273\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0826 - accuracy: 0.9670 - val_loss: 0.7117 - val_accuracy: 0.8211\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0777 - accuracy: 0.9671 - val_loss: 0.9281 - val_accuracy: 0.8197\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0837 - accuracy: 0.9656 - val_loss: 0.7625 - val_accuracy: 0.8280\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0719 - accuracy: 0.9706 - val_loss: 0.7901 - val_accuracy: 0.8259\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0663 - accuracy: 0.9731 - val_loss: 1.0126 - val_accuracy: 0.8339\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0879 - accuracy: 0.9654 - val_loss: 0.7012 - val_accuracy: 0.8218\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0795 - accuracy: 0.9676 - val_loss: 0.7944 - val_accuracy: 0.8343\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0697 - accuracy: 0.9700 - val_loss: 1.0818 - val_accuracy: 0.8238\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0645 - accuracy: 0.9735 - val_loss: 0.8148 - val_accuracy: 0.8263\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0773 - accuracy: 0.9700 - val_loss: 0.8816 - val_accuracy: 0.8270\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0705 - accuracy: 0.9698 - val_loss: 0.8137 - val_accuracy: 0.8315\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0612 - accuracy: 0.9745 - val_loss: 0.8576 - val_accuracy: 0.8273\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0635 - accuracy: 0.9739 - val_loss: 1.0109 - val_accuracy: 0.8245\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0635 - accuracy: 0.9736 - val_loss: 0.7402 - val_accuracy: 0.8252\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0704 - accuracy: 0.9725 - val_loss: 0.6900 - val_accuracy: 0.8218\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0713 - accuracy: 0.9719 - val_loss: 0.9947 - val_accuracy: 0.8284\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0701 - accuracy: 0.9712 - val_loss: 0.8327 - val_accuracy: 0.8315\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0637 - accuracy: 0.9759 - val_loss: 1.0192 - val_accuracy: 0.8221\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0748 - accuracy: 0.9703 - val_loss: 0.7340 - val_accuracy: 0.8235\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0694 - accuracy: 0.9732 - val_loss: 0.8451 - val_accuracy: 0.8197\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0638 - accuracy: 0.9747 - val_loss: 0.9818 - val_accuracy: 0.8245\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0649 - accuracy: 0.9738 - val_loss: 0.8637 - val_accuracy: 0.8252\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0550 - accuracy: 0.9775 - val_loss: 0.9514 - val_accuracy: 0.8197\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0598 - accuracy: 0.9771 - val_loss: 1.1025 - val_accuracy: 0.8169\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0796 - accuracy: 0.9699 - val_loss: 0.7736 - val_accuracy: 0.8235\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0578 - accuracy: 0.9777 - val_loss: 0.8695 - val_accuracy: 0.8151\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0669 - accuracy: 0.9736 - val_loss: 0.8126 - val_accuracy: 0.8207\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0608 - accuracy: 0.9758 - val_loss: 1.0416 - val_accuracy: 0.8280\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0571 - accuracy: 0.9782 - val_loss: 0.7076 - val_accuracy: 0.8242\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0729 - accuracy: 0.9718 - val_loss: 0.9517 - val_accuracy: 0.8280\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0823 - accuracy: 0.9680 - val_loss: 0.8317 - val_accuracy: 0.8190\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0656 - accuracy: 0.9723 - val_loss: 1.1520 - val_accuracy: 0.8304\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0523 - accuracy: 0.9802 - val_loss: 1.3606 - val_accuracy: 0.8228\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0423 - accuracy: 0.9820 - val_loss: 1.1468 - val_accuracy: 0.8277\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0520 - accuracy: 0.9816 - val_loss: 0.8105 - val_accuracy: 0.8245\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0435 - accuracy: 0.9827 - val_loss: 0.9198 - val_accuracy: 0.8245\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0458 - accuracy: 0.9815 - val_loss: 1.0521 - val_accuracy: 0.8256\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0462 - accuracy: 0.9818 - val_loss: 1.0610 - val_accuracy: 0.8214\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0543 - accuracy: 0.9806 - val_loss: 1.2973 - val_accuracy: 0.8290\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0532 - accuracy: 0.9803 - val_loss: 0.8757 - val_accuracy: 0.8214\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0558 - accuracy: 0.9787 - val_loss: 0.9025 - val_accuracy: 0.8200\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0542 - accuracy: 0.9815 - val_loss: 0.6272 - val_accuracy: 0.8259\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0508 - accuracy: 0.9822 - val_loss: 0.9156 - val_accuracy: 0.8284\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.0495 - accuracy: 0.9819 - val_loss: 1.0099 - val_accuracy: 0.8297\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0472 - accuracy: 0.9818 - val_loss: 1.0367 - val_accuracy: 0.8308\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.0493 - accuracy: 0.9803 - val_loss: 1.1296 - val_accuracy: 0.8242\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0619 - accuracy: 0.9765 - val_loss: 0.8183 - val_accuracy: 0.8204\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0544 - accuracy: 0.9780 - val_loss: 0.7753 - val_accuracy: 0.8266\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0644 - accuracy: 0.9732 - val_loss: 0.9249 - val_accuracy: 0.8277\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 0.9232 - val_accuracy: 0.8266\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0554 - accuracy: 0.9803 - val_loss: 0.9765 - val_accuracy: 0.8263\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0530 - accuracy: 0.9801 - val_loss: 0.8145 - val_accuracy: 0.8221\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0535 - accuracy: 0.9793 - val_loss: 0.8123 - val_accuracy: 0.8221\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.0525 - accuracy: 0.9807 - val_loss: 0.8635 - val_accuracy: 0.8308\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.0434 - accuracy: 0.9849 - val_loss: 0.8888 - val_accuracy: 0.8263\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0523 - accuracy: 0.9805 - val_loss: 1.0762 - val_accuracy: 0.8263\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.0621 - accuracy: 0.9791 - val_loss: 1.3122 - val_accuracy: 0.8235\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.0645 - accuracy: 0.9785 - val_loss: 0.6147 - val_accuracy: 0.8186\n",
      "Epoch 129/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0599 - accuracy: 0.9784 - val_loss: 0.8354 - val_accuracy: 0.8259\n",
      "Epoch 130/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0514 - accuracy: 0.9820 - val_loss: 0.8082 - val_accuracy: 0.8284\n",
      "Epoch 131/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0418 - accuracy: 0.9837 - val_loss: 1.1523 - val_accuracy: 0.8284\n",
      "Epoch 132/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0549 - accuracy: 0.9784 - val_loss: 0.8169 - val_accuracy: 0.8249\n",
      "Epoch 133/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0515 - accuracy: 0.9821 - val_loss: 1.1188 - val_accuracy: 0.8228\n",
      "Epoch 134/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0395 - accuracy: 0.9858 - val_loss: 1.4446 - val_accuracy: 0.8224\n",
      "Epoch 135/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0343 - accuracy: 0.9874 - val_loss: 1.0002 - val_accuracy: 0.8266\n",
      "Epoch 136/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0361 - accuracy: 0.9870 - val_loss: 1.0667 - val_accuracy: 0.8214\n",
      "Epoch 137/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0458 - accuracy: 0.9842 - val_loss: 0.9565 - val_accuracy: 0.8214\n",
      "Epoch 138/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0368 - accuracy: 0.9863 - val_loss: 0.9077 - val_accuracy: 0.8245\n",
      "Epoch 139/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0402 - accuracy: 0.9848 - val_loss: 1.0383 - val_accuracy: 0.8263\n",
      "Epoch 140/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0475 - accuracy: 0.9825 - val_loss: 0.8196 - val_accuracy: 0.8259\n",
      "Epoch 141/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0551 - accuracy: 0.9797 - val_loss: 1.0849 - val_accuracy: 0.8301\n",
      "Epoch 142/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0440 - accuracy: 0.9835 - val_loss: 0.8280 - val_accuracy: 0.8249\n",
      "Epoch 143/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 1.1636 - val_accuracy: 0.8252\n",
      "Epoch 144/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0301 - accuracy: 0.9886 - val_loss: 1.0908 - val_accuracy: 0.8280\n",
      "Epoch 145/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0356 - accuracy: 0.9871 - val_loss: 1.0498 - val_accuracy: 0.8228\n",
      "Epoch 146/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0288 - accuracy: 0.9891 - val_loss: 1.5294 - val_accuracy: 0.8190\n",
      "Epoch 147/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 1.1446 - val_accuracy: 0.8228\n",
      "Epoch 148/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0666 - accuracy: 0.9798 - val_loss: 0.6581 - val_accuracy: 0.8207\n",
      "Epoch 149/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0579 - accuracy: 0.9793 - val_loss: 1.0469 - val_accuracy: 0.8197\n",
      "Epoch 150/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0646 - accuracy: 0.9778 - val_loss: 0.8991 - val_accuracy: 0.8252\n",
      "Epoch 151/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0503 - accuracy: 0.9819 - val_loss: 0.8699 - val_accuracy: 0.8179\n",
      "Epoch 152/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0527 - accuracy: 0.9814 - val_loss: 0.9928 - val_accuracy: 0.8183\n",
      "Epoch 153/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0454 - accuracy: 0.9840 - val_loss: 0.8069 - val_accuracy: 0.8211\n",
      "Epoch 154/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.9140 - val_accuracy: 0.8204\n",
      "Epoch 155/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0283 - accuracy: 0.9891 - val_loss: 1.2097 - val_accuracy: 0.8228\n",
      "Epoch 156/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0318 - accuracy: 0.9883 - val_loss: 0.9884 - val_accuracy: 0.8165\n",
      "Epoch 157/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0307 - accuracy: 0.9886 - val_loss: 2.3487 - val_accuracy: 0.8200\n",
      "Epoch 158/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0697 - accuracy: 0.9774 - val_loss: 0.7902 - val_accuracy: 0.8172\n",
      "Epoch 159/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.9039 - val_accuracy: 0.8256\n",
      "Epoch 160/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0379 - accuracy: 0.9867 - val_loss: 0.9229 - val_accuracy: 0.8235\n",
      "Epoch 161/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0342 - accuracy: 0.9871 - val_loss: 0.8916 - val_accuracy: 0.8245\n",
      "Epoch 162/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0366 - accuracy: 0.9870 - val_loss: 0.9985 - val_accuracy: 0.8252\n",
      "Epoch 163/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0466 - accuracy: 0.9847 - val_loss: 1.2344 - val_accuracy: 0.8252\n",
      "Epoch 164/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0575 - accuracy: 0.9785 - val_loss: 0.9253 - val_accuracy: 0.8193\n",
      "Epoch 165/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.7876 - val_accuracy: 0.8297\n",
      "Epoch 166/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0413 - accuracy: 0.9864 - val_loss: 1.5547 - val_accuracy: 0.8329\n",
      "Epoch 167/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 1.1236 - val_accuracy: 0.8256\n",
      "Epoch 168/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 1.0959 - val_accuracy: 0.8263\n",
      "Epoch 169/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0932 - accuracy: 0.9713 - val_loss: 0.6111 - val_accuracy: 0.8266\n",
      "Epoch 170/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0671 - accuracy: 0.9759 - val_loss: 0.8450 - val_accuracy: 0.8301\n",
      "Epoch 171/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0529 - accuracy: 0.9818 - val_loss: 0.8118 - val_accuracy: 0.8193\n",
      "Epoch 172/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0461 - accuracy: 0.9824 - val_loss: 0.8616 - val_accuracy: 0.8318\n",
      "Epoch 173/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0389 - accuracy: 0.9862 - val_loss: 0.8219 - val_accuracy: 0.8287\n",
      "Epoch 174/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0425 - accuracy: 0.9844 - val_loss: 0.9305 - val_accuracy: 0.8245\n",
      "Epoch 175/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 0.9644 - val_accuracy: 0.8294\n",
      "Epoch 176/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 1.0361 - val_accuracy: 0.8249\n",
      "Epoch 177/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0326 - accuracy: 0.9881 - val_loss: 1.4118 - val_accuracy: 0.8284\n",
      "Epoch 178/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0379 - accuracy: 0.9878 - val_loss: 0.8767 - val_accuracy: 0.8256\n",
      "Epoch 179/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 1.0784 - val_accuracy: 0.8242\n",
      "Epoch 180/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0352 - accuracy: 0.9868 - val_loss: 0.9175 - val_accuracy: 0.8207\n",
      "Epoch 181/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0335 - accuracy: 0.9876 - val_loss: 0.9809 - val_accuracy: 0.8290\n",
      "Epoch 182/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0422 - accuracy: 0.9852 - val_loss: 0.9243 - val_accuracy: 0.8224\n",
      "Epoch 183/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 0.6282 - val_accuracy: 0.8204\n",
      "Epoch 184/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0402 - accuracy: 0.9863 - val_loss: 1.0548 - val_accuracy: 0.8256\n",
      "Epoch 185/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0316 - accuracy: 0.9886 - val_loss: 1.2108 - val_accuracy: 0.8214\n",
      "Epoch 186/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0271 - accuracy: 0.9891 - val_loss: 1.5427 - val_accuracy: 0.8259\n",
      "Epoch 187/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.9168 - val_accuracy: 0.8231\n",
      "Epoch 188/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 1.0375 - val_accuracy: 0.8231\n",
      "Epoch 189/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0396 - accuracy: 0.9858 - val_loss: 1.1623 - val_accuracy: 0.8259\n",
      "Epoch 190/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.6586 - val_accuracy: 0.8127\n",
      "Epoch 191/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0634 - accuracy: 0.9795 - val_loss: 1.0101 - val_accuracy: 0.8263\n",
      "Epoch 192/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 0.8904 - val_accuracy: 0.8343\n",
      "Epoch 193/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0233 - accuracy: 0.9914 - val_loss: 1.0188 - val_accuracy: 0.8224\n",
      "Epoch 194/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0198 - accuracy: 0.9919 - val_loss: 0.9635 - val_accuracy: 0.8294\n",
      "Epoch 195/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0174 - accuracy: 0.9935 - val_loss: 1.2780 - val_accuracy: 0.8301\n",
      "Epoch 196/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.8118 - val_accuracy: 0.8270\n",
      "Epoch 197/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.8511 - val_accuracy: 0.8325\n",
      "Epoch 198/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 1.3180 - val_accuracy: 0.8325\n",
      "Epoch 199/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 1.0601 - val_accuracy: 0.8304\n",
      "Epoch 200/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 0.9072 - val_accuracy: 0.8346\n",
      "Epoch 201/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0329 - accuracy: 0.9869 - val_loss: 1.1106 - val_accuracy: 0.8263\n",
      "Epoch 202/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0348 - accuracy: 0.9876 - val_loss: 0.7128 - val_accuracy: 0.8304\n",
      "Epoch 203/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0307 - accuracy: 0.9886 - val_loss: 0.9743 - val_accuracy: 0.8245\n",
      "Epoch 204/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.9349 - val_accuracy: 0.8242\n",
      "Epoch 205/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 1.1170 - val_accuracy: 0.8204\n",
      "Epoch 206/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 1.0314 - val_accuracy: 0.8193\n",
      "Epoch 207/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.9701 - val_accuracy: 0.8304\n",
      "Epoch 208/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0319 - accuracy: 0.9899 - val_loss: 1.1808 - val_accuracy: 0.8284\n",
      "Epoch 209/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0387 - accuracy: 0.9871 - val_loss: 0.8337 - val_accuracy: 0.8287\n",
      "Epoch 210/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 1.0495 - val_accuracy: 0.8252\n",
      "Epoch 211/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0446 - accuracy: 0.9843 - val_loss: 0.6991 - val_accuracy: 0.8214\n",
      "Epoch 212/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 1.0270 - val_accuracy: 0.8249\n",
      "Epoch 213/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0428 - accuracy: 0.9845 - val_loss: 0.9873 - val_accuracy: 0.8214\n",
      "Epoch 214/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 1.0080 - val_accuracy: 0.8277\n",
      "Epoch 215/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 1.0482 - val_accuracy: 0.8360\n",
      "Epoch 216/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.8983 - val_accuracy: 0.8235\n",
      "Epoch 217/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 1.2491 - val_accuracy: 0.8249\n",
      "Epoch 218/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0375 - accuracy: 0.9877 - val_loss: 1.2106 - val_accuracy: 0.8207\n",
      "Epoch 219/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.8339 - val_accuracy: 0.8224\n",
      "Epoch 220/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0451 - accuracy: 0.9849 - val_loss: 0.9057 - val_accuracy: 0.8238\n",
      "Epoch 221/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.9001 - val_accuracy: 0.8273\n",
      "Epoch 222/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 1.0107 - val_accuracy: 0.8266\n",
      "Epoch 223/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0358 - accuracy: 0.9868 - val_loss: 1.0287 - val_accuracy: 0.8308\n",
      "Epoch 224/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0341 - accuracy: 0.9885 - val_loss: 1.0422 - val_accuracy: 0.8311\n",
      "Epoch 225/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 1.5136 - val_accuracy: 0.8270\n",
      "Epoch 226/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.9567 - val_accuracy: 0.8207\n",
      "Epoch 227/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.9259 - val_accuracy: 0.8315\n",
      "Epoch 228/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 1.1422 - val_accuracy: 0.8297\n",
      "Epoch 229/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 1.7522 - val_accuracy: 0.8304\n",
      "Epoch 230/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 1.0260 - val_accuracy: 0.8245\n",
      "Epoch 231/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 1.3390 - val_accuracy: 0.8249\n",
      "Epoch 232/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 1.4954 - val_accuracy: 0.8218\n",
      "Epoch 233/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 1.6874 - val_accuracy: 0.8242\n",
      "Epoch 234/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0349 - accuracy: 0.9886 - val_loss: 1.4668 - val_accuracy: 0.8190\n",
      "Epoch 235/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0250 - accuracy: 0.9906 - val_loss: 1.9071 - val_accuracy: 0.8256\n",
      "Epoch 236/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 1.2366 - val_accuracy: 0.8273\n",
      "Epoch 237/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0262 - accuracy: 0.9897 - val_loss: 1.4311 - val_accuracy: 0.8211\n",
      "Epoch 238/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 1.0022 - val_accuracy: 0.8231\n",
      "Epoch 239/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0412 - accuracy: 0.9864 - val_loss: 1.1914 - val_accuracy: 0.8235\n",
      "Epoch 240/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 1.9536 - val_accuracy: 0.8155\n",
      "Epoch 241/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0608 - accuracy: 0.9787 - val_loss: 1.7857 - val_accuracy: 0.8204\n",
      "Epoch 242/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0349 - accuracy: 0.9858 - val_loss: 2.3250 - val_accuracy: 0.8266\n",
      "Epoch 243/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0329 - accuracy: 0.9888 - val_loss: 3.7278 - val_accuracy: 0.8249\n",
      "Epoch 244/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0775 - accuracy: 0.9781 - val_loss: 4.8106 - val_accuracy: 0.8138\n",
      "Epoch 245/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1060 - accuracy: 0.9618 - val_loss: 1.3449 - val_accuracy: 0.8176\n",
      "Epoch 246/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0874 - accuracy: 0.9694 - val_loss: 0.7627 - val_accuracy: 0.8186\n",
      "Epoch 247/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0605 - accuracy: 0.9791 - val_loss: 0.8424 - val_accuracy: 0.8204\n",
      "Epoch 248/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0365 - accuracy: 0.9877 - val_loss: 0.8986 - val_accuracy: 0.8204\n",
      "Epoch 249/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 1.0312 - val_accuracy: 0.8252\n",
      "Epoch 250/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 1.2627 - val_accuracy: 0.8235\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=1048, activation='relu'))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dense(units=4096*2, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    batch_size=128,\n",
    "    epochs=250,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_scaled, y_val_categorical)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is overfitting so lets try something else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added Dropouts between each layer at 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1048)              537624    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1048)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2048)              2148352   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8192)              33562624  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 57,420,634\n",
      "Trainable params: 57,420,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      " 1/90 [..............................] - ETA: 2s - loss: 0.7181 - accuracy: 0.4609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.0275s). Check your callbacks.\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.7020 - accuracy: 0.7237 - val_loss: 0.5863 - val_accuracy: 0.7345\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5876 - accuracy: 0.7273 - val_loss: 0.5836 - val_accuracy: 0.7345\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5861 - accuracy: 0.7273 - val_loss: 0.5926 - val_accuracy: 0.7345\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5834 - accuracy: 0.7273 - val_loss: 0.5693 - val_accuracy: 0.7345\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5833 - accuracy: 0.7273 - val_loss: 0.5925 - val_accuracy: 0.7345\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5801 - accuracy: 0.7273 - val_loss: 0.5632 - val_accuracy: 0.7345\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5752 - accuracy: 0.7271 - val_loss: 0.5668 - val_accuracy: 0.7345\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5733 - accuracy: 0.7272 - val_loss: 0.5430 - val_accuracy: 0.7345\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5683 - accuracy: 0.7262 - val_loss: 0.5554 - val_accuracy: 0.7227\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5629 - accuracy: 0.7253 - val_loss: 0.5626 - val_accuracy: 0.7345\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5600 - accuracy: 0.7273 - val_loss: 0.5349 - val_accuracy: 0.7342\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5558 - accuracy: 0.7259 - val_loss: 0.5291 - val_accuracy: 0.7345\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5551 - accuracy: 0.7253 - val_loss: 0.5344 - val_accuracy: 0.7345\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5533 - accuracy: 0.7269 - val_loss: 0.5573 - val_accuracy: 0.7377\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5512 - accuracy: 0.7267 - val_loss: 0.5281 - val_accuracy: 0.7345\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5460 - accuracy: 0.7247 - val_loss: 0.5252 - val_accuracy: 0.7380\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5473 - accuracy: 0.7260 - val_loss: 0.5293 - val_accuracy: 0.7345\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5424 - accuracy: 0.7271 - val_loss: 0.5251 - val_accuracy: 0.7505\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5426 - accuracy: 0.7293 - val_loss: 0.5201 - val_accuracy: 0.7606\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5409 - accuracy: 0.7280 - val_loss: 0.5252 - val_accuracy: 0.7345\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5423 - accuracy: 0.7242 - val_loss: 0.5213 - val_accuracy: 0.7345\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5379 - accuracy: 0.7292 - val_loss: 0.5130 - val_accuracy: 0.7345\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5318 - accuracy: 0.7287 - val_loss: 0.5053 - val_accuracy: 0.7457\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5321 - accuracy: 0.7294 - val_loss: 0.5077 - val_accuracy: 0.7345\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5335 - accuracy: 0.7283 - val_loss: 0.5026 - val_accuracy: 0.7467\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5276 - accuracy: 0.7326 - val_loss: 0.5016 - val_accuracy: 0.7345\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5333 - accuracy: 0.7284 - val_loss: 0.5117 - val_accuracy: 0.7345\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5268 - accuracy: 0.7294 - val_loss: 0.5020 - val_accuracy: 0.7338\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5299 - accuracy: 0.7318 - val_loss: 0.4936 - val_accuracy: 0.7457\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5331 - accuracy: 0.7292 - val_loss: 0.4919 - val_accuracy: 0.7460\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5273 - accuracy: 0.7308 - val_loss: 0.4936 - val_accuracy: 0.7345\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5235 - accuracy: 0.7338 - val_loss: 0.5153 - val_accuracy: 0.7418\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5253 - accuracy: 0.7384 - val_loss: 0.5137 - val_accuracy: 0.7728\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5212 - accuracy: 0.7341 - val_loss: 0.4900 - val_accuracy: 0.7356\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5187 - accuracy: 0.7312 - val_loss: 0.4884 - val_accuracy: 0.7745\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5157 - accuracy: 0.7397 - val_loss: 0.4868 - val_accuracy: 0.7366\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5191 - accuracy: 0.7375 - val_loss: 0.4800 - val_accuracy: 0.7808\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5138 - accuracy: 0.7447 - val_loss: 0.5070 - val_accuracy: 0.7345\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5134 - accuracy: 0.7377 - val_loss: 0.4899 - val_accuracy: 0.7467\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5131 - accuracy: 0.7367 - val_loss: 0.5026 - val_accuracy: 0.7575\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5122 - accuracy: 0.7402 - val_loss: 0.4915 - val_accuracy: 0.7745\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5169 - accuracy: 0.7388 - val_loss: 0.5186 - val_accuracy: 0.7665\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.5162 - accuracy: 0.7379 - val_loss: 0.4839 - val_accuracy: 0.7568\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.5104 - accuracy: 0.7463 - val_loss: 0.4931 - val_accuracy: 0.7832\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.5103 - accuracy: 0.7418 - val_loss: 0.4777 - val_accuracy: 0.7825\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.5072 - accuracy: 0.7438 - val_loss: 0.4937 - val_accuracy: 0.7787\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.5089 - accuracy: 0.7493 - val_loss: 0.4883 - val_accuracy: 0.7856\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5074 - accuracy: 0.7439 - val_loss: 0.4988 - val_accuracy: 0.7325\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5072 - accuracy: 0.7477 - val_loss: 0.4843 - val_accuracy: 0.7825\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5075 - accuracy: 0.7437 - val_loss: 0.4852 - val_accuracy: 0.7523\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5017 - accuracy: 0.7544 - val_loss: 0.5015 - val_accuracy: 0.7582\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5052 - accuracy: 0.7527 - val_loss: 0.4838 - val_accuracy: 0.7856\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5033 - accuracy: 0.7537 - val_loss: 0.4878 - val_accuracy: 0.7835\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5060 - accuracy: 0.7479 - val_loss: 0.4780 - val_accuracy: 0.7686\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5031 - accuracy: 0.7557 - val_loss: 0.4990 - val_accuracy: 0.7540\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5023 - accuracy: 0.7548 - val_loss: 0.4779 - val_accuracy: 0.7776\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4984 - accuracy: 0.7539 - val_loss: 0.4906 - val_accuracy: 0.7491\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4981 - accuracy: 0.7488 - val_loss: 0.4761 - val_accuracy: 0.7464\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4932 - accuracy: 0.7615 - val_loss: 0.5005 - val_accuracy: 0.7811\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4956 - accuracy: 0.7525 - val_loss: 0.4867 - val_accuracy: 0.7853\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4982 - accuracy: 0.7591 - val_loss: 0.4702 - val_accuracy: 0.7905\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4968 - accuracy: 0.7553 - val_loss: 0.4706 - val_accuracy: 0.7842\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4901 - accuracy: 0.7578 - val_loss: 0.4666 - val_accuracy: 0.7464\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4944 - accuracy: 0.7596 - val_loss: 0.4773 - val_accuracy: 0.7825\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4967 - accuracy: 0.7631 - val_loss: 0.4999 - val_accuracy: 0.7950\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4968 - accuracy: 0.7642 - val_loss: 0.4677 - val_accuracy: 0.7860\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4965 - accuracy: 0.7610 - val_loss: 0.4918 - val_accuracy: 0.7964\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4907 - accuracy: 0.7653 - val_loss: 0.4697 - val_accuracy: 0.7828\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4887 - accuracy: 0.7689 - val_loss: 0.4647 - val_accuracy: 0.7953\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4904 - accuracy: 0.7659 - val_loss: 0.4735 - val_accuracy: 0.7797\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4902 - accuracy: 0.7618 - val_loss: 0.4632 - val_accuracy: 0.7752\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4869 - accuracy: 0.7627 - val_loss: 0.4650 - val_accuracy: 0.7919\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4878 - accuracy: 0.7735 - val_loss: 0.4797 - val_accuracy: 0.7960\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4821 - accuracy: 0.7712 - val_loss: 0.4645 - val_accuracy: 0.7926\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4927 - accuracy: 0.7628 - val_loss: 0.4850 - val_accuracy: 0.7922\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4879 - accuracy: 0.7641 - val_loss: 0.4669 - val_accuracy: 0.7728\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4840 - accuracy: 0.7652 - val_loss: 0.4759 - val_accuracy: 0.7523\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4835 - accuracy: 0.7657 - val_loss: 0.4806 - val_accuracy: 0.7662\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4926 - accuracy: 0.7584 - val_loss: 0.4855 - val_accuracy: 0.7345\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4852 - accuracy: 0.7668 - val_loss: 0.4585 - val_accuracy: 0.7967\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4802 - accuracy: 0.7683 - val_loss: 0.4498 - val_accuracy: 0.7992\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4875 - accuracy: 0.7665 - val_loss: 0.4598 - val_accuracy: 0.7908\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4771 - accuracy: 0.7736 - val_loss: 0.4733 - val_accuracy: 0.7964\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4780 - accuracy: 0.7706 - val_loss: 0.4699 - val_accuracy: 0.7523\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4813 - accuracy: 0.7711 - val_loss: 0.4520 - val_accuracy: 0.7971\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4800 - accuracy: 0.7701 - val_loss: 0.4520 - val_accuracy: 0.7915\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4816 - accuracy: 0.7697 - val_loss: 0.4580 - val_accuracy: 0.7985\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4815 - accuracy: 0.7714 - val_loss: 0.4721 - val_accuracy: 0.7978\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4781 - accuracy: 0.7756 - val_loss: 0.4622 - val_accuracy: 0.7957\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4851 - accuracy: 0.7653 - val_loss: 0.4563 - val_accuracy: 0.7999\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4772 - accuracy: 0.7696 - val_loss: 0.4725 - val_accuracy: 0.7919\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4778 - accuracy: 0.7726 - val_loss: 0.4435 - val_accuracy: 0.7933\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4750 - accuracy: 0.7762 - val_loss: 0.4881 - val_accuracy: 0.7467\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4809 - accuracy: 0.7737 - val_loss: 0.4561 - val_accuracy: 0.8033\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4806 - accuracy: 0.7744 - val_loss: 0.4596 - val_accuracy: 0.8016\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4777 - accuracy: 0.7744 - val_loss: 0.4399 - val_accuracy: 0.8026\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4779 - accuracy: 0.7735 - val_loss: 0.4450 - val_accuracy: 0.8047\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4753 - accuracy: 0.7687 - val_loss: 0.4476 - val_accuracy: 0.8075\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4995 - accuracy: 0.7725 - val_loss: 0.4494 - val_accuracy: 0.7981\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4806 - accuracy: 0.7714 - val_loss: 0.4715 - val_accuracy: 0.7884\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4769 - accuracy: 0.7715 - val_loss: 0.4697 - val_accuracy: 0.7915\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4706 - accuracy: 0.7790 - val_loss: 0.4756 - val_accuracy: 0.8002\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4690 - accuracy: 0.7792 - val_loss: 0.4482 - val_accuracy: 0.8023\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4786 - accuracy: 0.7724 - val_loss: 0.4680 - val_accuracy: 0.7995\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4764 - accuracy: 0.7773 - val_loss: 0.4617 - val_accuracy: 0.7856\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4678 - accuracy: 0.7710 - val_loss: 0.4647 - val_accuracy: 0.8023\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4753 - accuracy: 0.7711 - val_loss: 0.4715 - val_accuracy: 0.8009\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4909 - accuracy: 0.7741 - val_loss: 0.4562 - val_accuracy: 0.7794\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.4352 - val_accuracy: 0.8051\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4783 - accuracy: 0.7752 - val_loss: 0.4397 - val_accuracy: 0.8016\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4753 - accuracy: 0.7712 - val_loss: 0.4393 - val_accuracy: 0.7978\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4750 - accuracy: 0.7692 - val_loss: 0.4392 - val_accuracy: 0.7964\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4754 - accuracy: 0.7636 - val_loss: 0.4617 - val_accuracy: 0.7825\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4712 - accuracy: 0.7791 - val_loss: 0.4568 - val_accuracy: 0.7992\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5231 - accuracy: 0.7719 - val_loss: 0.4426 - val_accuracy: 0.8006\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4757 - accuracy: 0.7740 - val_loss: 0.4414 - val_accuracy: 0.7748\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4788 - accuracy: 0.7732 - val_loss: 0.4555 - val_accuracy: 0.7988\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4810 - accuracy: 0.7727 - val_loss: 0.4601 - val_accuracy: 0.8058\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4724 - accuracy: 0.7703 - val_loss: 0.4609 - val_accuracy: 0.7953\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4760 - accuracy: 0.7730 - val_loss: 0.4453 - val_accuracy: 0.7988\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4725 - accuracy: 0.7797 - val_loss: 0.4386 - val_accuracy: 0.7999\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4746 - accuracy: 0.7790 - val_loss: 0.4442 - val_accuracy: 0.8065\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4725 - accuracy: 0.7672 - val_loss: 0.4282 - val_accuracy: 0.7988\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4640 - accuracy: 0.7810 - val_loss: 0.4421 - val_accuracy: 0.7992\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4685 - accuracy: 0.7753 - val_loss: 0.4305 - val_accuracy: 0.8009\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4643 - accuracy: 0.7821 - val_loss: 0.4412 - val_accuracy: 0.8019\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4663 - accuracy: 0.7754 - val_loss: 0.4499 - val_accuracy: 0.7950\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4740 - accuracy: 0.7689 - val_loss: 0.4557 - val_accuracy: 0.8085\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4799 - accuracy: 0.7737 - val_loss: 0.4415 - val_accuracy: 0.8030\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4652 - accuracy: 0.7794 - val_loss: 0.4332 - val_accuracy: 0.8016\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4714 - accuracy: 0.7803 - val_loss: 0.4443 - val_accuracy: 0.8079\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4669 - accuracy: 0.7821 - val_loss: 0.4456 - val_accuracy: 0.8085\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4711 - accuracy: 0.7763 - val_loss: 0.4498 - val_accuracy: 0.8009\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4699 - accuracy: 0.7825 - val_loss: 0.4381 - val_accuracy: 0.8044\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4713 - accuracy: 0.7803 - val_loss: 0.4298 - val_accuracy: 0.8061\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4692 - accuracy: 0.7832 - val_loss: 0.4405 - val_accuracy: 0.8019\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4781 - accuracy: 0.7709 - val_loss: 0.4337 - val_accuracy: 0.8023\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4641 - accuracy: 0.7799 - val_loss: 0.4312 - val_accuracy: 0.8013\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4614 - accuracy: 0.7848 - val_loss: 0.4303 - val_accuracy: 0.8065\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4699 - accuracy: 0.7780 - val_loss: 0.4358 - val_accuracy: 0.8079\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4656 - accuracy: 0.7796 - val_loss: 0.4544 - val_accuracy: 0.7835\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4678 - accuracy: 0.7803 - val_loss: 0.4426 - val_accuracy: 0.8061\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4680 - accuracy: 0.7754 - val_loss: 0.4292 - val_accuracy: 0.8096\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4663 - accuracy: 0.7821 - val_loss: 0.4409 - val_accuracy: 0.8072\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4619 - accuracy: 0.7860 - val_loss: 0.4186 - val_accuracy: 0.8068\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4712 - accuracy: 0.7806 - val_loss: 0.4301 - val_accuracy: 0.8061\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4647 - accuracy: 0.7848 - val_loss: 0.4275 - val_accuracy: 0.8040\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4649 - accuracy: 0.7767 - val_loss: 0.4312 - val_accuracy: 0.8016\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4731 - accuracy: 0.7843 - val_loss: 0.4382 - val_accuracy: 0.7898\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4636 - accuracy: 0.7805 - val_loss: 0.4412 - val_accuracy: 0.8013\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4639 - accuracy: 0.7845 - val_loss: 0.4300 - val_accuracy: 0.8047\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4299 - val_accuracy: 0.8065\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4821 - accuracy: 0.7812 - val_loss: 0.4357 - val_accuracy: 0.8075\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4652 - accuracy: 0.7826 - val_loss: 0.4300 - val_accuracy: 0.8085\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4674 - accuracy: 0.7750 - val_loss: 0.4237 - val_accuracy: 0.8106\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4792 - accuracy: 0.7782 - val_loss: 0.4256 - val_accuracy: 0.8044\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4761 - accuracy: 0.7762 - val_loss: 0.4327 - val_accuracy: 0.8019\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4751 - accuracy: 0.7729 - val_loss: 0.4344 - val_accuracy: 0.8103\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4647 - accuracy: 0.7797 - val_loss: 0.4340 - val_accuracy: 0.8040\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4694 - accuracy: 0.7801 - val_loss: 0.4348 - val_accuracy: 0.8148\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4706 - accuracy: 0.7785 - val_loss: 0.4313 - val_accuracy: 0.8054\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4902 - accuracy: 0.7758 - val_loss: 0.4300 - val_accuracy: 0.8099\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4705 - accuracy: 0.7767 - val_loss: 0.4430 - val_accuracy: 0.7999\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4674 - accuracy: 0.7809 - val_loss: 0.4367 - val_accuracy: 0.8089\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4694 - accuracy: 0.7775 - val_loss: 0.4481 - val_accuracy: 0.8033\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4972 - accuracy: 0.7664 - val_loss: 0.4421 - val_accuracy: 0.8044\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4714 - accuracy: 0.7738 - val_loss: 0.4248 - val_accuracy: 0.7978\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4691 - accuracy: 0.7766 - val_loss: 0.4284 - val_accuracy: 0.8040\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4825 - accuracy: 0.7716 - val_loss: 0.4353 - val_accuracy: 0.8033\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4776 - accuracy: 0.7737 - val_loss: 0.4494 - val_accuracy: 0.7971\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4693 - accuracy: 0.7763 - val_loss: 0.4450 - val_accuracy: 0.8006\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4726 - accuracy: 0.7767 - val_loss: 0.4356 - val_accuracy: 0.8006\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4699 - accuracy: 0.7731 - val_loss: 0.4203 - val_accuracy: 0.8061\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4644 - accuracy: 0.7822 - val_loss: 0.4336 - val_accuracy: 0.8106\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4629 - accuracy: 0.7816 - val_loss: 0.4178 - val_accuracy: 0.8138\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4657 - accuracy: 0.7816 - val_loss: 0.4270 - val_accuracy: 0.8061\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4611 - accuracy: 0.7809 - val_loss: 0.4455 - val_accuracy: 0.8058\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4701 - accuracy: 0.7799 - val_loss: 0.4347 - val_accuracy: 0.8068\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.4354 - val_accuracy: 0.8006\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4693 - accuracy: 0.7761 - val_loss: 0.4453 - val_accuracy: 0.8054\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4667 - accuracy: 0.7785 - val_loss: 0.4269 - val_accuracy: 0.8113\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4709 - accuracy: 0.7755 - val_loss: 0.4389 - val_accuracy: 0.8110\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.4162 - val_accuracy: 0.8158\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4611 - accuracy: 0.7810 - val_loss: 0.4141 - val_accuracy: 0.8092\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4666 - accuracy: 0.7757 - val_loss: 0.4180 - val_accuracy: 0.8138\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4677 - accuracy: 0.7761 - val_loss: 0.4371 - val_accuracy: 0.8040\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4976 - accuracy: 0.7715 - val_loss: 0.4316 - val_accuracy: 0.8023\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4688 - accuracy: 0.7753 - val_loss: 0.4693 - val_accuracy: 0.7613\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4672 - accuracy: 0.7781 - val_loss: 0.4252 - val_accuracy: 0.8113\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4674 - accuracy: 0.7816 - val_loss: 0.4301 - val_accuracy: 0.8190\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4767 - accuracy: 0.7751 - val_loss: 0.4499 - val_accuracy: 0.8065\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4697 - accuracy: 0.7727 - val_loss: 0.4394 - val_accuracy: 0.7530\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4660 - accuracy: 0.7804 - val_loss: 0.4411 - val_accuracy: 0.7960\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4750 - accuracy: 0.7803 - val_loss: 0.4555 - val_accuracy: 0.8103\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4732 - accuracy: 0.7778 - val_loss: 0.4394 - val_accuracy: 0.8120\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4669 - accuracy: 0.7791 - val_loss: 0.4282 - val_accuracy: 0.8113\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4633 - accuracy: 0.7825 - val_loss: 0.4277 - val_accuracy: 0.8047\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4608 - accuracy: 0.7790 - val_loss: 0.4394 - val_accuracy: 0.8165\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4654 - accuracy: 0.7797 - val_loss: 0.4233 - val_accuracy: 0.8127\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4683 - accuracy: 0.7747 - val_loss: 0.4357 - val_accuracy: 0.7585\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4696 - accuracy: 0.7786 - val_loss: 0.4301 - val_accuracy: 0.8169\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4675 - accuracy: 0.7735 - val_loss: 0.4552 - val_accuracy: 0.7853\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.4306 - val_accuracy: 0.8047\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4707 - accuracy: 0.7777 - val_loss: 0.4158 - val_accuracy: 0.8131\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4724 - accuracy: 0.7794 - val_loss: 0.4255 - val_accuracy: 0.8200\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4150 - val_accuracy: 0.8256\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4689 - accuracy: 0.7823 - val_loss: 0.4167 - val_accuracy: 0.8148\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4638 - accuracy: 0.7781 - val_loss: 0.4219 - val_accuracy: 0.8113\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4606 - accuracy: 0.7855 - val_loss: 0.4194 - val_accuracy: 0.8089\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4614 - accuracy: 0.7737 - val_loss: 0.4266 - val_accuracy: 0.8103\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4600 - accuracy: 0.7786 - val_loss: 0.4396 - val_accuracy: 0.8207\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4859 - accuracy: 0.7697 - val_loss: 0.4232 - val_accuracy: 0.8124\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4747 - accuracy: 0.7697 - val_loss: 0.4252 - val_accuracy: 0.7835\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4666 - accuracy: 0.7675 - val_loss: 0.4160 - val_accuracy: 0.8169\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5380 - accuracy: 0.7805 - val_loss: 0.4408 - val_accuracy: 0.7540\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4732 - accuracy: 0.7674 - val_loss: 0.4268 - val_accuracy: 0.8106\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4712 - accuracy: 0.7755 - val_loss: 0.4260 - val_accuracy: 0.8113\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4644 - accuracy: 0.7791 - val_loss: 0.4292 - val_accuracy: 0.8186\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4844 - accuracy: 0.7676 - val_loss: 0.4430 - val_accuracy: 0.7870\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5069 - accuracy: 0.7753 - val_loss: 0.4424 - val_accuracy: 0.7696\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4753 - accuracy: 0.7649 - val_loss: 0.4420 - val_accuracy: 0.7599\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5198 - accuracy: 0.7694 - val_loss: 0.4369 - val_accuracy: 0.7689\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4846 - accuracy: 0.7677 - val_loss: 0.4337 - val_accuracy: 0.7967\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4728 - accuracy: 0.7687 - val_loss: 0.4354 - val_accuracy: 0.7436\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4942 - accuracy: 0.7693 - val_loss: 0.4333 - val_accuracy: 0.7589\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4786 - accuracy: 0.7657 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4696 - accuracy: 0.7722 - val_loss: 0.4221 - val_accuracy: 0.8006\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4683 - accuracy: 0.7701 - val_loss: 0.4265 - val_accuracy: 0.7846\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4694 - accuracy: 0.7748 - val_loss: 0.4326 - val_accuracy: 0.8051\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4752 - accuracy: 0.7720 - val_loss: 0.4402 - val_accuracy: 0.7380\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4905 - accuracy: 0.7686 - val_loss: 0.4357 - val_accuracy: 0.7637\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4691 - accuracy: 0.7731 - val_loss: 0.4253 - val_accuracy: 0.7995\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4679 - accuracy: 0.7769 - val_loss: 0.4251 - val_accuracy: 0.7981\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4661 - accuracy: 0.7757 - val_loss: 0.4203 - val_accuracy: 0.8058\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4715 - accuracy: 0.7749 - val_loss: 0.4400 - val_accuracy: 0.7543\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4675 - accuracy: 0.7713 - val_loss: 0.4263 - val_accuracy: 0.7814\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4749 - accuracy: 0.7680 - val_loss: 0.4349 - val_accuracy: 0.7728\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4659 - accuracy: 0.7752 - val_loss: 0.4196 - val_accuracy: 0.8033\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4663 - accuracy: 0.7741 - val_loss: 0.4312 - val_accuracy: 0.7995\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4690 - accuracy: 0.7746 - val_loss: 0.4379 - val_accuracy: 0.7384\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4650 - accuracy: 0.7770 - val_loss: 0.4293 - val_accuracy: 0.7721\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4859 - accuracy: 0.7770 - val_loss: 0.4222 - val_accuracy: 0.8030\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5094 - accuracy: 0.7752 - val_loss: 0.4417 - val_accuracy: 0.7675\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4758 - accuracy: 0.7744 - val_loss: 0.4360 - val_accuracy: 0.7561\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4287 - val_accuracy: 0.7901\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4235 - val_accuracy: 0.8155\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4656 - accuracy: 0.7775 - val_loss: 0.4247 - val_accuracy: 0.7630\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.4285 - val_accuracy: 0.8054\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4649 - accuracy: 0.7827 - val_loss: 0.4177 - val_accuracy: 0.8030\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4648 - accuracy: 0.7858 - val_loss: 0.4321 - val_accuracy: 0.8040\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4667 - accuracy: 0.7806 - val_loss: 0.4319 - val_accuracy: 0.7672\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4634 - accuracy: 0.7806 - val_loss: 0.4340 - val_accuracy: 0.8158\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4844 - accuracy: 0.7757 - val_loss: 0.4200 - val_accuracy: 0.8072\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4689 - accuracy: 0.7786 - val_loss: 0.4252 - val_accuracy: 0.8033\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4719 - accuracy: 0.7830 - val_loss: 0.4429 - val_accuracy: 0.7644\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4721 - accuracy: 0.7787 - val_loss: 0.4301 - val_accuracy: 0.8016\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4742 - accuracy: 0.7757 - val_loss: 0.4483 - val_accuracy: 0.7422\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4948 - accuracy: 0.7669 - val_loss: 0.4317 - val_accuracy: 0.7728\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4679 - accuracy: 0.7741 - val_loss: 0.4326 - val_accuracy: 0.7516\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4817 - accuracy: 0.7658 - val_loss: 0.4514 - val_accuracy: 0.7450\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4796 - accuracy: 0.7685 - val_loss: 0.4434 - val_accuracy: 0.7498\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4774 - accuracy: 0.7627 - val_loss: 0.4330 - val_accuracy: 0.7655\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4761 - accuracy: 0.7699 - val_loss: 0.4495 - val_accuracy: 0.7533\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4823 - accuracy: 0.7679 - val_loss: 0.4533 - val_accuracy: 0.7422\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4784 - accuracy: 0.7637 - val_loss: 0.4365 - val_accuracy: 0.7502\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4718 - accuracy: 0.7735 - val_loss: 0.4383 - val_accuracy: 0.7596\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4697 - accuracy: 0.7723 - val_loss: 0.4407 - val_accuracy: 0.7380\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4692 - accuracy: 0.7757 - val_loss: 0.4188 - val_accuracy: 0.8033\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4692 - accuracy: 0.7731 - val_loss: 0.4282 - val_accuracy: 0.7894\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4662 - accuracy: 0.7755 - val_loss: 0.4318 - val_accuracy: 0.7978\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4588 - accuracy: 0.7817 - val_loss: 0.4287 - val_accuracy: 0.7936\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4637 - accuracy: 0.7809 - val_loss: 0.4370 - val_accuracy: 0.7637\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4644 - accuracy: 0.7763 - val_loss: 0.4154 - val_accuracy: 0.8082\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4605 - accuracy: 0.7810 - val_loss: 0.4303 - val_accuracy: 0.8051\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4674 - accuracy: 0.7862 - val_loss: 0.4274 - val_accuracy: 0.8096\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4841 - accuracy: 0.7820 - val_loss: 0.4319 - val_accuracy: 0.8061\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4694 - accuracy: 0.7902 - val_loss: 0.4260 - val_accuracy: 0.8051\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4587 - accuracy: 0.7844 - val_loss: 0.4283 - val_accuracy: 0.8026\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4709 - accuracy: 0.7831 - val_loss: 0.4288 - val_accuracy: 0.7898\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4661 - accuracy: 0.7793 - val_loss: 0.4272 - val_accuracy: 0.8092\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4682 - accuracy: 0.7710 - val_loss: 0.4265 - val_accuracy: 0.8002\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4602 - accuracy: 0.7790 - val_loss: 0.4284 - val_accuracy: 0.7988\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4671 - accuracy: 0.7796 - val_loss: 0.4136 - val_accuracy: 0.8131\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4693 - accuracy: 0.7810 - val_loss: 0.4284 - val_accuracy: 0.7919\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4679 - accuracy: 0.7745 - val_loss: 0.4263 - val_accuracy: 0.7957\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4610 - accuracy: 0.7818 - val_loss: 0.4307 - val_accuracy: 0.8023\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4658 - accuracy: 0.7829 - val_loss: 0.4150 - val_accuracy: 0.8002\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4615 - accuracy: 0.7828 - val_loss: 0.4135 - val_accuracy: 0.8197\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4608 - accuracy: 0.7840 - val_loss: 0.4259 - val_accuracy: 0.8224\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4697 - accuracy: 0.7789 - val_loss: 0.4154 - val_accuracy: 0.8082\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4686 - accuracy: 0.7906 - val_loss: 0.4219 - val_accuracy: 0.8138\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4581 - accuracy: 0.7867 - val_loss: 0.4145 - val_accuracy: 0.8179\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4628 - accuracy: 0.7872 - val_loss: 0.4234 - val_accuracy: 0.8141\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4670 - accuracy: 0.7755 - val_loss: 0.4435 - val_accuracy: 0.8127\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4659 - accuracy: 0.7868 - val_loss: 0.4311 - val_accuracy: 0.8058\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4777 - accuracy: 0.7843 - val_loss: 0.4190 - val_accuracy: 0.8072\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4679 - accuracy: 0.7832 - val_loss: 0.4235 - val_accuracy: 0.8061\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4710 - accuracy: 0.7797 - val_loss: 0.4252 - val_accuracy: 0.8058\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4850 - accuracy: 0.7757 - val_loss: 0.4231 - val_accuracy: 0.8089\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4760 - accuracy: 0.7733 - val_loss: 0.4170 - val_accuracy: 0.8148\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4644 - accuracy: 0.7836 - val_loss: 0.4309 - val_accuracy: 0.8058\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4695 - accuracy: 0.7844 - val_loss: 0.4187 - val_accuracy: 0.8165\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4872 - accuracy: 0.7781 - val_loss: 0.4151 - val_accuracy: 0.8089\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4691 - accuracy: 0.7787 - val_loss: 0.4315 - val_accuracy: 0.7995\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4742 - accuracy: 0.7762 - val_loss: 0.4334 - val_accuracy: 0.7627\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4649 - accuracy: 0.7845 - val_loss: 0.4306 - val_accuracy: 0.8051\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4725 - accuracy: 0.7829 - val_loss: 0.4305 - val_accuracy: 0.8145\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4717 - accuracy: 0.7810 - val_loss: 0.4276 - val_accuracy: 0.8044\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4319 - val_accuracy: 0.8068\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4747 - accuracy: 0.7852 - val_loss: 0.4284 - val_accuracy: 0.7978\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4748 - accuracy: 0.7816 - val_loss: 0.4231 - val_accuracy: 0.8013\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4743 - accuracy: 0.7785 - val_loss: 0.4316 - val_accuracy: 0.8176\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4671 - accuracy: 0.7771 - val_loss: 0.4316 - val_accuracy: 0.8151\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4647 - accuracy: 0.7803 - val_loss: 0.4258 - val_accuracy: 0.8103\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4699 - accuracy: 0.7767 - val_loss: 0.4237 - val_accuracy: 0.8117\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4741 - accuracy: 0.7750 - val_loss: 0.4289 - val_accuracy: 0.8019\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4634 - accuracy: 0.7829 - val_loss: 0.4258 - val_accuracy: 0.8065\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4578 - accuracy: 0.7866 - val_loss: 0.4367 - val_accuracy: 0.7992\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4973 - accuracy: 0.7836 - val_loss: 0.4274 - val_accuracy: 0.8068\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4668 - accuracy: 0.7737 - val_loss: 0.4197 - val_accuracy: 0.8044\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4772 - accuracy: 0.7823 - val_loss: 0.4333 - val_accuracy: 0.8183\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4539 - accuracy: 0.7862 - val_loss: 0.4272 - val_accuracy: 0.8169\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4705 - accuracy: 0.7819 - val_loss: 0.4174 - val_accuracy: 0.7933\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4634 - accuracy: 0.7775 - val_loss: 0.4255 - val_accuracy: 0.7856\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4707 - accuracy: 0.7753 - val_loss: 0.4259 - val_accuracy: 0.8120\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4770 - accuracy: 0.7712 - val_loss: 0.4239 - val_accuracy: 0.8065\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4848 - accuracy: 0.7797 - val_loss: 0.4222 - val_accuracy: 0.8169\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4778 - accuracy: 0.7836 - val_loss: 0.4168 - val_accuracy: 0.8127\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4718 - accuracy: 0.7803 - val_loss: 0.4368 - val_accuracy: 0.8099\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4710 - accuracy: 0.7848 - val_loss: 0.4251 - val_accuracy: 0.8138\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4641 - accuracy: 0.7862 - val_loss: 0.4234 - val_accuracy: 0.8141\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4621 - accuracy: 0.7844 - val_loss: 0.4202 - val_accuracy: 0.8176\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5076 - accuracy: 0.7799 - val_loss: 0.4379 - val_accuracy: 0.8179\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4803 - accuracy: 0.7724 - val_loss: 0.4237 - val_accuracy: 0.8148\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4711 - accuracy: 0.7746 - val_loss: 0.4280 - val_accuracy: 0.8026\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4671 - accuracy: 0.7773 - val_loss: 0.4191 - val_accuracy: 0.8085\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4687 - accuracy: 0.7821 - val_loss: 0.4239 - val_accuracy: 0.8186\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7837 - val_loss: 0.4238 - val_accuracy: 0.8224\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4674 - accuracy: 0.7810 - val_loss: 0.4351 - val_accuracy: 0.8110\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4978 - accuracy: 0.7766 - val_loss: 0.4220 - val_accuracy: 0.8117\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4726 - accuracy: 0.7763 - val_loss: 0.4284 - val_accuracy: 0.8068\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4690 - accuracy: 0.7815 - val_loss: 0.4244 - val_accuracy: 0.8099\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4820 - accuracy: 0.7777 - val_loss: 0.4254 - val_accuracy: 0.8120\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4645 - accuracy: 0.7824 - val_loss: 0.4182 - val_accuracy: 0.8082\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4680 - accuracy: 0.7833 - val_loss: 0.4179 - val_accuracy: 0.8138\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4763 - accuracy: 0.7793 - val_loss: 0.4315 - val_accuracy: 0.8120\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7845 - val_loss: 0.4296 - val_accuracy: 0.8075\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4615 - accuracy: 0.7892 - val_loss: 0.4266 - val_accuracy: 0.8033\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4840 - accuracy: 0.7834 - val_loss: 0.4153 - val_accuracy: 0.8013\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4684 - accuracy: 0.7803 - val_loss: 0.4257 - val_accuracy: 0.7971\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4585 - accuracy: 0.7871 - val_loss: 0.4182 - val_accuracy: 0.8145\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4952 - accuracy: 0.7790 - val_loss: 0.4252 - val_accuracy: 0.8047\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4684 - accuracy: 0.7813 - val_loss: 0.4286 - val_accuracy: 0.8131\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4756 - accuracy: 0.7817 - val_loss: 0.4321 - val_accuracy: 0.8110\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4628 - accuracy: 0.7745 - val_loss: 0.4319 - val_accuracy: 0.8096\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4607 - accuracy: 0.7829 - val_loss: 0.4220 - val_accuracy: 0.8092\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5706 - accuracy: 0.7734 - val_loss: 0.4298 - val_accuracy: 0.8082\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4647 - accuracy: 0.7793 - val_loss: 0.4185 - val_accuracy: 0.8148\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4914 - accuracy: 0.7750 - val_loss: 0.4208 - val_accuracy: 0.8085\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4705 - accuracy: 0.7807 - val_loss: 0.4286 - val_accuracy: 0.8127\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4636 - accuracy: 0.7820 - val_loss: 0.4210 - val_accuracy: 0.8151\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4770 - accuracy: 0.7853 - val_loss: 0.4190 - val_accuracy: 0.8162\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4722 - accuracy: 0.7789 - val_loss: 0.4216 - val_accuracy: 0.8158\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4732 - accuracy: 0.7764 - val_loss: 0.4199 - val_accuracy: 0.8155\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4719 - accuracy: 0.7817 - val_loss: 0.4241 - val_accuracy: 0.8113\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4702 - accuracy: 0.7757 - val_loss: 0.4371 - val_accuracy: 0.8148\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4838 - accuracy: 0.7732 - val_loss: 0.4346 - val_accuracy: 0.8186\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4788 - accuracy: 0.7743 - val_loss: 0.4209 - val_accuracy: 0.8082\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4715 - accuracy: 0.7769 - val_loss: 0.4207 - val_accuracy: 0.8117\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4693 - accuracy: 0.7796 - val_loss: 0.4207 - val_accuracy: 0.8085\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4643 - accuracy: 0.7794 - val_loss: 0.4245 - val_accuracy: 0.8026\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4648 - accuracy: 0.7781 - val_loss: 0.4305 - val_accuracy: 0.8148\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4717 - accuracy: 0.7801 - val_loss: 0.4287 - val_accuracy: 0.8075\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4728 - accuracy: 0.7777 - val_loss: 0.4290 - val_accuracy: 0.7995\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4679 - accuracy: 0.7775 - val_loss: 0.4303 - val_accuracy: 0.8151\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4721 - accuracy: 0.7795 - val_loss: 0.4342 - val_accuracy: 0.8072\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4605 - accuracy: 0.7815 - val_loss: 0.4223 - val_accuracy: 0.8179\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4789 - accuracy: 0.7737 - val_loss: 0.4379 - val_accuracy: 0.7700\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4735 - accuracy: 0.7716 - val_loss: 0.4297 - val_accuracy: 0.8040\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.4246 - val_accuracy: 0.8197\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4657 - accuracy: 0.7816 - val_loss: 0.4414 - val_accuracy: 0.7821\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4745 - accuracy: 0.7717 - val_loss: 0.4321 - val_accuracy: 0.7568\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4759 - accuracy: 0.7696 - val_loss: 0.4311 - val_accuracy: 0.7554\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4792 - accuracy: 0.7742 - val_loss: 0.4323 - val_accuracy: 0.8047\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4788 - accuracy: 0.7753 - val_loss: 0.4272 - val_accuracy: 0.7634\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4651 - accuracy: 0.7810 - val_loss: 0.4222 - val_accuracy: 0.8162\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4717 - accuracy: 0.7780 - val_loss: 0.4246 - val_accuracy: 0.8037\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4648 - accuracy: 0.7829 - val_loss: 0.4301 - val_accuracy: 0.7662\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4642 - accuracy: 0.7816 - val_loss: 0.4343 - val_accuracy: 0.7884\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4633 - accuracy: 0.7828 - val_loss: 0.4319 - val_accuracy: 0.8082\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4670 - accuracy: 0.7800 - val_loss: 0.4255 - val_accuracy: 0.8061\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4758 - accuracy: 0.7844 - val_loss: 0.4176 - val_accuracy: 0.8058\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4633 - accuracy: 0.7854 - val_loss: 0.4325 - val_accuracy: 0.8148\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4617 - accuracy: 0.7903 - val_loss: 0.4196 - val_accuracy: 0.8186\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4772 - accuracy: 0.7871 - val_loss: 0.4236 - val_accuracy: 0.8145\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4671 - accuracy: 0.7803 - val_loss: 0.4460 - val_accuracy: 0.8131\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4865 - accuracy: 0.7750 - val_loss: 0.4492 - val_accuracy: 0.8110\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4983 - accuracy: 0.7723 - val_loss: 0.4283 - val_accuracy: 0.8096\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4722 - accuracy: 0.7729 - val_loss: 0.4261 - val_accuracy: 0.8085\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7785 - val_loss: 0.4180 - val_accuracy: 0.7967\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4608 - accuracy: 0.7871 - val_loss: 0.4129 - val_accuracy: 0.8169\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4635 - accuracy: 0.7823 - val_loss: 0.4256 - val_accuracy: 0.8207\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4711 - accuracy: 0.7831 - val_loss: 0.4205 - val_accuracy: 0.8148\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4669 - accuracy: 0.7819 - val_loss: 0.4207 - val_accuracy: 0.8158\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4934 - accuracy: 0.7758 - val_loss: 0.4290 - val_accuracy: 0.7801\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.5066 - accuracy: 0.7657 - val_loss: 0.4286 - val_accuracy: 0.8072\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4778 - accuracy: 0.7733 - val_loss: 0.4336 - val_accuracy: 0.8106\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4730 - accuracy: 0.7708 - val_loss: 0.4220 - val_accuracy: 0.8131\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4747 - accuracy: 0.7784 - val_loss: 0.4302 - val_accuracy: 0.8197\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4686 - accuracy: 0.7842 - val_loss: 0.4215 - val_accuracy: 0.8162\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4658 - accuracy: 0.7843 - val_loss: 0.4370 - val_accuracy: 0.8099\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4816 - accuracy: 0.7830 - val_loss: 0.4197 - val_accuracy: 0.8023\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4683 - accuracy: 0.7804 - val_loss: 0.4262 - val_accuracy: 0.7995\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4720 - accuracy: 0.7806 - val_loss: 0.4168 - val_accuracy: 0.8051\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4638 - accuracy: 0.7814 - val_loss: 0.4132 - val_accuracy: 0.8162\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4630 - accuracy: 0.7894 - val_loss: 0.4310 - val_accuracy: 0.8165\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.5277 - accuracy: 0.7894 - val_loss: 0.4197 - val_accuracy: 0.8224\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4820 - accuracy: 0.7770 - val_loss: 0.4348 - val_accuracy: 0.8169\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4822 - accuracy: 0.7801 - val_loss: 0.4183 - val_accuracy: 0.8197\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4789 - accuracy: 0.7769 - val_loss: 0.4287 - val_accuracy: 0.8054\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4790 - accuracy: 0.7750 - val_loss: 0.4192 - val_accuracy: 0.8204\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4764 - accuracy: 0.7763 - val_loss: 0.4259 - val_accuracy: 0.8190\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4678 - accuracy: 0.7805 - val_loss: 0.4131 - val_accuracy: 0.8200\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4726 - accuracy: 0.7720 - val_loss: 0.4363 - val_accuracy: 0.8172\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4745 - accuracy: 0.7744 - val_loss: 0.4341 - val_accuracy: 0.8165\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4752 - accuracy: 0.7744 - val_loss: 0.4209 - val_accuracy: 0.8183\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4690 - accuracy: 0.7790 - val_loss: 0.4160 - val_accuracy: 0.8023\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4732 - accuracy: 0.7768 - val_loss: 0.4157 - val_accuracy: 0.8197\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4749 - accuracy: 0.7791 - val_loss: 0.4211 - val_accuracy: 0.8172\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4714 - accuracy: 0.7817 - val_loss: 0.4295 - val_accuracy: 0.8127\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4724 - accuracy: 0.7850 - val_loss: 0.4233 - val_accuracy: 0.8099\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4939 - accuracy: 0.7770 - val_loss: 0.4341 - val_accuracy: 0.8211\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4894 - accuracy: 0.7798 - val_loss: 0.4230 - val_accuracy: 0.8151\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4693 - accuracy: 0.7805 - val_loss: 0.4334 - val_accuracy: 0.8134\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4890 - accuracy: 0.7759 - val_loss: 0.4280 - val_accuracy: 0.8026\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4850 - accuracy: 0.7726 - val_loss: 0.4285 - val_accuracy: 0.8106\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4804 - accuracy: 0.7749 - val_loss: 0.4288 - val_accuracy: 0.7978\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4931 - accuracy: 0.7765 - val_loss: 0.4279 - val_accuracy: 0.8145\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4756 - accuracy: 0.7758 - val_loss: 0.4314 - val_accuracy: 0.8169\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4841 - accuracy: 0.7723 - val_loss: 0.4366 - val_accuracy: 0.8193\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4844 - accuracy: 0.7674 - val_loss: 0.4379 - val_accuracy: 0.7759\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.8108 - accuracy: 0.7611 - val_loss: 0.4386 - val_accuracy: 0.8037\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4838 - accuracy: 0.7689 - val_loss: 0.4325 - val_accuracy: 0.8200\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4800 - accuracy: 0.7703 - val_loss: 0.4438 - val_accuracy: 0.8120\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4779 - accuracy: 0.7752 - val_loss: 0.4259 - val_accuracy: 0.8224\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4730 - accuracy: 0.7749 - val_loss: 0.4276 - val_accuracy: 0.8162\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4714 - accuracy: 0.7747 - val_loss: 0.4296 - val_accuracy: 0.8231\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4721 - accuracy: 0.7736 - val_loss: 0.4231 - val_accuracy: 0.8197\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4913 - accuracy: 0.7758 - val_loss: 0.4505 - val_accuracy: 0.8138\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4870 - accuracy: 0.7722 - val_loss: 0.4331 - val_accuracy: 0.8148\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4746 - accuracy: 0.7769 - val_loss: 0.4317 - val_accuracy: 0.8186\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4783 - accuracy: 0.7770 - val_loss: 0.4285 - val_accuracy: 0.8211\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4821 - accuracy: 0.7825 - val_loss: 0.4322 - val_accuracy: 0.8211\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4809 - accuracy: 0.7809 - val_loss: 0.4371 - val_accuracy: 0.8165\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4741 - accuracy: 0.7816 - val_loss: 0.4387 - val_accuracy: 0.8155\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4669 - accuracy: 0.7777 - val_loss: 0.4305 - val_accuracy: 0.8026\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4836 - accuracy: 0.7777 - val_loss: 0.4228 - val_accuracy: 0.8179\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4788 - accuracy: 0.7671 - val_loss: 0.4366 - val_accuracy: 0.8204\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4689 - accuracy: 0.7723 - val_loss: 0.4192 - val_accuracy: 0.8211\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4662 - accuracy: 0.7869 - val_loss: 0.4258 - val_accuracy: 0.8179\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4710 - accuracy: 0.7822 - val_loss: 0.4179 - val_accuracy: 0.8193\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4713 - accuracy: 0.7816 - val_loss: 0.4246 - val_accuracy: 0.8214\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4712 - accuracy: 0.7763 - val_loss: 0.4316 - val_accuracy: 0.8183\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4736 - accuracy: 0.7751 - val_loss: 0.4336 - val_accuracy: 0.8158\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4715 - accuracy: 0.7722 - val_loss: 0.4304 - val_accuracy: 0.8134\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4718 - accuracy: 0.7750 - val_loss: 0.4175 - val_accuracy: 0.8207\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4725 - accuracy: 0.7742 - val_loss: 0.4340 - val_accuracy: 0.8231\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4626 - accuracy: 0.7783 - val_loss: 0.4178 - val_accuracy: 0.8186\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4839 - accuracy: 0.7717 - val_loss: 0.4296 - val_accuracy: 0.8082\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4618 - accuracy: 0.7807 - val_loss: 0.4238 - val_accuracy: 0.8026\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4710 - accuracy: 0.7754 - val_loss: 0.4203 - val_accuracy: 0.7894\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4806 - accuracy: 0.7741 - val_loss: 0.4348 - val_accuracy: 0.8224\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4750 - accuracy: 0.7760 - val_loss: 0.4228 - val_accuracy: 0.8235\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4685 - accuracy: 0.7780 - val_loss: 0.4243 - val_accuracy: 0.8290\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4932 - accuracy: 0.7754 - val_loss: 0.4276 - val_accuracy: 0.8068\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4731 - accuracy: 0.7719 - val_loss: 0.4323 - val_accuracy: 0.8165\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4778 - accuracy: 0.7750 - val_loss: 0.4346 - val_accuracy: 0.7988\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4773 - accuracy: 0.7742 - val_loss: 0.4403 - val_accuracy: 0.8200\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4756 - accuracy: 0.7735 - val_loss: 0.4310 - val_accuracy: 0.8197\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4740 - accuracy: 0.7733 - val_loss: 0.4349 - val_accuracy: 0.8110\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4938 - accuracy: 0.7745 - val_loss: 0.4332 - val_accuracy: 0.8079\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4831 - accuracy: 0.7677 - val_loss: 0.4392 - val_accuracy: 0.8113\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4938 - accuracy: 0.7707 - val_loss: 0.4514 - val_accuracy: 0.8054\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4865 - accuracy: 0.7697 - val_loss: 0.4428 - val_accuracy: 0.7960\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5568 - accuracy: 0.7733 - val_loss: 0.4430 - val_accuracy: 0.8183\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4984 - accuracy: 0.7728 - val_loss: 0.4410 - val_accuracy: 0.7960\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4843 - accuracy: 0.7637 - val_loss: 0.4525 - val_accuracy: 0.7860\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4790 - accuracy: 0.7614 - val_loss: 0.4531 - val_accuracy: 0.8013\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4827 - accuracy: 0.7577 - val_loss: 0.4369 - val_accuracy: 0.7946\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4742 - accuracy: 0.7703 - val_loss: 0.4405 - val_accuracy: 0.8023\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4762 - accuracy: 0.7693 - val_loss: 0.4317 - val_accuracy: 0.8044\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4761 - accuracy: 0.7697 - val_loss: 0.4316 - val_accuracy: 0.8207\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4716 - accuracy: 0.7732 - val_loss: 0.4401 - val_accuracy: 0.8221\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5028 - accuracy: 0.7763 - val_loss: 0.4349 - val_accuracy: 0.8238\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4922 - accuracy: 0.7676 - val_loss: 0.4355 - val_accuracy: 0.8148\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4883 - accuracy: 0.7697 - val_loss: 0.4348 - val_accuracy: 0.8221\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4892 - accuracy: 0.7740 - val_loss: 0.4305 - val_accuracy: 0.8106\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4769 - accuracy: 0.7708 - val_loss: 0.4366 - val_accuracy: 0.8106\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4802 - accuracy: 0.7708 - val_loss: 0.4428 - val_accuracy: 0.7988\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4876 - accuracy: 0.7609 - val_loss: 0.4467 - val_accuracy: 0.7960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4096*2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_scaled, y_val_categorical)\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dropouts at a rate at 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1048)              537624    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1048)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2048)              2148352   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 8192)              33562624  \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 57,420,634\n",
      "Trainable params: 57,420,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      " 1/90 [..............................] - ETA: 2s - loss: 0.6809 - accuracy: 0.7266WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.0319s). Check your callbacks.\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.6559 - accuracy: 0.7264 - val_loss: 0.5858 - val_accuracy: 0.7345\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5701 - accuracy: 0.7273 - val_loss: 0.5556 - val_accuracy: 0.7345\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5587 - accuracy: 0.7266 - val_loss: 0.5282 - val_accuracy: 0.7338\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5541 - accuracy: 0.7277 - val_loss: 0.5413 - val_accuracy: 0.7345\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5409 - accuracy: 0.7291 - val_loss: 0.5157 - val_accuracy: 0.7345\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5346 - accuracy: 0.7289 - val_loss: 0.5132 - val_accuracy: 0.7338\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.5292 - accuracy: 0.7394 - val_loss: 0.5058 - val_accuracy: 0.7366\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.5239 - accuracy: 0.7458 - val_loss: 0.4774 - val_accuracy: 0.7682\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.5199 - accuracy: 0.7466 - val_loss: 0.4754 - val_accuracy: 0.7773\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.5126 - accuracy: 0.7519 - val_loss: 0.4737 - val_accuracy: 0.7790\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5151 - accuracy: 0.7474 - val_loss: 0.4792 - val_accuracy: 0.7766\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5037 - accuracy: 0.7608 - val_loss: 0.4719 - val_accuracy: 0.7898\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5024 - accuracy: 0.7608 - val_loss: 0.4620 - val_accuracy: 0.7898\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4955 - accuracy: 0.7691 - val_loss: 0.4579 - val_accuracy: 0.7971\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4936 - accuracy: 0.7746 - val_loss: 0.4846 - val_accuracy: 0.7790\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4925 - accuracy: 0.7734 - val_loss: 0.4634 - val_accuracy: 0.7856\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4863 - accuracy: 0.7725 - val_loss: 0.4365 - val_accuracy: 0.7936\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4840 - accuracy: 0.7737 - val_loss: 0.4299 - val_accuracy: 0.7933\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4769 - accuracy: 0.7779 - val_loss: 0.4275 - val_accuracy: 0.8044\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4772 - accuracy: 0.7792 - val_loss: 0.4331 - val_accuracy: 0.8075\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4745 - accuracy: 0.7802 - val_loss: 0.4188 - val_accuracy: 0.8026\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4706 - accuracy: 0.7836 - val_loss: 0.4205 - val_accuracy: 0.8072\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4684 - accuracy: 0.7802 - val_loss: 0.4246 - val_accuracy: 0.8065\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4680 - accuracy: 0.7793 - val_loss: 0.4259 - val_accuracy: 0.8085\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4598 - accuracy: 0.7837 - val_loss: 0.4161 - val_accuracy: 0.8106\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4656 - accuracy: 0.7808 - val_loss: 0.4077 - val_accuracy: 0.8120\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4631 - accuracy: 0.7836 - val_loss: 0.4053 - val_accuracy: 0.8127\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4602 - accuracy: 0.7872 - val_loss: 0.4157 - val_accuracy: 0.7933\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4585 - accuracy: 0.7867 - val_loss: 0.4086 - val_accuracy: 0.8134\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4493 - accuracy: 0.7916 - val_loss: 0.4072 - val_accuracy: 0.8127\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4445 - accuracy: 0.7909 - val_loss: 0.3990 - val_accuracy: 0.8169\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4504 - accuracy: 0.7936 - val_loss: 0.4027 - val_accuracy: 0.8158\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4493 - accuracy: 0.7930 - val_loss: 0.3929 - val_accuracy: 0.8162\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4476 - accuracy: 0.7976 - val_loss: 0.4081 - val_accuracy: 0.8204\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4422 - accuracy: 0.7973 - val_loss: 0.3992 - val_accuracy: 0.8179\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4444 - accuracy: 0.7980 - val_loss: 0.4126 - val_accuracy: 0.8016\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4420 - accuracy: 0.7955 - val_loss: 0.4038 - val_accuracy: 0.8183\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4405 - accuracy: 0.7942 - val_loss: 0.3986 - val_accuracy: 0.8155\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4414 - accuracy: 0.7989 - val_loss: 0.3888 - val_accuracy: 0.8197\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4374 - accuracy: 0.7968 - val_loss: 0.3942 - val_accuracy: 0.8235\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4302 - accuracy: 0.7976 - val_loss: 0.3889 - val_accuracy: 0.8228\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4376 - accuracy: 0.8004 - val_loss: 0.3889 - val_accuracy: 0.8284\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4288 - accuracy: 0.8048 - val_loss: 0.3867 - val_accuracy: 0.8284\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4302 - accuracy: 0.8023 - val_loss: 0.3894 - val_accuracy: 0.8325\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4334 - accuracy: 0.8026 - val_loss: 0.3794 - val_accuracy: 0.8311\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4267 - accuracy: 0.8053 - val_loss: 0.3815 - val_accuracy: 0.8235\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4262 - accuracy: 0.8058 - val_loss: 0.3825 - val_accuracy: 0.8214\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4207 - accuracy: 0.8097 - val_loss: 0.3784 - val_accuracy: 0.8311\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4265 - accuracy: 0.8082 - val_loss: 0.3804 - val_accuracy: 0.8294\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4256 - accuracy: 0.8069 - val_loss: 0.3797 - val_accuracy: 0.8256\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.3928 - val_accuracy: 0.8263\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4208 - accuracy: 0.8072 - val_loss: 0.3826 - val_accuracy: 0.8277\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4196 - accuracy: 0.8076 - val_loss: 0.3774 - val_accuracy: 0.8308\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4200 - accuracy: 0.8079 - val_loss: 0.3799 - val_accuracy: 0.8273\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4221 - accuracy: 0.8066 - val_loss: 0.3837 - val_accuracy: 0.8339\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4189 - accuracy: 0.8121 - val_loss: 0.3694 - val_accuracy: 0.8336\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4176 - accuracy: 0.8094 - val_loss: 0.3762 - val_accuracy: 0.8343\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4171 - accuracy: 0.8061 - val_loss: 0.3713 - val_accuracy: 0.8356\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4115 - accuracy: 0.8144 - val_loss: 0.3794 - val_accuracy: 0.8277\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4106 - accuracy: 0.8152 - val_loss: 0.3665 - val_accuracy: 0.8304\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4142 - accuracy: 0.8091 - val_loss: 0.3928 - val_accuracy: 0.8318\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4103 - accuracy: 0.8106 - val_loss: 0.3733 - val_accuracy: 0.8322\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4099 - accuracy: 0.8163 - val_loss: 0.3734 - val_accuracy: 0.8325\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.3665 - val_accuracy: 0.8360\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4178 - accuracy: 0.8121 - val_loss: 0.3721 - val_accuracy: 0.8370\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4091 - accuracy: 0.8158 - val_loss: 0.3657 - val_accuracy: 0.8374\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4105 - accuracy: 0.8121 - val_loss: 0.3629 - val_accuracy: 0.8402\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4163 - accuracy: 0.8100 - val_loss: 0.3788 - val_accuracy: 0.8346\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4090 - accuracy: 0.8127 - val_loss: 0.3670 - val_accuracy: 0.8429\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4099 - accuracy: 0.8148 - val_loss: 0.3700 - val_accuracy: 0.8339\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4080 - accuracy: 0.8134 - val_loss: 0.3786 - val_accuracy: 0.8336\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4100 - accuracy: 0.8198 - val_loss: 0.3760 - val_accuracy: 0.8294\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4048 - accuracy: 0.8185 - val_loss: 0.3689 - val_accuracy: 0.8464\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4030 - accuracy: 0.8200 - val_loss: 0.3635 - val_accuracy: 0.8412\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4004 - accuracy: 0.8188 - val_loss: 0.3582 - val_accuracy: 0.8419\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3979 - accuracy: 0.8208 - val_loss: 0.3533 - val_accuracy: 0.8423\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3952 - accuracy: 0.8251 - val_loss: 0.3686 - val_accuracy: 0.8370\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4062 - accuracy: 0.8178 - val_loss: 0.3799 - val_accuracy: 0.8329\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.3583 - val_accuracy: 0.8381\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4045 - accuracy: 0.8173 - val_loss: 0.3562 - val_accuracy: 0.8388\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3957 - accuracy: 0.8258 - val_loss: 0.3540 - val_accuracy: 0.8370\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4088 - accuracy: 0.8211 - val_loss: 0.3637 - val_accuracy: 0.8381\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4014 - accuracy: 0.8207 - val_loss: 0.3710 - val_accuracy: 0.8436\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4025 - accuracy: 0.8173 - val_loss: 0.3635 - val_accuracy: 0.8443\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3998 - accuracy: 0.8220 - val_loss: 0.3581 - val_accuracy: 0.8429\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4036 - accuracy: 0.8188 - val_loss: 0.3622 - val_accuracy: 0.8429\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4020 - accuracy: 0.8194 - val_loss: 0.3594 - val_accuracy: 0.8433\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4101 - accuracy: 0.8175 - val_loss: 0.3608 - val_accuracy: 0.8402\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3950 - accuracy: 0.8206 - val_loss: 0.3680 - val_accuracy: 0.8315\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3961 - accuracy: 0.8263 - val_loss: 0.3557 - val_accuracy: 0.8461\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4079 - accuracy: 0.8192 - val_loss: 0.3549 - val_accuracy: 0.8443\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4052 - accuracy: 0.8181 - val_loss: 0.3636 - val_accuracy: 0.8405\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4002 - accuracy: 0.8214 - val_loss: 0.3612 - val_accuracy: 0.8398\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3962 - accuracy: 0.8230 - val_loss: 0.3520 - val_accuracy: 0.8433\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3942 - accuracy: 0.8230 - val_loss: 0.3607 - val_accuracy: 0.8398\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4001 - accuracy: 0.8242 - val_loss: 0.3733 - val_accuracy: 0.8468\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4000 - accuracy: 0.8230 - val_loss: 0.3746 - val_accuracy: 0.8436\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3968 - accuracy: 0.8254 - val_loss: 0.3515 - val_accuracy: 0.8527\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3979 - accuracy: 0.8231 - val_loss: 0.3620 - val_accuracy: 0.8468\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3976 - accuracy: 0.8225 - val_loss: 0.3594 - val_accuracy: 0.8461\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3932 - accuracy: 0.8270 - val_loss: 0.3569 - val_accuracy: 0.8398\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3903 - accuracy: 0.8279 - val_loss: 0.3520 - val_accuracy: 0.8471\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3878 - accuracy: 0.8285 - val_loss: 0.3497 - val_accuracy: 0.8450\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3940 - accuracy: 0.8241 - val_loss: 0.3484 - val_accuracy: 0.8499\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3844 - accuracy: 0.8327 - val_loss: 0.3547 - val_accuracy: 0.8482\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3798 - accuracy: 0.8296 - val_loss: 0.3532 - val_accuracy: 0.8443\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3857 - accuracy: 0.8267 - val_loss: 0.3514 - val_accuracy: 0.8447\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3895 - accuracy: 0.8260 - val_loss: 0.3564 - val_accuracy: 0.8468\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3837 - accuracy: 0.8286 - val_loss: 0.3598 - val_accuracy: 0.8464\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3849 - accuracy: 0.8298 - val_loss: 0.3564 - val_accuracy: 0.8482\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3886 - accuracy: 0.8267 - val_loss: 0.3602 - val_accuracy: 0.8471\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3892 - accuracy: 0.8320 - val_loss: 0.3747 - val_accuracy: 0.8304\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3898 - accuracy: 0.8255 - val_loss: 0.3525 - val_accuracy: 0.8485\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3867 - accuracy: 0.8257 - val_loss: 0.3587 - val_accuracy: 0.8440\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3860 - accuracy: 0.8255 - val_loss: 0.3481 - val_accuracy: 0.8447\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3817 - accuracy: 0.8259 - val_loss: 0.3585 - val_accuracy: 0.8429\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3893 - accuracy: 0.8296 - val_loss: 0.3516 - val_accuracy: 0.8457\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3916 - accuracy: 0.8254 - val_loss: 0.3539 - val_accuracy: 0.8443\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3848 - accuracy: 0.8290 - val_loss: 0.3566 - val_accuracy: 0.8405\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3848 - accuracy: 0.8286 - val_loss: 0.3538 - val_accuracy: 0.8440\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3816 - accuracy: 0.8290 - val_loss: 0.3555 - val_accuracy: 0.8436\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3908 - accuracy: 0.8275 - val_loss: 0.3540 - val_accuracy: 0.8464\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3862 - accuracy: 0.8281 - val_loss: 0.3559 - val_accuracy: 0.8429\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3936 - accuracy: 0.8241 - val_loss: 0.3622 - val_accuracy: 0.8318\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3930 - accuracy: 0.8249 - val_loss: 0.3647 - val_accuracy: 0.8419\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3897 - accuracy: 0.8270 - val_loss: 0.3586 - val_accuracy: 0.8398\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3892 - accuracy: 0.8263 - val_loss: 0.3611 - val_accuracy: 0.8419\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3864 - accuracy: 0.8287 - val_loss: 0.3531 - val_accuracy: 0.8489\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3832 - accuracy: 0.8274 - val_loss: 0.4020 - val_accuracy: 0.8509\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3882 - accuracy: 0.8275 - val_loss: 0.3528 - val_accuracy: 0.8454\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3953 - accuracy: 0.8291 - val_loss: 0.3582 - val_accuracy: 0.8478\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3923 - accuracy: 0.8287 - val_loss: 0.3596 - val_accuracy: 0.8381\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3927 - accuracy: 0.8233 - val_loss: 0.3593 - val_accuracy: 0.8402\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3991 - accuracy: 0.8251 - val_loss: 0.3530 - val_accuracy: 0.8513\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3874 - accuracy: 0.8283 - val_loss: 0.3577 - val_accuracy: 0.8447\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3860 - accuracy: 0.8299 - val_loss: 0.3521 - val_accuracy: 0.8482\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3852 - accuracy: 0.8276 - val_loss: 0.3521 - val_accuracy: 0.8447\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3844 - accuracy: 0.8280 - val_loss: 0.3544 - val_accuracy: 0.8423\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3874 - accuracy: 0.8327 - val_loss: 0.3468 - val_accuracy: 0.8426\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3848 - accuracy: 0.8260 - val_loss: 0.3656 - val_accuracy: 0.8273\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4029 - accuracy: 0.8283 - val_loss: 0.3597 - val_accuracy: 0.8405\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3893 - accuracy: 0.8245 - val_loss: 0.3613 - val_accuracy: 0.8402\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3904 - accuracy: 0.8275 - val_loss: 0.3492 - val_accuracy: 0.8440\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3784 - accuracy: 0.8327 - val_loss: 0.3496 - val_accuracy: 0.8447\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3933 - accuracy: 0.8230 - val_loss: 0.3581 - val_accuracy: 0.8374\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3874 - accuracy: 0.8267 - val_loss: 0.3577 - val_accuracy: 0.8374\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3818 - accuracy: 0.8287 - val_loss: 0.3567 - val_accuracy: 0.8416\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3844 - accuracy: 0.8278 - val_loss: 0.3533 - val_accuracy: 0.8436\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3791 - accuracy: 0.8316 - val_loss: 0.3462 - val_accuracy: 0.8492\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3810 - accuracy: 0.8289 - val_loss: 0.3500 - val_accuracy: 0.8447\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3834 - accuracy: 0.8289 - val_loss: 0.3470 - val_accuracy: 0.8489\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3786 - accuracy: 0.8333 - val_loss: 0.3503 - val_accuracy: 0.8416\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3961 - accuracy: 0.8244 - val_loss: 0.3492 - val_accuracy: 0.8423\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3808 - accuracy: 0.8293 - val_loss: 0.3503 - val_accuracy: 0.8509\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3810 - accuracy: 0.8291 - val_loss: 0.3567 - val_accuracy: 0.8440\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3784 - accuracy: 0.8309 - val_loss: 0.3518 - val_accuracy: 0.8475\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3798 - accuracy: 0.8305 - val_loss: 0.3538 - val_accuracy: 0.8412\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3741 - accuracy: 0.8329 - val_loss: 0.3510 - val_accuracy: 0.8416\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3681 - accuracy: 0.8359 - val_loss: 0.3519 - val_accuracy: 0.8416\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3872 - accuracy: 0.8353 - val_loss: 0.3606 - val_accuracy: 0.8402\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3976 - accuracy: 0.8310 - val_loss: 0.3574 - val_accuracy: 0.8377\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3864 - accuracy: 0.8286 - val_loss: 0.3489 - val_accuracy: 0.8443\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3787 - accuracy: 0.8317 - val_loss: 0.3543 - val_accuracy: 0.8405\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3808 - accuracy: 0.8274 - val_loss: 0.3553 - val_accuracy: 0.8464\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3990 - accuracy: 0.8259 - val_loss: 0.3572 - val_accuracy: 0.8419\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3821 - accuracy: 0.8284 - val_loss: 0.3465 - val_accuracy: 0.8461\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3844 - accuracy: 0.8271 - val_loss: 0.3503 - val_accuracy: 0.8485\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3729 - accuracy: 0.8386 - val_loss: 0.3426 - val_accuracy: 0.8492\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3857 - accuracy: 0.8287 - val_loss: 0.3438 - val_accuracy: 0.8513\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4395 - accuracy: 0.8261 - val_loss: 0.3689 - val_accuracy: 0.8423\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3907 - accuracy: 0.8307 - val_loss: 0.3519 - val_accuracy: 0.8454\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3882 - accuracy: 0.8290 - val_loss: 0.3631 - val_accuracy: 0.8388\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3805 - accuracy: 0.8352 - val_loss: 0.3538 - val_accuracy: 0.8475\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3876 - accuracy: 0.8333 - val_loss: 0.3568 - val_accuracy: 0.8478\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3865 - accuracy: 0.8290 - val_loss: 0.3575 - val_accuracy: 0.8471\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3958 - accuracy: 0.8255 - val_loss: 0.3545 - val_accuracy: 0.8464\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3824 - accuracy: 0.8276 - val_loss: 0.3634 - val_accuracy: 0.8318\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3859 - accuracy: 0.8267 - val_loss: 0.3473 - val_accuracy: 0.8495\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5864 - accuracy: 0.8244 - val_loss: 0.3855 - val_accuracy: 0.8238\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3986 - accuracy: 0.8242 - val_loss: 0.3549 - val_accuracy: 0.8461\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3990 - accuracy: 0.8218 - val_loss: 0.3469 - val_accuracy: 0.8468\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3873 - accuracy: 0.8306 - val_loss: 0.3580 - val_accuracy: 0.8471\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3994 - accuracy: 0.8259 - val_loss: 0.3629 - val_accuracy: 0.8353\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3826 - accuracy: 0.8274 - val_loss: 0.3560 - val_accuracy: 0.8398\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3855 - accuracy: 0.8296 - val_loss: 0.3566 - val_accuracy: 0.8464\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4148 - accuracy: 0.8287 - val_loss: 0.3761 - val_accuracy: 0.8256\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3913 - accuracy: 0.8233 - val_loss: 0.3570 - val_accuracy: 0.8419\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3853 - accuracy: 0.8291 - val_loss: 0.3634 - val_accuracy: 0.8471\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3864 - accuracy: 0.8296 - val_loss: 0.3537 - val_accuracy: 0.8447\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3905 - accuracy: 0.8254 - val_loss: 0.3626 - val_accuracy: 0.8374\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3863 - accuracy: 0.8300 - val_loss: 0.3513 - val_accuracy: 0.8443\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4010 - accuracy: 0.8264 - val_loss: 0.3485 - val_accuracy: 0.8461\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3852 - accuracy: 0.8305 - val_loss: 0.3557 - val_accuracy: 0.8395\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3792 - accuracy: 0.8307 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3795 - accuracy: 0.8330 - val_loss: 0.3588 - val_accuracy: 0.8391\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4046 - accuracy: 0.8269 - val_loss: 0.3529 - val_accuracy: 0.8395\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3837 - accuracy: 0.8292 - val_loss: 0.3621 - val_accuracy: 0.8416\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3794 - accuracy: 0.8316 - val_loss: 0.3548 - val_accuracy: 0.8409\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3777 - accuracy: 0.8334 - val_loss: 0.3444 - val_accuracy: 0.8423\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3789 - accuracy: 0.8307 - val_loss: 0.3570 - val_accuracy: 0.8367\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3768 - accuracy: 0.8327 - val_loss: 0.3537 - val_accuracy: 0.8426\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3772 - accuracy: 0.8327 - val_loss: 0.3662 - val_accuracy: 0.8339\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3845 - accuracy: 0.8298 - val_loss: 0.3572 - val_accuracy: 0.8367\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3838 - accuracy: 0.8319 - val_loss: 0.3649 - val_accuracy: 0.8429\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3830 - accuracy: 0.8286 - val_loss: 0.3664 - val_accuracy: 0.8343\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3769 - accuracy: 0.8320 - val_loss: 0.3593 - val_accuracy: 0.8391\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3753 - accuracy: 0.8356 - val_loss: 0.3516 - val_accuracy: 0.8429\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3852 - accuracy: 0.8327 - val_loss: 0.3626 - val_accuracy: 0.8360\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3782 - accuracy: 0.8341 - val_loss: 0.3549 - val_accuracy: 0.8440\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3715 - accuracy: 0.8380 - val_loss: 0.3391 - val_accuracy: 0.8492\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3684 - accuracy: 0.8353 - val_loss: 0.3516 - val_accuracy: 0.8381\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3722 - accuracy: 0.8340 - val_loss: 0.3550 - val_accuracy: 0.8336\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3707 - accuracy: 0.8341 - val_loss: 0.3458 - val_accuracy: 0.8419\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3738 - accuracy: 0.8337 - val_loss: 0.3580 - val_accuracy: 0.8402\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3768 - accuracy: 0.8350 - val_loss: 0.3558 - val_accuracy: 0.8440\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3676 - accuracy: 0.8362 - val_loss: 0.3533 - val_accuracy: 0.8450\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3771 - accuracy: 0.8352 - val_loss: 0.3533 - val_accuracy: 0.8433\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3733 - accuracy: 0.8369 - val_loss: 0.3546 - val_accuracy: 0.8402\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4531 - accuracy: 0.8307 - val_loss: 0.3491 - val_accuracy: 0.8409\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3730 - accuracy: 0.8326 - val_loss: 0.3480 - val_accuracy: 0.8426\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3740 - accuracy: 0.8310 - val_loss: 0.3427 - val_accuracy: 0.8454\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3837 - accuracy: 0.8357 - val_loss: 0.3575 - val_accuracy: 0.8370\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3778 - accuracy: 0.8318 - val_loss: 0.3540 - val_accuracy: 0.8395\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3761 - accuracy: 0.8325 - val_loss: 0.3699 - val_accuracy: 0.8297\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3769 - accuracy: 0.8318 - val_loss: 0.3755 - val_accuracy: 0.8315\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3725 - accuracy: 0.8343 - val_loss: 0.3515 - val_accuracy: 0.8464\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3734 - accuracy: 0.8333 - val_loss: 0.3468 - val_accuracy: 0.8485\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3824 - accuracy: 0.8295 - val_loss: 0.3661 - val_accuracy: 0.8343\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3876 - accuracy: 0.8316 - val_loss: 0.3622 - val_accuracy: 0.8381\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3796 - accuracy: 0.8328 - val_loss: 0.3554 - val_accuracy: 0.8443\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3735 - accuracy: 0.8359 - val_loss: 0.3468 - val_accuracy: 0.8450\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3735 - accuracy: 0.8327 - val_loss: 0.3407 - val_accuracy: 0.8499\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3738 - accuracy: 0.8361 - val_loss: 0.3461 - val_accuracy: 0.8485\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3654 - accuracy: 0.8366 - val_loss: 0.3434 - val_accuracy: 0.8468\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3695 - accuracy: 0.8331 - val_loss: 0.3476 - val_accuracy: 0.8457\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3899 - accuracy: 0.8360 - val_loss: 0.3642 - val_accuracy: 0.8325\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3698 - accuracy: 0.8342 - val_loss: 0.3471 - val_accuracy: 0.8468\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3648 - accuracy: 0.8392 - val_loss: 0.3540 - val_accuracy: 0.8409\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3646 - accuracy: 0.8360 - val_loss: 0.3639 - val_accuracy: 0.8290\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3680 - accuracy: 0.8380 - val_loss: 0.3456 - val_accuracy: 0.8471\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3929 - accuracy: 0.8317 - val_loss: 0.3679 - val_accuracy: 0.8336\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3808 - accuracy: 0.8299 - val_loss: 0.3590 - val_accuracy: 0.8311\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3722 - accuracy: 0.8377 - val_loss: 0.3472 - val_accuracy: 0.8429\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3738 - accuracy: 0.8333 - val_loss: 0.3583 - val_accuracy: 0.8426\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3745 - accuracy: 0.8360 - val_loss: 0.3529 - val_accuracy: 0.8461\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3697 - accuracy: 0.8380 - val_loss: 0.3576 - val_accuracy: 0.8325\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3752 - accuracy: 0.8319 - val_loss: 0.3521 - val_accuracy: 0.8416\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3842 - accuracy: 0.8306 - val_loss: 0.3539 - val_accuracy: 0.8374\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3682 - accuracy: 0.8326 - val_loss: 0.3693 - val_accuracy: 0.8384\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3703 - accuracy: 0.8400 - val_loss: 0.3615 - val_accuracy: 0.8381\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3897 - accuracy: 0.8366 - val_loss: 0.3655 - val_accuracy: 0.8228\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3759 - accuracy: 0.8353 - val_loss: 0.3540 - val_accuracy: 0.8377\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3742 - accuracy: 0.8349 - val_loss: 0.3522 - val_accuracy: 0.8426\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3744 - accuracy: 0.8364 - val_loss: 0.3504 - val_accuracy: 0.8454\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3751 - accuracy: 0.8357 - val_loss: 0.3539 - val_accuracy: 0.8464\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3667 - accuracy: 0.8389 - val_loss: 0.3508 - val_accuracy: 0.8468\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3901 - accuracy: 0.8333 - val_loss: 0.3582 - val_accuracy: 0.8398\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3659 - accuracy: 0.8366 - val_loss: 0.3521 - val_accuracy: 0.8426\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3697 - accuracy: 0.8339 - val_loss: 0.3583 - val_accuracy: 0.8423\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3656 - accuracy: 0.8407 - val_loss: 0.3629 - val_accuracy: 0.8287\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3744 - accuracy: 0.8371 - val_loss: 0.3482 - val_accuracy: 0.8457\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3778 - accuracy: 0.8356 - val_loss: 0.3526 - val_accuracy: 0.8419\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3727 - accuracy: 0.8347 - val_loss: 0.3592 - val_accuracy: 0.8388\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3843 - accuracy: 0.8316 - val_loss: 0.3551 - val_accuracy: 0.8416\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3763 - accuracy: 0.8374 - val_loss: 0.3554 - val_accuracy: 0.8447\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3728 - accuracy: 0.8350 - val_loss: 0.3537 - val_accuracy: 0.8429\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3888 - accuracy: 0.8363 - val_loss: 0.3583 - val_accuracy: 0.8363\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3825 - accuracy: 0.8287 - val_loss: 0.3562 - val_accuracy: 0.8429\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3678 - accuracy: 0.8355 - val_loss: 0.3446 - val_accuracy: 0.8468\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3721 - accuracy: 0.8335 - val_loss: 0.3694 - val_accuracy: 0.8176\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3707 - accuracy: 0.8372 - val_loss: 0.3474 - val_accuracy: 0.8436\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3934 - accuracy: 0.8332 - val_loss: 0.3739 - val_accuracy: 0.8242\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3747 - accuracy: 0.8376 - val_loss: 0.3561 - val_accuracy: 0.8419\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3740 - accuracy: 0.8313 - val_loss: 0.3465 - val_accuracy: 0.8475\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3665 - accuracy: 0.8398 - val_loss: 0.3466 - val_accuracy: 0.8464\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3737 - accuracy: 0.8360 - val_loss: 0.3584 - val_accuracy: 0.8416\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3653 - accuracy: 0.8405 - val_loss: 0.3647 - val_accuracy: 0.8336\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3699 - accuracy: 0.8366 - val_loss: 0.3471 - val_accuracy: 0.8419\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3860 - accuracy: 0.8321 - val_loss: 0.3492 - val_accuracy: 0.8398\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3669 - accuracy: 0.8376 - val_loss: 0.3557 - val_accuracy: 0.8363\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3683 - accuracy: 0.8393 - val_loss: 0.3439 - val_accuracy: 0.8395\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3683 - accuracy: 0.8380 - val_loss: 0.3482 - val_accuracy: 0.8416\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3612 - accuracy: 0.8422 - val_loss: 0.3559 - val_accuracy: 0.8416\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3977 - accuracy: 0.8297 - val_loss: 0.3734 - val_accuracy: 0.8290\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3866 - accuracy: 0.8293 - val_loss: 0.3605 - val_accuracy: 0.8367\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3733 - accuracy: 0.8316 - val_loss: 0.3527 - val_accuracy: 0.8416\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3794 - accuracy: 0.8317 - val_loss: 0.3660 - val_accuracy: 0.8343\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3759 - accuracy: 0.8322 - val_loss: 0.3645 - val_accuracy: 0.8294\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3830 - accuracy: 0.8388 - val_loss: 0.3560 - val_accuracy: 0.8356\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3941 - accuracy: 0.8292 - val_loss: 0.3601 - val_accuracy: 0.8374\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3837 - accuracy: 0.8303 - val_loss: 0.3650 - val_accuracy: 0.8395\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3744 - accuracy: 0.8354 - val_loss: 0.3526 - val_accuracy: 0.8388\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3951 - accuracy: 0.8320 - val_loss: 0.3832 - val_accuracy: 0.8304\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3823 - accuracy: 0.8295 - val_loss: 0.3599 - val_accuracy: 0.8363\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3690 - accuracy: 0.8376 - val_loss: 0.3551 - val_accuracy: 0.8402\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3773 - accuracy: 0.8327 - val_loss: 0.3569 - val_accuracy: 0.8395\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3612 - accuracy: 0.8388 - val_loss: 0.3493 - val_accuracy: 0.8391\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3810 - accuracy: 0.8340 - val_loss: 0.3652 - val_accuracy: 0.8329\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3790 - accuracy: 0.8315 - val_loss: 0.3645 - val_accuracy: 0.8297\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3740 - accuracy: 0.8342 - val_loss: 0.3597 - val_accuracy: 0.8339\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3775 - accuracy: 0.8328 - val_loss: 0.3520 - val_accuracy: 0.8489\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3716 - accuracy: 0.8345 - val_loss: 0.3509 - val_accuracy: 0.8489\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3780 - accuracy: 0.8347 - val_loss: 0.3543 - val_accuracy: 0.8471\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3873 - accuracy: 0.8317 - val_loss: 0.3631 - val_accuracy: 0.8339\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3793 - accuracy: 0.8315 - val_loss: 0.3617 - val_accuracy: 0.8322\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3704 - accuracy: 0.8346 - val_loss: 0.3550 - val_accuracy: 0.8440\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3825 - accuracy: 0.8326 - val_loss: 0.3555 - val_accuracy: 0.8440\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3857 - accuracy: 0.8305 - val_loss: 0.3541 - val_accuracy: 0.8381\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3862 - accuracy: 0.8307 - val_loss: 0.3644 - val_accuracy: 0.8370\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3811 - accuracy: 0.8313 - val_loss: 0.3685 - val_accuracy: 0.8332\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3686 - accuracy: 0.8370 - val_loss: 0.3486 - val_accuracy: 0.8447\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3836 - accuracy: 0.8388 - val_loss: 0.3441 - val_accuracy: 0.8468\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3750 - accuracy: 0.8350 - val_loss: 0.3749 - val_accuracy: 0.8363\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3727 - accuracy: 0.8375 - val_loss: 0.3638 - val_accuracy: 0.8419\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5118 - accuracy: 0.8308 - val_loss: 0.3599 - val_accuracy: 0.8367\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3855 - accuracy: 0.8325 - val_loss: 0.3560 - val_accuracy: 0.8367\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3808 - accuracy: 0.8306 - val_loss: 0.3556 - val_accuracy: 0.8395\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3682 - accuracy: 0.8333 - val_loss: 0.3510 - val_accuracy: 0.8429\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3741 - accuracy: 0.8354 - val_loss: 0.3610 - val_accuracy: 0.8374\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3634 - accuracy: 0.8380 - val_loss: 0.3477 - val_accuracy: 0.8450\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3831 - accuracy: 0.8372 - val_loss: 0.3576 - val_accuracy: 0.8329\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3712 - accuracy: 0.8371 - val_loss: 0.3602 - val_accuracy: 0.8395\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3660 - accuracy: 0.8413 - val_loss: 0.3488 - val_accuracy: 0.8409\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3848 - accuracy: 0.8333 - val_loss: 0.3552 - val_accuracy: 0.8409\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3938 - accuracy: 0.8333 - val_loss: 0.3579 - val_accuracy: 0.8374\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3773 - accuracy: 0.8341 - val_loss: 0.3601 - val_accuracy: 0.8332\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3727 - accuracy: 0.8350 - val_loss: 0.3564 - val_accuracy: 0.8329\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3731 - accuracy: 0.8366 - val_loss: 0.3507 - val_accuracy: 0.8398\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3671 - accuracy: 0.8409 - val_loss: 0.3539 - val_accuracy: 0.8339\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3728 - accuracy: 0.8375 - val_loss: 0.3584 - val_accuracy: 0.8350\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3690 - accuracy: 0.8400 - val_loss: 0.3501 - val_accuracy: 0.8443\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3695 - accuracy: 0.8380 - val_loss: 0.3439 - val_accuracy: 0.8482\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.3651 - accuracy: 0.8404 - val_loss: 0.3452 - val_accuracy: 0.8412\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.3942 - accuracy: 0.8307 - val_loss: 0.3645 - val_accuracy: 0.8318\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.3458 - val_accuracy: 0.8495\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3855 - accuracy: 0.8311 - val_loss: 0.3545 - val_accuracy: 0.8423\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3742 - accuracy: 0.8414 - val_loss: 0.3540 - val_accuracy: 0.8443\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3724 - accuracy: 0.8389 - val_loss: 0.3423 - val_accuracy: 0.8475\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3681 - accuracy: 0.8409 - val_loss: 0.3467 - val_accuracy: 0.8478\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3643 - accuracy: 0.8418 - val_loss: 0.3458 - val_accuracy: 0.8461\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3712 - accuracy: 0.8353 - val_loss: 0.3516 - val_accuracy: 0.8440\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3640 - accuracy: 0.8398 - val_loss: 0.3416 - val_accuracy: 0.8461\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3771 - accuracy: 0.8369 - val_loss: 0.3448 - val_accuracy: 0.8450\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3738 - accuracy: 0.8402 - val_loss: 0.3488 - val_accuracy: 0.8478\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3733 - accuracy: 0.8389 - val_loss: 0.3454 - val_accuracy: 0.8450\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3755 - accuracy: 0.8356 - val_loss: 0.3555 - val_accuracy: 0.8350\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3643 - accuracy: 0.8390 - val_loss: 0.3539 - val_accuracy: 0.8332\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3675 - accuracy: 0.8414 - val_loss: 0.3453 - val_accuracy: 0.8475\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3655 - accuracy: 0.8389 - val_loss: 0.3456 - val_accuracy: 0.8475\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4185 - accuracy: 0.8320 - val_loss: 0.3570 - val_accuracy: 0.8370\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3706 - accuracy: 0.8366 - val_loss: 0.3642 - val_accuracy: 0.8370\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3795 - accuracy: 0.8346 - val_loss: 0.3573 - val_accuracy: 0.8478\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3866 - accuracy: 0.8357 - val_loss: 0.3637 - val_accuracy: 0.8395\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3757 - accuracy: 0.8330 - val_loss: 0.3602 - val_accuracy: 0.8398\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3731 - accuracy: 0.8403 - val_loss: 0.3546 - val_accuracy: 0.8384\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3648 - accuracy: 0.8394 - val_loss: 0.3586 - val_accuracy: 0.8304\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3829 - accuracy: 0.8381 - val_loss: 0.3592 - val_accuracy: 0.8416\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3707 - accuracy: 0.8391 - val_loss: 0.3466 - val_accuracy: 0.8468\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3615 - accuracy: 0.8388 - val_loss: 0.3592 - val_accuracy: 0.8360\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3756 - accuracy: 0.8393 - val_loss: 0.3463 - val_accuracy: 0.8482\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3667 - accuracy: 0.8364 - val_loss: 0.3514 - val_accuracy: 0.8388\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3630 - accuracy: 0.8444 - val_loss: 0.3572 - val_accuracy: 0.8423\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3578 - accuracy: 0.8442 - val_loss: 0.3498 - val_accuracy: 0.8495\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3618 - accuracy: 0.8435 - val_loss: 0.3553 - val_accuracy: 0.8360\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3699 - accuracy: 0.8345 - val_loss: 0.3569 - val_accuracy: 0.8311\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3675 - accuracy: 0.8396 - val_loss: 0.3492 - val_accuracy: 0.8492\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3662 - accuracy: 0.8393 - val_loss: 0.3516 - val_accuracy: 0.8464\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3759 - accuracy: 0.8362 - val_loss: 0.3493 - val_accuracy: 0.8443\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4082 - accuracy: 0.8292 - val_loss: 0.3629 - val_accuracy: 0.8398\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3878 - accuracy: 0.8267 - val_loss: 0.3554 - val_accuracy: 0.8412\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3728 - accuracy: 0.8401 - val_loss: 0.3591 - val_accuracy: 0.8304\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3686 - accuracy: 0.8382 - val_loss: 0.3595 - val_accuracy: 0.8332\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3646 - accuracy: 0.8409 - val_loss: 0.3573 - val_accuracy: 0.8353\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3669 - accuracy: 0.8386 - val_loss: 0.3384 - val_accuracy: 0.8551\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3588 - accuracy: 0.8434 - val_loss: 0.3486 - val_accuracy: 0.8541\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3759 - accuracy: 0.8395 - val_loss: 0.3455 - val_accuracy: 0.8534\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3590 - accuracy: 0.8441 - val_loss: 0.3412 - val_accuracy: 0.8541\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3558 - accuracy: 0.8462 - val_loss: 0.3566 - val_accuracy: 0.8436\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3561 - accuracy: 0.8432 - val_loss: 0.3453 - val_accuracy: 0.8412\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.3601 - accuracy: 0.8423 - val_loss: 0.3563 - val_accuracy: 0.8464\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3628 - accuracy: 0.8397 - val_loss: 0.3496 - val_accuracy: 0.8489\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3656 - accuracy: 0.8409 - val_loss: 0.3409 - val_accuracy: 0.8572\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3621 - accuracy: 0.8396 - val_loss: 0.3540 - val_accuracy: 0.8423\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3621 - accuracy: 0.8400 - val_loss: 0.3486 - val_accuracy: 0.8436\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3592 - accuracy: 0.8419 - val_loss: 0.3415 - val_accuracy: 0.8530\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3786 - accuracy: 0.8402 - val_loss: 0.3557 - val_accuracy: 0.8377\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3739 - accuracy: 0.8374 - val_loss: 0.3472 - val_accuracy: 0.8478\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3670 - accuracy: 0.8360 - val_loss: 0.3541 - val_accuracy: 0.8447\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3697 - accuracy: 0.8389 - val_loss: 0.3574 - val_accuracy: 0.8391\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3696 - accuracy: 0.8393 - val_loss: 0.3585 - val_accuracy: 0.8409\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3646 - accuracy: 0.8366 - val_loss: 0.3563 - val_accuracy: 0.8412\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3644 - accuracy: 0.8422 - val_loss: 0.3735 - val_accuracy: 0.8318\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3627 - accuracy: 0.8375 - val_loss: 0.3538 - val_accuracy: 0.8388\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3777 - accuracy: 0.8399 - val_loss: 0.3521 - val_accuracy: 0.8499\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3679 - accuracy: 0.8392 - val_loss: 0.3457 - val_accuracy: 0.8426\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3737 - accuracy: 0.8392 - val_loss: 0.3532 - val_accuracy: 0.8454\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3622 - accuracy: 0.8400 - val_loss: 0.3499 - val_accuracy: 0.8468\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3649 - accuracy: 0.8358 - val_loss: 0.3551 - val_accuracy: 0.8475\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3582 - accuracy: 0.8396 - val_loss: 0.3485 - val_accuracy: 0.8423\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3549 - accuracy: 0.8463 - val_loss: 0.3480 - val_accuracy: 0.8433\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3793 - accuracy: 0.8381 - val_loss: 0.3434 - val_accuracy: 0.8506\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3634 - accuracy: 0.8379 - val_loss: 0.3392 - val_accuracy: 0.8423\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3695 - accuracy: 0.8440 - val_loss: 0.3515 - val_accuracy: 0.8443\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3563 - accuracy: 0.8474 - val_loss: 0.3427 - val_accuracy: 0.8478\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3601 - accuracy: 0.8426 - val_loss: 0.3385 - val_accuracy: 0.8492\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3751 - accuracy: 0.8371 - val_loss: 0.3719 - val_accuracy: 0.8294\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3726 - accuracy: 0.8375 - val_loss: 0.3631 - val_accuracy: 0.8374\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3593 - accuracy: 0.8434 - val_loss: 0.3522 - val_accuracy: 0.8416\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3593 - accuracy: 0.8370 - val_loss: 0.3553 - val_accuracy: 0.8419\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3574 - accuracy: 0.8406 - val_loss: 0.3495 - val_accuracy: 0.8447\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3708 - accuracy: 0.8430 - val_loss: 0.3629 - val_accuracy: 0.8429\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3587 - accuracy: 0.8406 - val_loss: 0.3455 - val_accuracy: 0.8513\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3558 - accuracy: 0.8436 - val_loss: 0.3533 - val_accuracy: 0.8440\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3669 - accuracy: 0.8393 - val_loss: 0.3652 - val_accuracy: 0.8350\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3586 - accuracy: 0.8433 - val_loss: 0.3510 - val_accuracy: 0.8412\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3559 - accuracy: 0.8427 - val_loss: 0.3525 - val_accuracy: 0.8374\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3665 - accuracy: 0.8391 - val_loss: 0.3571 - val_accuracy: 0.8339\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3658 - accuracy: 0.8366 - val_loss: 0.3521 - val_accuracy: 0.8370\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3569 - accuracy: 0.8399 - val_loss: 0.3564 - val_accuracy: 0.8311\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3599 - accuracy: 0.8431 - val_loss: 0.3550 - val_accuracy: 0.8350\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3759 - accuracy: 0.8393 - val_loss: 0.3647 - val_accuracy: 0.8263\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3782 - accuracy: 0.8386 - val_loss: 0.3590 - val_accuracy: 0.8381\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3642 - accuracy: 0.8375 - val_loss: 0.3607 - val_accuracy: 0.8360\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3646 - accuracy: 0.8405 - val_loss: 0.3601 - val_accuracy: 0.8363\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3584 - accuracy: 0.8410 - val_loss: 0.3425 - val_accuracy: 0.8520\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3598 - accuracy: 0.8404 - val_loss: 0.3590 - val_accuracy: 0.8329\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3588 - accuracy: 0.8406 - val_loss: 0.3449 - val_accuracy: 0.8457\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3599 - accuracy: 0.8445 - val_loss: 0.3430 - val_accuracy: 0.8492\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3497 - accuracy: 0.8461 - val_loss: 0.3621 - val_accuracy: 0.8304\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3597 - accuracy: 0.8475 - val_loss: 0.3610 - val_accuracy: 0.8409\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3581 - accuracy: 0.8419 - val_loss: 0.3511 - val_accuracy: 0.8370\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3559 - accuracy: 0.8412 - val_loss: 0.3452 - val_accuracy: 0.8457\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3548 - accuracy: 0.8425 - val_loss: 0.3451 - val_accuracy: 0.8464\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3828 - accuracy: 0.8380 - val_loss: 0.3618 - val_accuracy: 0.8381\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3678 - accuracy: 0.8399 - val_loss: 0.3622 - val_accuracy: 0.8343\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3686 - accuracy: 0.8400 - val_loss: 0.3521 - val_accuracy: 0.8398\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3802 - accuracy: 0.8386 - val_loss: 0.3613 - val_accuracy: 0.8423\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3844 - accuracy: 0.8413 - val_loss: 0.3558 - val_accuracy: 0.8429\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3817 - accuracy: 0.8355 - val_loss: 0.3573 - val_accuracy: 0.8377\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3704 - accuracy: 0.8366 - val_loss: 0.3494 - val_accuracy: 0.8426\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3645 - accuracy: 0.8395 - val_loss: 0.3543 - val_accuracy: 0.8356\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3631 - accuracy: 0.8479 - val_loss: 0.3735 - val_accuracy: 0.8290\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3713 - accuracy: 0.8425 - val_loss: 0.3625 - val_accuracy: 0.8356\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3600 - accuracy: 0.8431 - val_loss: 0.3484 - val_accuracy: 0.8468\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3640 - accuracy: 0.8435 - val_loss: 0.3530 - val_accuracy: 0.8436\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3565 - accuracy: 0.8439 - val_loss: 0.3612 - val_accuracy: 0.8332\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3685 - accuracy: 0.8408 - val_loss: 0.3544 - val_accuracy: 0.8353\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3559 - accuracy: 0.8459 - val_loss: 0.3644 - val_accuracy: 0.8360\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3526 - accuracy: 0.8465 - val_loss: 0.3465 - val_accuracy: 0.8475\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3681 - accuracy: 0.8477 - val_loss: 0.3511 - val_accuracy: 0.8440\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3606 - accuracy: 0.8466 - val_loss: 0.3637 - val_accuracy: 0.8308\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3596 - accuracy: 0.8448 - val_loss: 0.3540 - val_accuracy: 0.8485\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3568 - accuracy: 0.8476 - val_loss: 0.3556 - val_accuracy: 0.8377\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3877 - accuracy: 0.8439 - val_loss: 0.3487 - val_accuracy: 0.8443\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3621 - accuracy: 0.8387 - val_loss: 0.3561 - val_accuracy: 0.8384\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3648 - accuracy: 0.8426 - val_loss: 0.3499 - val_accuracy: 0.8398\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3586 - accuracy: 0.8441 - val_loss: 0.3523 - val_accuracy: 0.8475\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3737 - accuracy: 0.8407 - val_loss: 0.3633 - val_accuracy: 0.8356\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3668 - accuracy: 0.8411 - val_loss: 0.3521 - val_accuracy: 0.8388\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3549 - accuracy: 0.8429 - val_loss: 0.3539 - val_accuracy: 0.8429\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3709 - accuracy: 0.8413 - val_loss: 0.3571 - val_accuracy: 0.8318\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3694 - accuracy: 0.8365 - val_loss: 0.3544 - val_accuracy: 0.8287\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3615 - accuracy: 0.8382 - val_loss: 0.3486 - val_accuracy: 0.8423\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3616 - accuracy: 0.8413 - val_loss: 0.3513 - val_accuracy: 0.8360\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3612 - accuracy: 0.8418 - val_loss: 0.3453 - val_accuracy: 0.8440\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3881 - accuracy: 0.8442 - val_loss: 0.3651 - val_accuracy: 0.8360\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3684 - accuracy: 0.8367 - val_loss: 0.3537 - val_accuracy: 0.8468\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3629 - accuracy: 0.8383 - val_loss: 0.3521 - val_accuracy: 0.8370\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3970 - accuracy: 0.8397 - val_loss: 0.3519 - val_accuracy: 0.8468\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3680 - accuracy: 0.8400 - val_loss: 0.3451 - val_accuracy: 0.8499\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3588 - accuracy: 0.8431 - val_loss: 0.3542 - val_accuracy: 0.8447\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3566 - accuracy: 0.8433 - val_loss: 0.3507 - val_accuracy: 0.8464\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3628 - accuracy: 0.8414 - val_loss: 0.3511 - val_accuracy: 0.8475\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3569 - accuracy: 0.8428 - val_loss: 0.3478 - val_accuracy: 0.8495\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3581 - accuracy: 0.8447 - val_loss: 0.3483 - val_accuracy: 0.8443\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3630 - accuracy: 0.8433 - val_loss: 0.3558 - val_accuracy: 0.8443\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3636 - accuracy: 0.8415 - val_loss: 0.3460 - val_accuracy: 0.8464\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3655 - accuracy: 0.8434 - val_loss: 0.3543 - val_accuracy: 0.8468\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3610 - accuracy: 0.8424 - val_loss: 0.3513 - val_accuracy: 0.8464\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3620 - accuracy: 0.8431 - val_loss: 0.3488 - val_accuracy: 0.8461\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3562 - accuracy: 0.8445 - val_loss: 0.3451 - val_accuracy: 0.8461\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4277 - accuracy: 0.8399 - val_loss: 0.3712 - val_accuracy: 0.8256\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3840 - accuracy: 0.8267 - val_loss: 0.3782 - val_accuracy: 0.8151\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3735 - accuracy: 0.8331 - val_loss: 0.3745 - val_accuracy: 0.8263\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3668 - accuracy: 0.8421 - val_loss: 0.3635 - val_accuracy: 0.8447\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3724 - accuracy: 0.8381 - val_loss: 0.3666 - val_accuracy: 0.8301\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3780 - accuracy: 0.8340 - val_loss: 0.3627 - val_accuracy: 0.8350\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3900 - accuracy: 0.8241 - val_loss: 0.3644 - val_accuracy: 0.8322\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3702 - accuracy: 0.8347 - val_loss: 0.3581 - val_accuracy: 0.8471\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3715 - accuracy: 0.8337 - val_loss: 0.3522 - val_accuracy: 0.8495\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3643 - accuracy: 0.8407 - val_loss: 0.3528 - val_accuracy: 0.8513\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3622 - accuracy: 0.8413 - val_loss: 0.3474 - val_accuracy: 0.8506\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3694 - accuracy: 0.8390 - val_loss: 0.3633 - val_accuracy: 0.8419\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3698 - accuracy: 0.8380 - val_loss: 0.3585 - val_accuracy: 0.8436\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4284 - accuracy: 0.8339 - val_loss: 0.3661 - val_accuracy: 0.8405\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3910 - accuracy: 0.8238 - val_loss: 0.3727 - val_accuracy: 0.8287\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3898 - accuracy: 0.8287 - val_loss: 0.3737 - val_accuracy: 0.8284\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3830 - accuracy: 0.8342 - val_loss: 0.3691 - val_accuracy: 0.8377\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3724 - accuracy: 0.8353 - val_loss: 0.3585 - val_accuracy: 0.8332\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3794 - accuracy: 0.8331 - val_loss: 0.3606 - val_accuracy: 0.8412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=4096*2, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_scaled, y_val_categorical)\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to apply a keras hyperperameters to find the perfect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dense\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameter\n",
    "\n",
    "def build_model():\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=128, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=256, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=512, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=1048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=4096, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=4096*2, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train_scaled,\n",
    "#     y_train_categorical,\n",
    "#     batch_size=128,\n",
    "#     epochs=500,\n",
    "#     shuffle=True,\n",
    "#     verbose=1,\n",
    "#     validation_data=(X_val_scaled, y_val_categorical)\n",
    "# )\n",
    "\n",
    "# history_df = pd.DataFrame(history.history)\n",
    "# history_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

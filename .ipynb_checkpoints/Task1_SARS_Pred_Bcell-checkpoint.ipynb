{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2T3T0</td>\n",
       "      <td>MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>SASFT</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0V2I4</td>\n",
       "      <td>MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>LCLKI</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75508</td>\n",
       "      <td>MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>AHRET</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O84462</td>\n",
       "      <td>MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>SNYDD</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00918</td>\n",
       "      <td>MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>DGTYR</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0            A2T3T0  MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...   \n",
       "1            F0V2I4  MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...   \n",
       "2            O75508  MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...   \n",
       "3            O84462  MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...   \n",
       "4            P00918  MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...   \n",
       "\n",
       "   start_position  end_position peptide_seq  chou_fasman  emini  \\\n",
       "0             161           165       SASFT        1.016  0.703   \n",
       "1             251           255       LCLKI        0.770  0.179   \n",
       "2             145           149       AHRET        0.852  3.427   \n",
       "3             152           156       SNYDD        1.410  2.548   \n",
       "4              85            89       DGTYR        1.214  1.908   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.018    2.22           5.810364     0.103275   \n",
       "1                1.199   -3.86           6.210876     0.065476   \n",
       "2                0.960    4.28           8.223938     0.091787   \n",
       "3                0.936    6.32           4.237976     0.044776   \n",
       "4                0.937    4.64           6.867493     0.103846   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.143829  40.273300       1  \n",
       "1       -0.036905  24.998512       1  \n",
       "2        0.879227  27.863333       1  \n",
       "3       -0.521393  30.765373       1  \n",
       "4       -0.578846  21.684615       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcell_df = pd.read_csv(os.path.join('data','input_bcell.csv'))\n",
    "bcell_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>MFIFLLFLTLTSGSDLD</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.159</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>MFIFLLFLTLTSGSD</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>FIFLLFLTL</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-7.467</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>LFLTLTSGSDLDRCT</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>TLTSGSDLDRCTTFDDV</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "1          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "2          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "3          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "4          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "\n",
       "   start_position  end_position        peptide_seq  chou_fasman  emini  \\\n",
       "0               1            17  MFIFLLFLTLTSGSDLD        0.887  0.040   \n",
       "1               1            15    MFIFLLFLTLTSGSD        0.869  0.047   \n",
       "2               2            10          FIFLLFLTL        0.621  0.042   \n",
       "3               6            20    LFLTLTSGSDLDRCT        1.021  0.230   \n",
       "4               9            25  TLTSGSDLDRCTTFDDV        1.089  0.627   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.056  -2.159           5.569763     0.116335   \n",
       "1                1.056  -2.500           5.569763     0.116335   \n",
       "2                1.148  -7.467           5.569763     0.116335   \n",
       "3                1.049   0.927           5.569763     0.116335   \n",
       "4                1.015   3.165           5.569763     0.116335   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.061116  33.205116       0  \n",
       "1       -0.061116  33.205116       0  \n",
       "2       -0.061116  33.205116       0  \n",
       "3       -0.061116  33.205116       0  \n",
       "4       -0.061116  33.205116       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars_df = pd.read_csv(os.path.join('data','input_sars.csv'))\n",
    "sars_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein feature Engineering and experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq_example = bcell_df.protein_seq.values.reshape(-1,1)[0]\n",
    "peptide_seq_example = bcell_df.peptide_seq.values.reshape(-1,1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEFQTGGIGNLPIRNWNFNFGLLGTTLLNLDANYVETARNTIDYFVDFVDNVCMDEMVRESQRNGIAPQSDSLRKLSAIKFKRINFDNSSEYIENWNLQNRRQRTGFTFHKPNIFPYSASFTLNRSQPAHDNLMGTMWLNAGSEIQVAGFDYSCAINAPANIQQFEHIVPLRRVLTTATITLLPDAERFSFPRVINSADGATTWFFNPVILRPNNVEVEFLLNGQIINTYQARFGTIVARNFDTIRLSFQLMRPPNMTPAVAVLFPNAQPFEHHATVGLTLRIESAVCESVLADASETLLANVTSVRQEYAIPVGPVFPPGMNWTDLITNYSPSREDNLQRVFTVASIRSMLIK'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SASFT'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_seq_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biophysical quantitative properties that are also Features that need to be made from protein and peptides\n",
    "* mass\n",
    "* length\n",
    "The rest have been provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dictionary of protein mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_dict = {'A':89, 'R':174, 'N':132, 'D':133,\n",
    "                'B':133, 'C':121, 'Q':146, 'E':147,\n",
    "                'Z':147, 'G':75, 'H':155, 'I':131,\n",
    "                'L':131, 'K':146, 'M':149, 'F':165,\n",
    "                'P':115, 'S':105, 'T':119, 'W':204,\n",
    "                'Y':181, 'V':117}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass maker function\n",
    "def mass_list_maker(df_and_column):\n",
    "    mass_lst = []\n",
    "    for i in df_and_column:\n",
    "        mass = 0\n",
    "        for j in i:\n",
    "            mass = mass + protein_dict[j]\n",
    "        mass_lst.append(mass)\n",
    "    return mass_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_list_maker(df_and_column):\n",
    "    return [len(i) for i in df_and_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass of protien Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51950, 42734, 25675, 120095, 33875, 33875, 33875, 33875, 33875, 49762]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_mass_lst = mass_list_maker(bcell_df.protein_seq)\n",
    "protein_mass_lst[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of protein testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[397, 336, 207, 1005, 260, 260, 260, 260, 260, 386]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_length_lst=[len(i) for i in bcell_df.protein_seq]\n",
    "protein_length_lst[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass of Peptide Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_length_lst=[len(i) for i in bcell_df.peptide_seq]\n",
    "peptide_length_lst[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length of Peptide testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[583, 660, 684, 684, 682, 615, 588, 686, 620, 721]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_mass_lst = mass_list_maker(bcell_df.peptide_seq)\n",
    "peptide_mass_lst[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features in the sars and bcell dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>MFIFLLFLTLTSGSDLD</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.159</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>MFIFLLFLTLTSGSD</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>FIFLLFLTL</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-7.467</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>LFLTLTSGSDLDRCT</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>TLTSGSDLDRCTTFDDV</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "1          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "2          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "3          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "4          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "\n",
       "   start_position  end_position        peptide_seq  chou_fasman  emini  \\\n",
       "0               1            17  MFIFLLFLTLTSGSDLD        0.887  0.040   \n",
       "1               1            15    MFIFLLFLTLTSGSD        0.869  0.047   \n",
       "2               2            10          FIFLLFLTL        0.621  0.042   \n",
       "3               6            20    LFLTLTSGSDLDRCT        1.021  0.230   \n",
       "4               9            25  TLTSGSDLDRCTTFDDV        1.089  0.627   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.056  -2.159           5.569763     0.116335   \n",
       "1                1.056  -2.500           5.569763     0.116335   \n",
       "2                1.148  -7.467           5.569763     0.116335   \n",
       "3                1.049   0.927           5.569763     0.116335   \n",
       "4                1.015   3.165           5.569763     0.116335   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.061116  33.205116       0  \n",
       "1       -0.061116  33.205116       0  \n",
       "2       -0.061116  33.205116       0  \n",
       "3       -0.061116  33.205116       0  \n",
       "4       -0.061116  33.205116       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars_df.head() # This is the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "      <th>protein_seq_mass</th>\n",
       "      <th>protein_seq_length</th>\n",
       "      <th>peptide_seq_mass</th>\n",
       "      <th>peptide_seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>MFIFLLFLTLTSGSDLD</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.159</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>2219</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>MFIFLLFLTLTSGSD</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>1955</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>FIFLLFLTL</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-7.467</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>1269</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>LFLTLTSGSDLDRCT</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>1892</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>TLTSGSDLDRCTTFDDV</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "      <td>161643</td>\n",
       "      <td>1255</td>\n",
       "      <td>2132</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "1          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "2          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "3          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "4          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "\n",
       "   start_position  end_position        peptide_seq  chou_fasman  emini  \\\n",
       "0               1            17  MFIFLLFLTLTSGSDLD        0.887  0.040   \n",
       "1               1            15    MFIFLLFLTLTSGSD        0.869  0.047   \n",
       "2               2            10          FIFLLFLTL        0.621  0.042   \n",
       "3               6            20    LFLTLTSGSDLDRCT        1.021  0.230   \n",
       "4               9            25  TLTSGSDLDRCTTFDDV        1.089  0.627   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.056  -2.159           5.569763     0.116335   \n",
       "1                1.056  -2.500           5.569763     0.116335   \n",
       "2                1.148  -7.467           5.569763     0.116335   \n",
       "3                1.049   0.927           5.569763     0.116335   \n",
       "4                1.015   3.165           5.569763     0.116335   \n",
       "\n",
       "   hydrophobicity  stability  target  protein_seq_mass  protein_seq_length  \\\n",
       "0       -0.061116  33.205116       0            161643                1255   \n",
       "1       -0.061116  33.205116       0            161643                1255   \n",
       "2       -0.061116  33.205116       0            161643                1255   \n",
       "3       -0.061116  33.205116       0            161643                1255   \n",
       "4       -0.061116  33.205116       0            161643                1255   \n",
       "\n",
       "   peptide_seq_mass  peptide_seq_length  \n",
       "0              2219                  17  \n",
       "1              1955                  15  \n",
       "2              1269                   9  \n",
       "3              1892                  15  \n",
       "4              2132                  17  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars_df['protein_seq_mass'] = mass_list_maker(sars_df.protein_seq)\n",
    "sars_df['protein_seq_length'] = len_list_maker(sars_df.protein_seq)\n",
    "\n",
    "sars_df['peptide_seq_mass'] = mass_list_maker(sars_df.peptide_seq)\n",
    "sars_df['peptide_seq_length'] = len_list_maker(sars_df.peptide_seq)\n",
    "\n",
    "sars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2T3T0</td>\n",
       "      <td>MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>SASFT</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0V2I4</td>\n",
       "      <td>MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>LCLKI</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75508</td>\n",
       "      <td>MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>AHRET</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O84462</td>\n",
       "      <td>MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>SNYDD</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00918</td>\n",
       "      <td>MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>DGTYR</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0            A2T3T0  MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...   \n",
       "1            F0V2I4  MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...   \n",
       "2            O75508  MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...   \n",
       "3            O84462  MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...   \n",
       "4            P00918  MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...   \n",
       "\n",
       "   start_position  end_position peptide_seq  chou_fasman  emini  \\\n",
       "0             161           165       SASFT        1.016  0.703   \n",
       "1             251           255       LCLKI        0.770  0.179   \n",
       "2             145           149       AHRET        0.852  3.427   \n",
       "3             152           156       SNYDD        1.410  2.548   \n",
       "4              85            89       DGTYR        1.214  1.908   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.018    2.22           5.810364     0.103275   \n",
       "1                1.199   -3.86           6.210876     0.065476   \n",
       "2                0.960    4.28           8.223938     0.091787   \n",
       "3                0.936    6.32           4.237976     0.044776   \n",
       "4                0.937    4.64           6.867493     0.103846   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.143829  40.273300       1  \n",
       "1       -0.036905  24.998512       1  \n",
       "2        0.879227  27.863333       1  \n",
       "3       -0.521393  30.765373       1  \n",
       "4       -0.578846  21.684615       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcell_df.head() # This is the training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "      <th>protein_seq_mass</th>\n",
       "      <th>protein_seq_length</th>\n",
       "      <th>peptide_seq_mass</th>\n",
       "      <th>peptide_seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2T3T0</td>\n",
       "      <td>MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>SASFT</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "      <td>1</td>\n",
       "      <td>51950</td>\n",
       "      <td>397</td>\n",
       "      <td>583</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0V2I4</td>\n",
       "      <td>MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>LCLKI</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "      <td>1</td>\n",
       "      <td>42734</td>\n",
       "      <td>336</td>\n",
       "      <td>660</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75508</td>\n",
       "      <td>MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>AHRET</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>1</td>\n",
       "      <td>25675</td>\n",
       "      <td>207</td>\n",
       "      <td>684</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O84462</td>\n",
       "      <td>MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>SNYDD</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "      <td>1</td>\n",
       "      <td>120095</td>\n",
       "      <td>1005</td>\n",
       "      <td>684</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00918</td>\n",
       "      <td>MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>DGTYR</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "      <td>1</td>\n",
       "      <td>33875</td>\n",
       "      <td>260</td>\n",
       "      <td>682</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0            A2T3T0  MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...   \n",
       "1            F0V2I4  MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...   \n",
       "2            O75508  MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...   \n",
       "3            O84462  MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...   \n",
       "4            P00918  MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...   \n",
       "\n",
       "   start_position  end_position peptide_seq  chou_fasman  emini  \\\n",
       "0             161           165       SASFT        1.016  0.703   \n",
       "1             251           255       LCLKI        0.770  0.179   \n",
       "2             145           149       AHRET        0.852  3.427   \n",
       "3             152           156       SNYDD        1.410  2.548   \n",
       "4              85            89       DGTYR        1.214  1.908   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.018    2.22           5.810364     0.103275   \n",
       "1                1.199   -3.86           6.210876     0.065476   \n",
       "2                0.960    4.28           8.223938     0.091787   \n",
       "3                0.936    6.32           4.237976     0.044776   \n",
       "4                0.937    4.64           6.867493     0.103846   \n",
       "\n",
       "   hydrophobicity  stability  target  protein_seq_mass  protein_seq_length  \\\n",
       "0       -0.143829  40.273300       1             51950                 397   \n",
       "1       -0.036905  24.998512       1             42734                 336   \n",
       "2        0.879227  27.863333       1             25675                 207   \n",
       "3       -0.521393  30.765373       1            120095                1005   \n",
       "4       -0.578846  21.684615       1             33875                 260   \n",
       "\n",
       "   peptide_seq_mass  peptide_seq_length  \n",
       "0               583                   5  \n",
       "1               660                   5  \n",
       "2               684                   5  \n",
       "3               684                   5  \n",
       "4               682                   5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcell_df['protein_seq_mass'] = mass_list_maker(bcell_df.protein_seq)\n",
    "bcell_df['protein_seq_length'] = len_list_maker(bcell_df.protein_seq)\n",
    "\n",
    "bcell_df['peptide_seq_mass'] = mass_list_maker(bcell_df.peptide_seq)\n",
    "bcell_df['peptide_seq_length'] = len_list_maker(bcell_df.peptide_seq)\n",
    "\n",
    "bcell_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the training, validation, and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       start_position  end_position  chou_fasman  emini  kolaskar_tongaonkar  \\\n",
       " 0                 161           165        1.016  0.703                1.018   \n",
       " 1                 251           255        0.770  0.179                1.199   \n",
       " 2                 145           149        0.852  3.427                0.960   \n",
       " 3                 152           156        1.410  2.548                0.936   \n",
       " 4                  85            89        1.214  1.908                0.937   \n",
       " ...               ...           ...          ...    ...                  ...   \n",
       " 14382             177           191        0.910  0.175                1.054   \n",
       " 14383             285           299        0.966  0.216                1.044   \n",
       " 14384             189           203        0.821  0.023                1.044   \n",
       " 14385            1479          1493        1.069  0.239                1.037   \n",
       " 14386            1647          1661        0.962  0.257                1.045   \n",
       " \n",
       "        parker  isoelectric_point  aromaticity  hydrophobicity  stability  \\\n",
       " 0       2.220           5.810364     0.103275       -0.143829  40.273300   \n",
       " 1      -3.860           6.210876     0.065476       -0.036905  24.998512   \n",
       " 2       4.280           8.223938     0.091787        0.879227  27.863333   \n",
       " 3       6.320           4.237976     0.044776       -0.521393  30.765373   \n",
       " 4       4.640           6.867493     0.103846       -0.578846  21.684615   \n",
       " ...       ...                ...          ...             ...        ...   \n",
       " 14382   0.820           4.894836     0.071719       -0.701083  46.875237   \n",
       " 14383   1.160           4.894836     0.071719       -0.701083  46.875237   \n",
       " 14384  -1.360           4.894836     0.071719       -0.701083  46.875237   \n",
       " 14385   2.180           9.553040     0.044338       -0.671001  29.494308   \n",
       " 14386   2.127           9.553040     0.044338       -0.671001  29.494308   \n",
       " \n",
       "        protein_seq_mass  protein_seq_length  peptide_seq_mass  \\\n",
       " 0                 51950                 397               583   \n",
       " 1                 42734                 336               660   \n",
       " 2                 25675                 207               684   \n",
       " 3                120095                1005               684   \n",
       " 4                 33875                 260               682   \n",
       " ...                 ...                 ...               ...   \n",
       " 14382             96654                 739              1991   \n",
       " 14383             96654                 739              1897   \n",
       " 14384             96654                 739              2026   \n",
       " 14385            191567                1669              1806   \n",
       " 14386            191567                1669              1870   \n",
       " \n",
       "        peptide_seq_length  \n",
       " 0                       5  \n",
       " 1                       5  \n",
       " 2                       5  \n",
       " 3                       5  \n",
       " 4                       5  \n",
       " ...                   ...  \n",
       " 14382                  15  \n",
       " 14383                  15  \n",
       " 14384                  15  \n",
       " 14385                  15  \n",
       " 14386                  15  \n",
       " \n",
       " [14387 rows x 14 columns],\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = bcell_df.drop(['parent_protein_id','protein_seq','peptide_seq','target'], axis=1), bcell_df.target.values.reshape(-1,1)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = sars_df.drop(['parent_protein_id','protein_seq','peptide_seq','target'], axis=1), sars_df.target.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Min, max\"-ing and Categorising the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_val_scaled = X_scaler.transform(X_val)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_val_categorical = to_categorical(y_val)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the nerual network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1048)              537624    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2048)              2148352   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8192)              33562624  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 57,420,634\n",
      "Trainable params: 57,420,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/250\n",
      " 1/90 [..............................] - ETA: 0s - loss: 0.6927 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.0289s). Check your callbacks.\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5628 - accuracy: 0.7247 - val_loss: 0.5375 - val_accuracy: 0.6991\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.5223 - accuracy: 0.7253 - val_loss: 0.4987 - val_accuracy: 0.7418\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4732 - accuracy: 0.7663 - val_loss: 0.4555 - val_accuracy: 0.7630\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4425 - accuracy: 0.7871 - val_loss: 0.4323 - val_accuracy: 0.7804\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.4177 - accuracy: 0.8026 - val_loss: 0.4092 - val_accuracy: 0.8103\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.3875 - accuracy: 0.8216 - val_loss: 0.4115 - val_accuracy: 0.8019\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3626 - accuracy: 0.8312 - val_loss: 0.3956 - val_accuracy: 0.8051\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.3446 - accuracy: 0.8427 - val_loss: 0.3902 - val_accuracy: 0.8238\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.3320 - accuracy: 0.8528 - val_loss: 0.4124 - val_accuracy: 0.8290\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.3147 - accuracy: 0.8606 - val_loss: 0.3985 - val_accuracy: 0.8235\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.3018 - accuracy: 0.8650 - val_loss: 0.3818 - val_accuracy: 0.8353\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2859 - accuracy: 0.8723 - val_loss: 0.3744 - val_accuracy: 0.8329\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2787 - accuracy: 0.8795 - val_loss: 0.4016 - val_accuracy: 0.8273\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2744 - accuracy: 0.8810 - val_loss: 0.4193 - val_accuracy: 0.8297\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2628 - accuracy: 0.8883 - val_loss: 0.3761 - val_accuracy: 0.8384\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2482 - accuracy: 0.8921 - val_loss: 0.3889 - val_accuracy: 0.8353\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2490 - accuracy: 0.8913 - val_loss: 0.4299 - val_accuracy: 0.8402\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2450 - accuracy: 0.8956 - val_loss: 0.3937 - val_accuracy: 0.8395\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2248 - accuracy: 0.9030 - val_loss: 0.4239 - val_accuracy: 0.8461\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2166 - accuracy: 0.9064 - val_loss: 0.3979 - val_accuracy: 0.8343\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2179 - accuracy: 0.9082 - val_loss: 0.4610 - val_accuracy: 0.8416\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.2086 - accuracy: 0.9090 - val_loss: 0.4206 - val_accuracy: 0.8416\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1934 - accuracy: 0.9188 - val_loss: 0.4613 - val_accuracy: 0.8443\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1967 - accuracy: 0.9162 - val_loss: 0.4951 - val_accuracy: 0.8402\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1933 - accuracy: 0.9181 - val_loss: 0.4625 - val_accuracy: 0.8450\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1839 - accuracy: 0.9203 - val_loss: 0.4624 - val_accuracy: 0.8412\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1748 - accuracy: 0.9249 - val_loss: 0.5512 - val_accuracy: 0.8436\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1735 - accuracy: 0.9252 - val_loss: 0.5704 - val_accuracy: 0.8391\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1848 - accuracy: 0.9207 - val_loss: 0.4740 - val_accuracy: 0.8423\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1655 - accuracy: 0.9281 - val_loss: 0.5413 - val_accuracy: 0.8436\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1566 - accuracy: 0.9321 - val_loss: 0.5732 - val_accuracy: 0.8468\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1563 - accuracy: 0.9331 - val_loss: 0.6047 - val_accuracy: 0.8363\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1541 - accuracy: 0.9328 - val_loss: 0.6307 - val_accuracy: 0.8384\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1543 - accuracy: 0.9344 - val_loss: 0.7862 - val_accuracy: 0.8339\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1598 - accuracy: 0.9327 - val_loss: 0.4618 - val_accuracy: 0.8398\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1451 - accuracy: 0.9372 - val_loss: 0.6518 - val_accuracy: 0.8482\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1400 - accuracy: 0.9405 - val_loss: 0.8038 - val_accuracy: 0.8405\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1476 - accuracy: 0.9352 - val_loss: 0.4967 - val_accuracy: 0.8259\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.1493 - accuracy: 0.9369 - val_loss: 1.0288 - val_accuracy: 0.8436\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.1439 - accuracy: 0.9415 - val_loss: 0.5132 - val_accuracy: 0.8353\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1872 - accuracy: 0.9243 - val_loss: 0.4862 - val_accuracy: 0.8350\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1633 - accuracy: 0.9287 - val_loss: 0.4371 - val_accuracy: 0.8367\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1805 - accuracy: 0.9263 - val_loss: 0.5937 - val_accuracy: 0.8367\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1894 - accuracy: 0.9257 - val_loss: 0.7161 - val_accuracy: 0.8405\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1598 - accuracy: 0.9338 - val_loss: 2.1402 - val_accuracy: 0.8402\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1937 - accuracy: 0.9214 - val_loss: 1.2707 - val_accuracy: 0.8356\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1586 - accuracy: 0.9346 - val_loss: 1.6888 - val_accuracy: 0.8436\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1698 - accuracy: 0.9334 - val_loss: 0.8051 - val_accuracy: 0.8301\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1677 - accuracy: 0.9336 - val_loss: 0.6925 - val_accuracy: 0.8329\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1593 - accuracy: 0.9346 - val_loss: 0.9365 - val_accuracy: 0.8454\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1235 - accuracy: 0.9472 - val_loss: 2.3525 - val_accuracy: 0.8412\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.2079 - accuracy: 0.9221 - val_loss: 0.8899 - val_accuracy: 0.8318\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1742 - accuracy: 0.9269 - val_loss: 0.4948 - val_accuracy: 0.8221\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1721 - accuracy: 0.9273 - val_loss: 0.8905 - val_accuracy: 0.8388\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1314 - accuracy: 0.9425 - val_loss: 1.4012 - val_accuracy: 0.8346\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1213 - accuracy: 0.9467 - val_loss: 0.8059 - val_accuracy: 0.8315\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1109 - accuracy: 0.9534 - val_loss: 0.7626 - val_accuracy: 0.8346\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1086 - accuracy: 0.9517 - val_loss: 0.8085 - val_accuracy: 0.8370\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1057 - accuracy: 0.9551 - val_loss: 1.0024 - val_accuracy: 0.8218\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1282 - accuracy: 0.9498 - val_loss: 0.6497 - val_accuracy: 0.8329\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1030 - accuracy: 0.9568 - val_loss: 0.8978 - val_accuracy: 0.8356\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0993 - accuracy: 0.9603 - val_loss: 0.6861 - val_accuracy: 0.8436\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0805 - accuracy: 0.9643 - val_loss: 0.8674 - val_accuracy: 0.8336\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0934 - accuracy: 0.9627 - val_loss: 0.7868 - val_accuracy: 0.8377\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0850 - accuracy: 0.9651 - val_loss: 1.0498 - val_accuracy: 0.8381\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0818 - accuracy: 0.9659 - val_loss: 0.9831 - val_accuracy: 0.8409\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1737 - accuracy: 0.9394 - val_loss: 0.6573 - val_accuracy: 0.8343\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1082 - accuracy: 0.9528 - val_loss: 0.8819 - val_accuracy: 0.8409\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1032 - accuracy: 0.9576 - val_loss: 1.2786 - val_accuracy: 0.8311\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1923 - accuracy: 0.9235 - val_loss: 0.5915 - val_accuracy: 0.8377\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1380 - accuracy: 0.9453 - val_loss: 0.7566 - val_accuracy: 0.8329\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1056 - accuracy: 0.9569 - val_loss: 0.8692 - val_accuracy: 0.8405\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0933 - accuracy: 0.9627 - val_loss: 1.0395 - val_accuracy: 0.8419\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0850 - accuracy: 0.9644 - val_loss: 0.9625 - val_accuracy: 0.8370\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0827 - accuracy: 0.9656 - val_loss: 1.1121 - val_accuracy: 0.8339\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0860 - accuracy: 0.9646 - val_loss: 1.0708 - val_accuracy: 0.8391\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0686 - accuracy: 0.9698 - val_loss: 1.0545 - val_accuracy: 0.8419\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0653 - accuracy: 0.9731 - val_loss: 2.1349 - val_accuracy: 0.8405\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.0674 - accuracy: 0.9718 - val_loss: 1.5692 - val_accuracy: 0.8356\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0602 - accuracy: 0.9738 - val_loss: 2.2026 - val_accuracy: 0.8377\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0724 - accuracy: 0.9698 - val_loss: 1.4021 - val_accuracy: 0.8350\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0702 - accuracy: 0.9718 - val_loss: 2.0523 - val_accuracy: 0.8315\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0645 - accuracy: 0.9732 - val_loss: 2.2695 - val_accuracy: 0.8280\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0562 - accuracy: 0.9765 - val_loss: 2.3595 - val_accuracy: 0.8416\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.2525 - accuracy: 0.9160 - val_loss: 0.5112 - val_accuracy: 0.8155\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1761 - accuracy: 0.9281 - val_loss: 0.5880 - val_accuracy: 0.8256\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1403 - accuracy: 0.9474 - val_loss: 0.5981 - val_accuracy: 0.8294\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1128 - accuracy: 0.9558 - val_loss: 1.3723 - val_accuracy: 0.8311\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0845 - accuracy: 0.9652 - val_loss: 2.0958 - val_accuracy: 0.8377\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.2004 - accuracy: 0.9358 - val_loss: 0.7225 - val_accuracy: 0.8277\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1357 - accuracy: 0.9450 - val_loss: 0.6215 - val_accuracy: 0.8294\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1011 - accuracy: 0.9592 - val_loss: 0.6891 - val_accuracy: 0.8266\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0817 - accuracy: 0.9659 - val_loss: 0.8289 - val_accuracy: 0.8356\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0773 - accuracy: 0.9690 - val_loss: 0.9506 - val_accuracy: 0.8395\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.0752 - accuracy: 0.9675 - val_loss: 1.3224 - val_accuracy: 0.8398\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.0540 - accuracy: 0.9778 - val_loss: 1.4901 - val_accuracy: 0.8429\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.0571 - accuracy: 0.9773 - val_loss: 1.4399 - val_accuracy: 0.8346\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.0541 - accuracy: 0.9786 - val_loss: 1.8688 - val_accuracy: 0.8332\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.1045 - accuracy: 0.9608 - val_loss: 0.7336 - val_accuracy: 0.8346\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.1292 - accuracy: 0.9514 - val_loss: 0.8878 - val_accuracy: 0.8353\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0782 - accuracy: 0.9695 - val_loss: 0.9204 - val_accuracy: 0.8332\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0625 - accuracy: 0.9746 - val_loss: 0.9609 - val_accuracy: 0.8336\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0670 - accuracy: 0.9770 - val_loss: 0.7906 - val_accuracy: 0.8308\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0545 - accuracy: 0.9777 - val_loss: 0.9454 - val_accuracy: 0.8412\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.0498 - accuracy: 0.9799 - val_loss: 0.7359 - val_accuracy: 0.8416\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0592 - accuracy: 0.9768 - val_loss: 0.8501 - val_accuracy: 0.8356\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0562 - accuracy: 0.9793 - val_loss: 1.0158 - val_accuracy: 0.8325\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0529 - accuracy: 0.9805 - val_loss: 0.9464 - val_accuracy: 0.8423\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0503 - accuracy: 0.9800 - val_loss: 1.4342 - val_accuracy: 0.8409\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0837 - accuracy: 0.9727 - val_loss: 0.5160 - val_accuracy: 0.8228\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.1078 - accuracy: 0.9583 - val_loss: 0.8007 - val_accuracy: 0.8360\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0638 - accuracy: 0.9742 - val_loss: 0.8010 - val_accuracy: 0.8398\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0511 - accuracy: 0.9808 - val_loss: 0.9420 - val_accuracy: 0.8297\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0448 - accuracy: 0.9816 - val_loss: 1.1492 - val_accuracy: 0.8398\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 0.0454 - accuracy: 0.9828 - val_loss: 1.3902 - val_accuracy: 0.8252\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.0495 - accuracy: 0.9813 - val_loss: 1.1707 - val_accuracy: 0.8377\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.0466 - accuracy: 0.9812 - val_loss: 1.4968 - val_accuracy: 0.8370\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0781 - accuracy: 0.9742 - val_loss: 1.0822 - val_accuracy: 0.8325\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0520 - accuracy: 0.9807 - val_loss: 1.5129 - val_accuracy: 0.8259\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0586 - accuracy: 0.9828 - val_loss: 0.7895 - val_accuracy: 0.8259\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0848 - accuracy: 0.9666 - val_loss: 1.5090 - val_accuracy: 0.8336\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0605 - accuracy: 0.9776 - val_loss: 1.3469 - val_accuracy: 0.8426\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0435 - accuracy: 0.9831 - val_loss: 1.3563 - val_accuracy: 0.8301\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0382 - accuracy: 0.9851 - val_loss: 1.7772 - val_accuracy: 0.8329\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0368 - accuracy: 0.9859 - val_loss: 2.4398 - val_accuracy: 0.8311\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0646 - accuracy: 0.9772 - val_loss: 0.9538 - val_accuracy: 0.8082\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0692 - accuracy: 0.9725 - val_loss: 1.2663 - val_accuracy: 0.8363\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 1.6542 - val_accuracy: 0.8353\n",
      "Epoch 129/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0747 - accuracy: 0.9780 - val_loss: 0.5643 - val_accuracy: 0.8148\n",
      "Epoch 130/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1131 - accuracy: 0.9573 - val_loss: 0.7564 - val_accuracy: 0.8325\n",
      "Epoch 131/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0779 - accuracy: 0.9712 - val_loss: 0.7542 - val_accuracy: 0.8374\n",
      "Epoch 132/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 0.9633 - val_accuracy: 0.8304\n",
      "Epoch 133/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0475 - accuracy: 0.9824 - val_loss: 0.9119 - val_accuracy: 0.8329\n",
      "Epoch 134/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0403 - accuracy: 0.9829 - val_loss: 1.4643 - val_accuracy: 0.8290\n",
      "Epoch 135/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 1.3237 - val_accuracy: 0.8318\n",
      "Epoch 136/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0401 - accuracy: 0.9851 - val_loss: 2.3463 - val_accuracy: 0.8381\n",
      "Epoch 137/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0405 - accuracy: 0.9859 - val_loss: 1.9662 - val_accuracy: 0.8356\n",
      "Epoch 138/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0371 - accuracy: 0.9853 - val_loss: 3.3488 - val_accuracy: 0.8336\n",
      "Epoch 139/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0310 - accuracy: 0.9881 - val_loss: 5.5521 - val_accuracy: 0.8402\n",
      "Epoch 140/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0333 - accuracy: 0.9867 - val_loss: 3.5767 - val_accuracy: 0.8318\n",
      "Epoch 141/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0552 - accuracy: 0.9804 - val_loss: 1.5832 - val_accuracy: 0.8363\n",
      "Epoch 142/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0402 - accuracy: 0.9850 - val_loss: 1.7571 - val_accuracy: 0.8343\n",
      "Epoch 143/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0365 - accuracy: 0.9877 - val_loss: 1.6330 - val_accuracy: 0.8370\n",
      "Epoch 144/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0816 - accuracy: 0.9784 - val_loss: 0.5882 - val_accuracy: 0.8218\n",
      "Epoch 145/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0846 - accuracy: 0.9692 - val_loss: 0.7519 - val_accuracy: 0.8294\n",
      "Epoch 146/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0473 - accuracy: 0.9815 - val_loss: 0.9271 - val_accuracy: 0.8322\n",
      "Epoch 147/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0439 - accuracy: 0.9855 - val_loss: 0.9063 - val_accuracy: 0.8336\n",
      "Epoch 148/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 1.0235 - val_accuracy: 0.8311\n",
      "Epoch 149/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0382 - accuracy: 0.9844 - val_loss: 1.2518 - val_accuracy: 0.8329\n",
      "Epoch 150/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0437 - accuracy: 0.9833 - val_loss: 1.0019 - val_accuracy: 0.8308\n",
      "Epoch 151/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0373 - accuracy: 0.9858 - val_loss: 1.2068 - val_accuracy: 0.8346\n",
      "Epoch 152/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 1.1143 - val_accuracy: 0.8270\n",
      "Epoch 153/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0363 - accuracy: 0.9863 - val_loss: 1.2078 - val_accuracy: 0.8384\n",
      "Epoch 154/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0324 - accuracy: 0.9867 - val_loss: 1.3842 - val_accuracy: 0.8304\n",
      "Epoch 155/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0346 - accuracy: 0.9875 - val_loss: 1.4876 - val_accuracy: 0.8381\n",
      "Epoch 156/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0537 - accuracy: 0.9798 - val_loss: 1.0420 - val_accuracy: 0.8308\n",
      "Epoch 157/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0485 - accuracy: 0.9824 - val_loss: 0.9720 - val_accuracy: 0.8402\n",
      "Epoch 158/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0401 - accuracy: 0.9853 - val_loss: 1.1424 - val_accuracy: 0.8370\n",
      "Epoch 159/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0423 - accuracy: 0.9843 - val_loss: 1.2783 - val_accuracy: 0.8315\n",
      "Epoch 160/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0468 - accuracy: 0.9819 - val_loss: 1.3204 - val_accuracy: 0.8287\n",
      "Epoch 161/250\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.0395 - accuracy: 0.9848 - val_loss: 1.5327 - val_accuracy: 0.8329\n",
      "Epoch 162/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0371 - accuracy: 0.9855 - val_loss: 3.0108 - val_accuracy: 0.8325\n",
      "Epoch 163/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1057 - accuracy: 0.9765 - val_loss: 0.6486 - val_accuracy: 0.8259\n",
      "Epoch 164/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0877 - accuracy: 0.9675 - val_loss: 0.8393 - val_accuracy: 0.8388\n",
      "Epoch 165/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0497 - accuracy: 0.9813 - val_loss: 1.4677 - val_accuracy: 0.8318\n",
      "Epoch 166/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0517 - accuracy: 0.9800 - val_loss: 0.9562 - val_accuracy: 0.8315\n",
      "Epoch 167/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0377 - accuracy: 0.9848 - val_loss: 1.1384 - val_accuracy: 0.8290\n",
      "Epoch 168/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.9810 - val_accuracy: 0.8391\n",
      "Epoch 169/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 1.3025 - val_accuracy: 0.8346\n",
      "Epoch 170/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 1.3016 - val_accuracy: 0.8388\n",
      "Epoch 171/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0272 - accuracy: 0.9896 - val_loss: 1.3461 - val_accuracy: 0.8322\n",
      "Epoch 172/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 1.4603 - val_accuracy: 0.8256\n",
      "Epoch 173/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0993 - accuracy: 0.9733 - val_loss: 0.7118 - val_accuracy: 0.8259\n",
      "Epoch 174/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0730 - accuracy: 0.9725 - val_loss: 0.8192 - val_accuracy: 0.8284\n",
      "Epoch 175/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0447 - accuracy: 0.9845 - val_loss: 0.8209 - val_accuracy: 0.8284\n",
      "Epoch 176/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0349 - accuracy: 0.9872 - val_loss: 0.9894 - val_accuracy: 0.8367\n",
      "Epoch 177/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0271 - accuracy: 0.9895 - val_loss: 1.0060 - val_accuracy: 0.8252\n",
      "Epoch 178/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.9586 - val_accuracy: 0.8297\n",
      "Epoch 179/250\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.0271 - accuracy: 0.9899 - val_loss: 0.9988 - val_accuracy: 0.8332\n",
      "Epoch 180/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0212 - accuracy: 0.9915 - val_loss: 1.1329 - val_accuracy: 0.8304\n",
      "Epoch 181/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 1.1248 - val_accuracy: 0.8329\n",
      "Epoch 182/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0181 - accuracy: 0.9930 - val_loss: 1.2184 - val_accuracy: 0.8353\n",
      "Epoch 183/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0413 - accuracy: 0.9880 - val_loss: 0.6401 - val_accuracy: 0.8193\n",
      "Epoch 184/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0551 - accuracy: 0.9813 - val_loss: 0.8290 - val_accuracy: 0.8294\n",
      "Epoch 185/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0365 - accuracy: 0.9865 - val_loss: 1.1879 - val_accuracy: 0.8297\n",
      "Epoch 186/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0831 - accuracy: 0.9737 - val_loss: 0.6859 - val_accuracy: 0.8256\n",
      "Epoch 187/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0782 - accuracy: 0.9712 - val_loss: 0.8501 - val_accuracy: 0.8325\n",
      "Epoch 188/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0427 - accuracy: 0.9834 - val_loss: 1.6236 - val_accuracy: 0.8287\n",
      "Epoch 189/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 6.8665 - val_accuracy: 0.8290\n",
      "Epoch 190/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0360 - accuracy: 0.9876 - val_loss: 3.7384 - val_accuracy: 0.8290\n",
      "Epoch 191/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2701 - accuracy: 0.9741 - val_loss: 0.5533 - val_accuracy: 0.8072\n",
      "Epoch 192/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1692 - accuracy: 0.9330 - val_loss: 0.6489 - val_accuracy: 0.8259\n",
      "Epoch 193/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0760 - accuracy: 0.9730 - val_loss: 0.7455 - val_accuracy: 0.8308\n",
      "Epoch 194/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0513 - accuracy: 0.9802 - val_loss: 0.9051 - val_accuracy: 0.8235\n",
      "Epoch 195/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0412 - accuracy: 0.9832 - val_loss: 0.9478 - val_accuracy: 0.8249\n",
      "Epoch 196/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0342 - accuracy: 0.9880 - val_loss: 0.8938 - val_accuracy: 0.8304\n",
      "Epoch 197/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0277 - accuracy: 0.9890 - val_loss: 0.9840 - val_accuracy: 0.8228\n",
      "Epoch 198/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0305 - accuracy: 0.9898 - val_loss: 1.2137 - val_accuracy: 0.8256\n",
      "Epoch 199/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0248 - accuracy: 0.9904 - val_loss: 1.8239 - val_accuracy: 0.8277\n",
      "Epoch 200/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.9205 - val_accuracy: 0.8318\n",
      "Epoch 201/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0270 - accuracy: 0.9902 - val_loss: 1.0445 - val_accuracy: 0.8252\n",
      "Epoch 202/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 1.0416 - val_accuracy: 0.8290\n",
      "Epoch 203/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 1.0226 - val_accuracy: 0.8228\n",
      "Epoch 204/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0187 - accuracy: 0.9925 - val_loss: 1.2885 - val_accuracy: 0.8245\n",
      "Epoch 205/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0245 - accuracy: 0.9908 - val_loss: 1.2322 - val_accuracy: 0.8287\n",
      "Epoch 206/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0240 - accuracy: 0.9910 - val_loss: 1.3845 - val_accuracy: 0.8329\n",
      "Epoch 207/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 1.7213 - val_accuracy: 0.8238\n",
      "Epoch 208/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.9560 - val_accuracy: 0.8197\n",
      "Epoch 209/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0236 - accuracy: 0.9911 - val_loss: 1.0512 - val_accuracy: 0.8228\n",
      "Epoch 210/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0241 - accuracy: 0.9907 - val_loss: 1.1558 - val_accuracy: 0.8245\n",
      "Epoch 211/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 1.2948 - val_accuracy: 0.8228\n",
      "Epoch 212/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 1.1368 - val_accuracy: 0.8308\n",
      "Epoch 213/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0312 - accuracy: 0.9893 - val_loss: 1.2525 - val_accuracy: 0.8207\n",
      "Epoch 214/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 0.9701 - val_accuracy: 0.8263\n",
      "Epoch 215/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0423 - accuracy: 0.9837 - val_loss: 1.1930 - val_accuracy: 0.8242\n",
      "Epoch 216/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0308 - accuracy: 0.9884 - val_loss: 1.3251 - val_accuracy: 0.8294\n",
      "Epoch 217/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0245 - accuracy: 0.9909 - val_loss: 1.2090 - val_accuracy: 0.8329\n",
      "Epoch 218/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 1.2250 - val_accuracy: 0.8277\n",
      "Epoch 219/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0294 - accuracy: 0.9898 - val_loss: 1.1404 - val_accuracy: 0.8263\n",
      "Epoch 220/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 1.4355 - val_accuracy: 0.8259\n",
      "Epoch 221/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 1.2306 - val_accuracy: 0.8228\n",
      "Epoch 222/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 1.2718 - val_accuracy: 0.8277\n",
      "Epoch 223/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.1191 - accuracy: 0.9844 - val_loss: 0.7212 - val_accuracy: 0.8238\n",
      "Epoch 224/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0775 - accuracy: 0.9708 - val_loss: 0.7270 - val_accuracy: 0.8280\n",
      "Epoch 225/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0368 - accuracy: 0.9866 - val_loss: 1.0521 - val_accuracy: 0.8277\n",
      "Epoch 226/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0294 - accuracy: 0.9886 - val_loss: 1.1577 - val_accuracy: 0.8249\n",
      "Epoch 227/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0361 - accuracy: 0.9863 - val_loss: 1.0127 - val_accuracy: 0.8273\n",
      "Epoch 228/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 1.0570 - val_accuracy: 0.8290\n",
      "Epoch 229/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 1.4023 - val_accuracy: 0.8228\n",
      "Epoch 230/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0208 - accuracy: 0.9916 - val_loss: 1.3562 - val_accuracy: 0.8301\n",
      "Epoch 231/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0171 - accuracy: 0.9929 - val_loss: 1.8267 - val_accuracy: 0.8315\n",
      "Epoch 232/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0905 - accuracy: 0.9775 - val_loss: 0.8901 - val_accuracy: 0.8186\n",
      "Epoch 233/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0630 - accuracy: 0.9779 - val_loss: 0.9258 - val_accuracy: 0.8214\n",
      "Epoch 234/250\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.0318 - accuracy: 0.9886 - val_loss: 0.9819 - val_accuracy: 0.8263\n",
      "Epoch 235/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 1.0042 - val_accuracy: 0.8329\n",
      "Epoch 236/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0213 - accuracy: 0.9911 - val_loss: 0.9358 - val_accuracy: 0.8294\n",
      "Epoch 237/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0344 - accuracy: 0.9877 - val_loss: 0.9995 - val_accuracy: 0.8266\n",
      "Epoch 238/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 1.0746 - val_accuracy: 0.8294\n",
      "Epoch 239/250\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 1.0405 - val_accuracy: 0.8290\n",
      "Epoch 240/250\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 1.1555 - val_accuracy: 0.8280\n",
      "Epoch 241/250\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 1.2255 - val_accuracy: 0.8318\n",
      "Epoch 242/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0544 - accuracy: 0.9843 - val_loss: 0.8549 - val_accuracy: 0.8350\n",
      "Epoch 243/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 0.9321 - val_accuracy: 0.8284\n",
      "Epoch 244/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0348 - accuracy: 0.9877 - val_loss: 0.8182 - val_accuracy: 0.8294\n",
      "Epoch 245/250\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.0433 - accuracy: 0.9866 - val_loss: 1.0111 - val_accuracy: 0.8259\n",
      "Epoch 246/250\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.8161 - val_accuracy: 0.8318\n",
      "Epoch 247/250\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.0301 - accuracy: 0.9890 - val_loss: 1.0492 - val_accuracy: 0.8242\n",
      "Epoch 248/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0229 - accuracy: 0.9914 - val_loss: 1.4048 - val_accuracy: 0.8297\n",
      "Epoch 249/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0275 - accuracy: 0.9905 - val_loss: 0.9896 - val_accuracy: 0.8308\n",
      "Epoch 250/250\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.0203 - accuracy: 0.9919 - val_loss: 1.3317 - val_accuracy: 0.8360\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=1048, activation='relu'))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dense(units=4096*2, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    batch_size=128,\n",
    "    epochs=250,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_scaled, y_val_categorical)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is overfitting so lets try something else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added Dropouts between each layer at 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1048)              537624    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1048)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2048)              2148352   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8192)              33562624  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 57,420,634\n",
      "Trainable params: 57,420,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      " 1/90 [..............................] - ETA: 2s - loss: 0.7546 - accuracy: 0.3359WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.0279s). Check your callbacks.\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.6585 - accuracy: 0.7226 - val_loss: 0.5795 - val_accuracy: 0.7345\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5868 - accuracy: 0.7273 - val_loss: 0.5966 - val_accuracy: 0.7345\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5868 - accuracy: 0.7273 - val_loss: 0.5908 - val_accuracy: 0.7345\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5836 - accuracy: 0.7273 - val_loss: 0.5732 - val_accuracy: 0.7345\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5828 - accuracy: 0.7273 - val_loss: 0.5719 - val_accuracy: 0.7345\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5817 - accuracy: 0.7273 - val_loss: 0.5613 - val_accuracy: 0.7345\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.5784 - accuracy: 0.7262 - val_loss: 0.5496 - val_accuracy: 0.7345\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.5729 - accuracy: 0.7252 - val_loss: 0.5724 - val_accuracy: 0.7345\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5669 - accuracy: 0.7254 - val_loss: 0.5416 - val_accuracy: 0.7345\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5633 - accuracy: 0.7256 - val_loss: 0.5568 - val_accuracy: 0.7345\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5634 - accuracy: 0.7259 - val_loss: 0.5482 - val_accuracy: 0.7345\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5586 - accuracy: 0.7250 - val_loss: 0.5384 - val_accuracy: 0.7349\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5553 - accuracy: 0.7271 - val_loss: 0.5376 - val_accuracy: 0.7325\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5551 - accuracy: 0.7265 - val_loss: 0.5351 - val_accuracy: 0.7345\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5521 - accuracy: 0.7259 - val_loss: 0.5327 - val_accuracy: 0.7338\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5489 - accuracy: 0.7283 - val_loss: 0.5253 - val_accuracy: 0.7345\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5477 - accuracy: 0.7246 - val_loss: 0.5386 - val_accuracy: 0.7345\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5464 - accuracy: 0.7280 - val_loss: 0.5339 - val_accuracy: 0.7345\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5413 - accuracy: 0.7281 - val_loss: 0.5279 - val_accuracy: 0.7345\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5419 - accuracy: 0.7265 - val_loss: 0.5217 - val_accuracy: 0.7397\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.5442 - accuracy: 0.7281 - val_loss: 0.5201 - val_accuracy: 0.7345\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5420 - accuracy: 0.7260 - val_loss: 0.5238 - val_accuracy: 0.7345\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5395 - accuracy: 0.7252 - val_loss: 0.5134 - val_accuracy: 0.7345\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5345 - accuracy: 0.7266 - val_loss: 0.5121 - val_accuracy: 0.7345\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5424 - accuracy: 0.7299 - val_loss: 0.5131 - val_accuracy: 0.7491\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5392 - accuracy: 0.7265 - val_loss: 0.5263 - val_accuracy: 0.7345\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5336 - accuracy: 0.7289 - val_loss: 0.5090 - val_accuracy: 0.7345\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5337 - accuracy: 0.7275 - val_loss: 0.5041 - val_accuracy: 0.7352\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5323 - accuracy: 0.7317 - val_loss: 0.5130 - val_accuracy: 0.7151\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5336 - accuracy: 0.7296 - val_loss: 0.5029 - val_accuracy: 0.7345\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5296 - accuracy: 0.7302 - val_loss: 0.5162 - val_accuracy: 0.7352\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5297 - accuracy: 0.7300 - val_loss: 0.5161 - val_accuracy: 0.7349\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5265 - accuracy: 0.7273 - val_loss: 0.4995 - val_accuracy: 0.7345\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5283 - accuracy: 0.7278 - val_loss: 0.5115 - val_accuracy: 0.7345\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5285 - accuracy: 0.7300 - val_loss: 0.5064 - val_accuracy: 0.7345\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5224 - accuracy: 0.7304 - val_loss: 0.4972 - val_accuracy: 0.7352\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5238 - accuracy: 0.7333 - val_loss: 0.4875 - val_accuracy: 0.7599\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5213 - accuracy: 0.7336 - val_loss: 0.5014 - val_accuracy: 0.7373\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5206 - accuracy: 0.7328 - val_loss: 0.4980 - val_accuracy: 0.7495\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5243 - accuracy: 0.7320 - val_loss: 0.4959 - val_accuracy: 0.7345\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5193 - accuracy: 0.7293 - val_loss: 0.4927 - val_accuracy: 0.7345\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5257 - accuracy: 0.7295 - val_loss: 0.4849 - val_accuracy: 0.7345\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5197 - accuracy: 0.7319 - val_loss: 0.4914 - val_accuracy: 0.7345\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5167 - accuracy: 0.7299 - val_loss: 0.4844 - val_accuracy: 0.7373\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5249 - accuracy: 0.7305 - val_loss: 0.4988 - val_accuracy: 0.7457\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5157 - accuracy: 0.7334 - val_loss: 0.4963 - val_accuracy: 0.7345\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5131 - accuracy: 0.7324 - val_loss: 0.4818 - val_accuracy: 0.7460\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5142 - accuracy: 0.7285 - val_loss: 0.4765 - val_accuracy: 0.7345\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5156 - accuracy: 0.7330 - val_loss: 0.4861 - val_accuracy: 0.7474\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5083 - accuracy: 0.7335 - val_loss: 0.4922 - val_accuracy: 0.7352\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5098 - accuracy: 0.7339 - val_loss: 0.4767 - val_accuracy: 0.7356\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5100 - accuracy: 0.7376 - val_loss: 0.4948 - val_accuracy: 0.7404\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5069 - accuracy: 0.7388 - val_loss: 0.4815 - val_accuracy: 0.7345\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5100 - accuracy: 0.7343 - val_loss: 0.4722 - val_accuracy: 0.7477\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5066 - accuracy: 0.7419 - val_loss: 0.4738 - val_accuracy: 0.7644\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5071 - accuracy: 0.7404 - val_loss: 0.4669 - val_accuracy: 0.7696\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5073 - accuracy: 0.7379 - val_loss: 0.4847 - val_accuracy: 0.7345\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5056 - accuracy: 0.7411 - val_loss: 0.4744 - val_accuracy: 0.7345\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5071 - accuracy: 0.7409 - val_loss: 0.4655 - val_accuracy: 0.7345\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5017 - accuracy: 0.7381 - val_loss: 0.4706 - val_accuracy: 0.7352\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5024 - accuracy: 0.7464 - val_loss: 0.4870 - val_accuracy: 0.7345\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4986 - accuracy: 0.7447 - val_loss: 0.4654 - val_accuracy: 0.7352\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4983 - accuracy: 0.7485 - val_loss: 0.4900 - val_accuracy: 0.7345\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4974 - accuracy: 0.7472 - val_loss: 0.4633 - val_accuracy: 0.7682\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5003 - accuracy: 0.7397 - val_loss: 0.4841 - val_accuracy: 0.7345\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4960 - accuracy: 0.7492 - val_loss: 0.4683 - val_accuracy: 0.7780\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4921 - accuracy: 0.7564 - val_loss: 0.4746 - val_accuracy: 0.7345\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4985 - accuracy: 0.7547 - val_loss: 0.4732 - val_accuracy: 0.7401\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4965 - accuracy: 0.7445 - val_loss: 0.4765 - val_accuracy: 0.7418\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4929 - accuracy: 0.7528 - val_loss: 0.4590 - val_accuracy: 0.7575\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4927 - accuracy: 0.7467 - val_loss: 0.4669 - val_accuracy: 0.7429\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4929 - accuracy: 0.7467 - val_loss: 0.4639 - val_accuracy: 0.7345\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4905 - accuracy: 0.7546 - val_loss: 0.4674 - val_accuracy: 0.7776\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4926 - accuracy: 0.7556 - val_loss: 0.4742 - val_accuracy: 0.7550\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4920 - accuracy: 0.7507 - val_loss: 0.4628 - val_accuracy: 0.7345\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4896 - accuracy: 0.7540 - val_loss: 0.4597 - val_accuracy: 0.7679\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4909 - accuracy: 0.7616 - val_loss: 0.4636 - val_accuracy: 0.7526\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4851 - accuracy: 0.7535 - val_loss: 0.4565 - val_accuracy: 0.7526\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4886 - accuracy: 0.7585 - val_loss: 0.4724 - val_accuracy: 0.7637\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4863 - accuracy: 0.7587 - val_loss: 0.4728 - val_accuracy: 0.7363\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4859 - accuracy: 0.7590 - val_loss: 0.4724 - val_accuracy: 0.7345\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4864 - accuracy: 0.7611 - val_loss: 0.4501 - val_accuracy: 0.7752\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4870 - accuracy: 0.7586 - val_loss: 0.4776 - val_accuracy: 0.7345\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4870 - accuracy: 0.7620 - val_loss: 0.4653 - val_accuracy: 0.7363\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4845 - accuracy: 0.7644 - val_loss: 0.4732 - val_accuracy: 0.7825\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4843 - accuracy: 0.7644 - val_loss: 0.4487 - val_accuracy: 0.8016\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.4605 - val_accuracy: 0.7474\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4813 - accuracy: 0.7654 - val_loss: 0.4839 - val_accuracy: 0.7345\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4803 - accuracy: 0.7628 - val_loss: 0.4588 - val_accuracy: 0.7488\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4841 - accuracy: 0.7666 - val_loss: 0.4577 - val_accuracy: 0.7606\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4766 - accuracy: 0.7629 - val_loss: 0.4587 - val_accuracy: 0.7345\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4792 - accuracy: 0.7638 - val_loss: 0.4599 - val_accuracy: 0.7495\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4790 - accuracy: 0.7644 - val_loss: 0.4842 - val_accuracy: 0.7773\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4767 - accuracy: 0.7729 - val_loss: 0.4665 - val_accuracy: 0.7509\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4765 - accuracy: 0.7653 - val_loss: 0.4462 - val_accuracy: 0.8061\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4769 - accuracy: 0.7701 - val_loss: 0.4597 - val_accuracy: 0.8019\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4738 - accuracy: 0.7753 - val_loss: 0.4577 - val_accuracy: 0.8033\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4745 - accuracy: 0.7684 - val_loss: 0.4536 - val_accuracy: 0.7554\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4810 - accuracy: 0.7572 - val_loss: 0.4703 - val_accuracy: 0.7345\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4797 - accuracy: 0.7665 - val_loss: 0.4480 - val_accuracy: 0.7703\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4781 - accuracy: 0.7757 - val_loss: 0.4595 - val_accuracy: 0.7839\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4446 - val_accuracy: 0.8079\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4699 - accuracy: 0.7722 - val_loss: 0.4469 - val_accuracy: 0.8085\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4649 - accuracy: 0.7729 - val_loss: 0.4699 - val_accuracy: 0.7613\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4754 - accuracy: 0.7705 - val_loss: 0.4537 - val_accuracy: 0.7790\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4702 - accuracy: 0.7750 - val_loss: 0.4551 - val_accuracy: 0.8110\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4742 - accuracy: 0.7835 - val_loss: 0.4444 - val_accuracy: 0.8193\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4662 - accuracy: 0.7791 - val_loss: 0.4550 - val_accuracy: 0.8085\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4724 - accuracy: 0.7788 - val_loss: 0.4608 - val_accuracy: 0.8068\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4685 - accuracy: 0.7718 - val_loss: 0.4453 - val_accuracy: 0.8096\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4718 - accuracy: 0.7736 - val_loss: 0.4476 - val_accuracy: 0.8023\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4689 - accuracy: 0.7770 - val_loss: 0.4439 - val_accuracy: 0.7964\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4734 - accuracy: 0.7757 - val_loss: 0.4542 - val_accuracy: 0.7470\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4651 - accuracy: 0.7790 - val_loss: 0.4467 - val_accuracy: 0.7436\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4715 - accuracy: 0.7776 - val_loss: 0.4329 - val_accuracy: 0.7957\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4680 - accuracy: 0.7713 - val_loss: 0.4530 - val_accuracy: 0.7794\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4681 - accuracy: 0.7741 - val_loss: 0.4526 - val_accuracy: 0.8138\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7778 - val_loss: 0.4424 - val_accuracy: 0.7585\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4645 - accuracy: 0.7781 - val_loss: 0.4313 - val_accuracy: 0.7999\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4582 - accuracy: 0.7825 - val_loss: 0.4629 - val_accuracy: 0.7901\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4648 - accuracy: 0.7777 - val_loss: 0.4462 - val_accuracy: 0.7912\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4700 - accuracy: 0.7770 - val_loss: 0.4474 - val_accuracy: 0.8085\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4702 - accuracy: 0.7830 - val_loss: 0.4504 - val_accuracy: 0.8155\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4684 - accuracy: 0.7777 - val_loss: 0.4567 - val_accuracy: 0.7672\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4673 - accuracy: 0.7820 - val_loss: 0.4366 - val_accuracy: 0.8037\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4616 - accuracy: 0.7739 - val_loss: 0.4396 - val_accuracy: 0.7575\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4678 - accuracy: 0.7781 - val_loss: 0.4572 - val_accuracy: 0.7425\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4602 - accuracy: 0.7772 - val_loss: 0.4525 - val_accuracy: 0.7387\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4632 - accuracy: 0.7798 - val_loss: 0.4302 - val_accuracy: 0.7641\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4462 - val_accuracy: 0.7505\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4741 - accuracy: 0.7759 - val_loss: 0.4348 - val_accuracy: 0.8145\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4610 - accuracy: 0.7801 - val_loss: 0.4328 - val_accuracy: 0.8117\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4560 - accuracy: 0.7843 - val_loss: 0.4365 - val_accuracy: 0.8193\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4726 - accuracy: 0.7817 - val_loss: 0.4398 - val_accuracy: 0.7467\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4653 - accuracy: 0.7769 - val_loss: 0.4378 - val_accuracy: 0.7363\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4606 - accuracy: 0.7810 - val_loss: 0.4336 - val_accuracy: 0.7971\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4607 - accuracy: 0.7757 - val_loss: 0.4311 - val_accuracy: 0.7582\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7794 - val_loss: 0.4365 - val_accuracy: 0.7533\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4621 - accuracy: 0.7814 - val_loss: 0.4407 - val_accuracy: 0.8089\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4597 - accuracy: 0.7794 - val_loss: 0.4281 - val_accuracy: 0.7589\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4792 - accuracy: 0.7795 - val_loss: 0.4573 - val_accuracy: 0.7422\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4712 - accuracy: 0.7781 - val_loss: 0.4470 - val_accuracy: 0.7755\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4675 - accuracy: 0.7725 - val_loss: 0.4289 - val_accuracy: 0.7620\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4614 - accuracy: 0.7724 - val_loss: 0.4525 - val_accuracy: 0.7880\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4573 - accuracy: 0.7833 - val_loss: 0.4366 - val_accuracy: 0.7964\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4647 - accuracy: 0.7797 - val_loss: 0.4300 - val_accuracy: 0.7741\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4667 - accuracy: 0.7826 - val_loss: 0.4204 - val_accuracy: 0.8158\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4606 - accuracy: 0.7836 - val_loss: 0.4337 - val_accuracy: 0.8228\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4652 - accuracy: 0.7842 - val_loss: 0.4281 - val_accuracy: 0.7728\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4614 - accuracy: 0.7819 - val_loss: 0.4444 - val_accuracy: 0.7554\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4688 - accuracy: 0.7764 - val_loss: 0.4257 - val_accuracy: 0.7637\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4726 - accuracy: 0.7775 - val_loss: 0.4276 - val_accuracy: 0.7620\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4672 - accuracy: 0.7753 - val_loss: 0.4462 - val_accuracy: 0.8134\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4611 - accuracy: 0.7729 - val_loss: 0.4274 - val_accuracy: 0.7870\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4630 - accuracy: 0.7782 - val_loss: 0.4236 - val_accuracy: 0.8030\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4599 - accuracy: 0.7807 - val_loss: 0.4440 - val_accuracy: 0.7526\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4528 - accuracy: 0.7805 - val_loss: 0.4490 - val_accuracy: 0.7495\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4691 - accuracy: 0.7786 - val_loss: 0.4231 - val_accuracy: 0.8061\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4559 - accuracy: 0.7843 - val_loss: 0.4104 - val_accuracy: 0.8158\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4537 - accuracy: 0.7875 - val_loss: 0.4283 - val_accuracy: 0.8179\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4555 - accuracy: 0.7827 - val_loss: 0.4302 - val_accuracy: 0.7603\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4587 - accuracy: 0.7869 - val_loss: 0.4197 - val_accuracy: 0.8200\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4644 - accuracy: 0.7862 - val_loss: 0.4283 - val_accuracy: 0.8200\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4619 - accuracy: 0.7817 - val_loss: 0.4130 - val_accuracy: 0.8200\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4565 - accuracy: 0.7913 - val_loss: 0.4268 - val_accuracy: 0.7985\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.4310 - val_accuracy: 0.8162\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4765 - accuracy: 0.7831 - val_loss: 0.4258 - val_accuracy: 0.7908\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4662 - accuracy: 0.7837 - val_loss: 0.4266 - val_accuracy: 0.8176\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4568 - accuracy: 0.7816 - val_loss: 0.4162 - val_accuracy: 0.8162\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4581 - accuracy: 0.7821 - val_loss: 0.4124 - val_accuracy: 0.8165\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4590 - accuracy: 0.7842 - val_loss: 0.4130 - val_accuracy: 0.8211\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4756 - accuracy: 0.7829 - val_loss: 0.4168 - val_accuracy: 0.8214\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4668 - accuracy: 0.7857 - val_loss: 0.4246 - val_accuracy: 0.8186\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4559 - accuracy: 0.7860 - val_loss: 0.4391 - val_accuracy: 0.8096\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4597 - accuracy: 0.7864 - val_loss: 0.4251 - val_accuracy: 0.8228\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4627 - accuracy: 0.7793 - val_loss: 0.4153 - val_accuracy: 0.8124\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.4198 - val_accuracy: 0.8176\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4573 - accuracy: 0.7861 - val_loss: 0.4158 - val_accuracy: 0.8134\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4639 - accuracy: 0.7892 - val_loss: 0.4209 - val_accuracy: 0.8249\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4533 - accuracy: 0.7889 - val_loss: 0.4223 - val_accuracy: 0.8131\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.4317 - val_accuracy: 0.8200\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4621 - accuracy: 0.7793 - val_loss: 0.4155 - val_accuracy: 0.8256\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4720 - accuracy: 0.7850 - val_loss: 0.4290 - val_accuracy: 0.8200\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4625 - accuracy: 0.7831 - val_loss: 0.4261 - val_accuracy: 0.8155\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4577 - accuracy: 0.7844 - val_loss: 0.4389 - val_accuracy: 0.7898\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4595 - accuracy: 0.7832 - val_loss: 0.4302 - val_accuracy: 0.7689\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4704 - accuracy: 0.7807 - val_loss: 0.4287 - val_accuracy: 0.8165\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4650 - accuracy: 0.7805 - val_loss: 0.4286 - val_accuracy: 0.7603\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4599 - accuracy: 0.7770 - val_loss: 0.4271 - val_accuracy: 0.8117\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4650 - accuracy: 0.7784 - val_loss: 0.4266 - val_accuracy: 0.7599\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4610 - accuracy: 0.7805 - val_loss: 0.4324 - val_accuracy: 0.7474\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4619 - accuracy: 0.7802 - val_loss: 0.4402 - val_accuracy: 0.8259\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4569 - accuracy: 0.7860 - val_loss: 0.4230 - val_accuracy: 0.8252\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5391 - accuracy: 0.7739 - val_loss: 0.4297 - val_accuracy: 0.7436\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4641 - accuracy: 0.7768 - val_loss: 0.4166 - val_accuracy: 0.8026\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4606 - accuracy: 0.7829 - val_loss: 0.4285 - val_accuracy: 0.7543\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4630 - accuracy: 0.7873 - val_loss: 0.4218 - val_accuracy: 0.8072\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4721 - accuracy: 0.7810 - val_loss: 0.4223 - val_accuracy: 0.7550\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4582 - accuracy: 0.7826 - val_loss: 0.4158 - val_accuracy: 0.8242\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4557 - accuracy: 0.7870 - val_loss: 0.4068 - val_accuracy: 0.8235\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4606 - accuracy: 0.7896 - val_loss: 0.4220 - val_accuracy: 0.8169\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4522 - accuracy: 0.7885 - val_loss: 0.4246 - val_accuracy: 0.8224\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4584 - accuracy: 0.7833 - val_loss: 0.4155 - val_accuracy: 0.8218\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4539 - accuracy: 0.7856 - val_loss: 0.4121 - val_accuracy: 0.7922\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4621 - accuracy: 0.7904 - val_loss: 0.4111 - val_accuracy: 0.8186\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.4162 - val_accuracy: 0.8263\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4617 - accuracy: 0.7843 - val_loss: 0.4132 - val_accuracy: 0.8224\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4583 - accuracy: 0.7878 - val_loss: 0.4081 - val_accuracy: 0.8211\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4592 - accuracy: 0.7889 - val_loss: 0.4212 - val_accuracy: 0.8207\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4528 - accuracy: 0.7881 - val_loss: 0.4143 - val_accuracy: 0.8165\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4592 - accuracy: 0.7837 - val_loss: 0.4223 - val_accuracy: 0.7808\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4580 - accuracy: 0.7911 - val_loss: 0.4107 - val_accuracy: 0.8245\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4836 - accuracy: 0.7885 - val_loss: 0.4051 - val_accuracy: 0.8231\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4678 - accuracy: 0.7875 - val_loss: 0.4118 - val_accuracy: 0.8231\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4587 - accuracy: 0.7856 - val_loss: 0.4098 - val_accuracy: 0.8165\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4568 - accuracy: 0.7860 - val_loss: 0.4143 - val_accuracy: 0.8214\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4684 - accuracy: 0.7896 - val_loss: 0.4108 - val_accuracy: 0.8207\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4738 - accuracy: 0.7825 - val_loss: 0.4150 - val_accuracy: 0.8207\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4648 - accuracy: 0.7881 - val_loss: 0.4120 - val_accuracy: 0.8242\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4720 - accuracy: 0.7828 - val_loss: 0.4299 - val_accuracy: 0.8214\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4634 - accuracy: 0.7816 - val_loss: 0.4281 - val_accuracy: 0.7554\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4638 - accuracy: 0.7827 - val_loss: 0.4278 - val_accuracy: 0.8148\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4862 - accuracy: 0.7811 - val_loss: 0.4195 - val_accuracy: 0.7578\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4641 - accuracy: 0.7868 - val_loss: 0.4329 - val_accuracy: 0.8242\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4616 - accuracy: 0.7909 - val_loss: 0.4236 - val_accuracy: 0.8242\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4681 - accuracy: 0.7843 - val_loss: 0.4328 - val_accuracy: 0.7808\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4936 - accuracy: 0.7818 - val_loss: 0.4349 - val_accuracy: 0.8190\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4644 - accuracy: 0.7752 - val_loss: 0.4296 - val_accuracy: 0.7773\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4594 - accuracy: 0.7806 - val_loss: 0.4277 - val_accuracy: 0.7644\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4577 - accuracy: 0.7901 - val_loss: 0.4235 - val_accuracy: 0.8231\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4555 - accuracy: 0.7860 - val_loss: 0.4217 - val_accuracy: 0.8238\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4996 - accuracy: 0.7798 - val_loss: 0.4260 - val_accuracy: 0.8183\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4677 - accuracy: 0.7788 - val_loss: 0.4219 - val_accuracy: 0.8221\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4554 - accuracy: 0.7903 - val_loss: 0.4342 - val_accuracy: 0.8249\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.4299 - val_accuracy: 0.8214\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4724 - accuracy: 0.7780 - val_loss: 0.4450 - val_accuracy: 0.8054\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4639 - accuracy: 0.7786 - val_loss: 0.4207 - val_accuracy: 0.8179\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4548 - accuracy: 0.7830 - val_loss: 0.4309 - val_accuracy: 0.7627\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4918 - accuracy: 0.7849 - val_loss: 0.4285 - val_accuracy: 0.7637\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4568 - accuracy: 0.7820 - val_loss: 0.4280 - val_accuracy: 0.7530\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4556 - accuracy: 0.7855 - val_loss: 0.4315 - val_accuracy: 0.7401\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4510 - accuracy: 0.7825 - val_loss: 0.4181 - val_accuracy: 0.7578\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4748 - accuracy: 0.7843 - val_loss: 0.4333 - val_accuracy: 0.7495\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4547 - accuracy: 0.7884 - val_loss: 0.4311 - val_accuracy: 0.7651\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4365 - val_accuracy: 0.7536\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4626 - accuracy: 0.7833 - val_loss: 0.4188 - val_accuracy: 0.7929\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4615 - accuracy: 0.7902 - val_loss: 0.4216 - val_accuracy: 0.8207\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4508 - accuracy: 0.7926 - val_loss: 0.4144 - val_accuracy: 0.8193\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4645 - accuracy: 0.7834 - val_loss: 0.4329 - val_accuracy: 0.8075\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4764 - accuracy: 0.7746 - val_loss: 0.4315 - val_accuracy: 0.8061\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4605 - accuracy: 0.7827 - val_loss: 0.4289 - val_accuracy: 0.8127\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4527 - accuracy: 0.7862 - val_loss: 0.4102 - val_accuracy: 0.8120\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4592 - accuracy: 0.7891 - val_loss: 0.4361 - val_accuracy: 0.8138\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4611 - accuracy: 0.7850 - val_loss: 0.4385 - val_accuracy: 0.8099\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4552 - accuracy: 0.7844 - val_loss: 0.4159 - val_accuracy: 0.8120\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4753 - accuracy: 0.7811 - val_loss: 0.4411 - val_accuracy: 0.7512\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4684 - accuracy: 0.7695 - val_loss: 0.4390 - val_accuracy: 0.7686\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4684 - accuracy: 0.7823 - val_loss: 0.4385 - val_accuracy: 0.7933\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5325 - accuracy: 0.7763 - val_loss: 0.4540 - val_accuracy: 0.7540\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4769 - accuracy: 0.7713 - val_loss: 0.4632 - val_accuracy: 0.7596\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4670 - accuracy: 0.7763 - val_loss: 0.4345 - val_accuracy: 0.8165\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4732 - accuracy: 0.7816 - val_loss: 0.4360 - val_accuracy: 0.8106\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7770 - val_loss: 0.4323 - val_accuracy: 0.8235\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4578 - accuracy: 0.7818 - val_loss: 0.4326 - val_accuracy: 0.7748\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4637 - accuracy: 0.7802 - val_loss: 0.4317 - val_accuracy: 0.7825\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4634 - accuracy: 0.7763 - val_loss: 0.4343 - val_accuracy: 0.8155\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4575 - accuracy: 0.7811 - val_loss: 0.4354 - val_accuracy: 0.8124\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4773 - accuracy: 0.7714 - val_loss: 0.4330 - val_accuracy: 0.8127\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4588 - accuracy: 0.7780 - val_loss: 0.4298 - val_accuracy: 0.8131\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4720 - accuracy: 0.7800 - val_loss: 0.4341 - val_accuracy: 0.8186\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4583 - accuracy: 0.7822 - val_loss: 0.4263 - val_accuracy: 0.8183\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4680 - accuracy: 0.7841 - val_loss: 0.4320 - val_accuracy: 0.7752\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4138 - val_accuracy: 0.8249\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4516 - accuracy: 0.7878 - val_loss: 0.4076 - val_accuracy: 0.8266\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4581 - accuracy: 0.7841 - val_loss: 0.4345 - val_accuracy: 0.8197\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4605 - accuracy: 0.7813 - val_loss: 0.4177 - val_accuracy: 0.8162\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4658 - accuracy: 0.7775 - val_loss: 0.4179 - val_accuracy: 0.8211\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4594 - accuracy: 0.7902 - val_loss: 0.4338 - val_accuracy: 0.8207\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4500 - accuracy: 0.7919 - val_loss: 0.4013 - val_accuracy: 0.8224\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4601 - accuracy: 0.7868 - val_loss: 0.4141 - val_accuracy: 0.8141\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4710 - accuracy: 0.7889 - val_loss: 0.4158 - val_accuracy: 0.8186\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4988 - accuracy: 0.7855 - val_loss: 0.4249 - val_accuracy: 0.8207\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4635 - accuracy: 0.7796 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4563 - accuracy: 0.7824 - val_loss: 0.4147 - val_accuracy: 0.8211\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4521 - accuracy: 0.7895 - val_loss: 0.4141 - val_accuracy: 0.8193\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4627 - accuracy: 0.7888 - val_loss: 0.4213 - val_accuracy: 0.8211\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4870 - accuracy: 0.7803 - val_loss: 0.4188 - val_accuracy: 0.8131\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4584 - accuracy: 0.7818 - val_loss: 0.4230 - val_accuracy: 0.7564\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7715 - val_loss: 0.4297 - val_accuracy: 0.8106\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4552 - accuracy: 0.7891 - val_loss: 0.4285 - val_accuracy: 0.8124\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4621 - accuracy: 0.7786 - val_loss: 0.4308 - val_accuracy: 0.7536\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5234 - accuracy: 0.7780 - val_loss: 0.4413 - val_accuracy: 0.8002\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7783 - val_loss: 0.4444 - val_accuracy: 0.8117\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4732 - accuracy: 0.7777 - val_loss: 0.4314 - val_accuracy: 0.8072\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4671 - accuracy: 0.7763 - val_loss: 0.4360 - val_accuracy: 0.8145\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4736 - accuracy: 0.7790 - val_loss: 0.4299 - val_accuracy: 0.8054\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4683 - accuracy: 0.7802 - val_loss: 0.4396 - val_accuracy: 0.8145\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4735 - accuracy: 0.7803 - val_loss: 0.4394 - val_accuracy: 0.7592\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4612 - accuracy: 0.7833 - val_loss: 0.4189 - val_accuracy: 0.8179\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4583 - accuracy: 0.7889 - val_loss: 0.4249 - val_accuracy: 0.8176\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4618 - accuracy: 0.7823 - val_loss: 0.4323 - val_accuracy: 0.8158\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4573 - accuracy: 0.7840 - val_loss: 0.4318 - val_accuracy: 0.8165\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4781 - accuracy: 0.7808 - val_loss: 0.4367 - val_accuracy: 0.7620\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4579 - accuracy: 0.7810 - val_loss: 0.4286 - val_accuracy: 0.7894\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4568 - accuracy: 0.7869 - val_loss: 0.4285 - val_accuracy: 0.8037\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4616 - accuracy: 0.7850 - val_loss: 0.4299 - val_accuracy: 0.8085\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4762 - accuracy: 0.7845 - val_loss: 0.4469 - val_accuracy: 0.8124\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4741 - accuracy: 0.7803 - val_loss: 0.4336 - val_accuracy: 0.8065\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4811 - accuracy: 0.7730 - val_loss: 0.4478 - val_accuracy: 0.8124\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4717 - accuracy: 0.7788 - val_loss: 0.4401 - val_accuracy: 0.7870\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4693 - accuracy: 0.7770 - val_loss: 0.4303 - val_accuracy: 0.7738\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4887 - accuracy: 0.7840 - val_loss: 0.4258 - val_accuracy: 0.8214\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4687 - accuracy: 0.7815 - val_loss: 0.4220 - val_accuracy: 0.8183\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4647 - accuracy: 0.7902 - val_loss: 0.4338 - val_accuracy: 0.8207\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4843 - accuracy: 0.7821 - val_loss: 0.4575 - val_accuracy: 0.8190\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4684 - accuracy: 0.7866 - val_loss: 0.4383 - val_accuracy: 0.8190\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4678 - accuracy: 0.7881 - val_loss: 0.4172 - val_accuracy: 0.8155\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4644 - accuracy: 0.7868 - val_loss: 0.4162 - val_accuracy: 0.8207\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4548 - accuracy: 0.7921 - val_loss: 0.4096 - val_accuracy: 0.8256\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4544 - accuracy: 0.7910 - val_loss: 0.4127 - val_accuracy: 0.8221\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4625 - accuracy: 0.7881 - val_loss: 0.4267 - val_accuracy: 0.8145\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4594 - accuracy: 0.7897 - val_loss: 0.4095 - val_accuracy: 0.8183\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4547 - accuracy: 0.7908 - val_loss: 0.4177 - val_accuracy: 0.8235\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4623 - accuracy: 0.7920 - val_loss: 0.4181 - val_accuracy: 0.8214\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4671 - accuracy: 0.7869 - val_loss: 0.4239 - val_accuracy: 0.8186\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4678 - accuracy: 0.7863 - val_loss: 0.4219 - val_accuracy: 0.8204\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4591 - accuracy: 0.7896 - val_loss: 0.4282 - val_accuracy: 0.8183\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7852 - val_loss: 0.4163 - val_accuracy: 0.8172\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4633 - accuracy: 0.7904 - val_loss: 0.4208 - val_accuracy: 0.8193\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4531 - accuracy: 0.7936 - val_loss: 0.4185 - val_accuracy: 0.8238\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4901 - accuracy: 0.7865 - val_loss: 0.4196 - val_accuracy: 0.8231\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4659 - accuracy: 0.7866 - val_loss: 0.4195 - val_accuracy: 0.8218\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4648 - accuracy: 0.7937 - val_loss: 0.4300 - val_accuracy: 0.8204\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4659 - accuracy: 0.7843 - val_loss: 0.4098 - val_accuracy: 0.8169\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4701 - accuracy: 0.7896 - val_loss: 0.4158 - val_accuracy: 0.8207\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4597 - accuracy: 0.7950 - val_loss: 0.4204 - val_accuracy: 0.8224\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4578 - accuracy: 0.7881 - val_loss: 0.4338 - val_accuracy: 0.8120\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4669 - accuracy: 0.7820 - val_loss: 0.4296 - val_accuracy: 0.8211\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4699 - accuracy: 0.7912 - val_loss: 0.4207 - val_accuracy: 0.8106\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4667 - accuracy: 0.7794 - val_loss: 0.4296 - val_accuracy: 0.8085\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4614 - accuracy: 0.7852 - val_loss: 0.4230 - val_accuracy: 0.8044\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4637 - accuracy: 0.7869 - val_loss: 0.4220 - val_accuracy: 0.8138\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4996 - accuracy: 0.7868 - val_loss: 0.4302 - val_accuracy: 0.8117\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4675 - accuracy: 0.7851 - val_loss: 0.4379 - val_accuracy: 0.8096\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4719 - accuracy: 0.7786 - val_loss: 0.4322 - val_accuracy: 0.8134\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.4622 - accuracy: 0.7791 - val_loss: 0.4154 - val_accuracy: 0.8165\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4722 - accuracy: 0.7754 - val_loss: 0.4356 - val_accuracy: 0.8138\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4644 - accuracy: 0.7827 - val_loss: 0.4278 - val_accuracy: 0.8092\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4686 - accuracy: 0.7815 - val_loss: 0.4260 - val_accuracy: 0.8120\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4678 - accuracy: 0.7827 - val_loss: 0.4286 - val_accuracy: 0.8068\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4629 - accuracy: 0.7889 - val_loss: 0.4130 - val_accuracy: 0.8134\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4648 - accuracy: 0.7919 - val_loss: 0.4228 - val_accuracy: 0.8155\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4665 - accuracy: 0.7863 - val_loss: 0.4202 - val_accuracy: 0.8134\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4696 - accuracy: 0.7863 - val_loss: 0.4325 - val_accuracy: 0.8145\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4636 - accuracy: 0.7886 - val_loss: 0.4364 - val_accuracy: 0.8186\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4615 - accuracy: 0.7899 - val_loss: 0.4265 - val_accuracy: 0.8186\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4654 - accuracy: 0.7912 - val_loss: 0.4286 - val_accuracy: 0.8204\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4726 - accuracy: 0.7883 - val_loss: 0.4298 - val_accuracy: 0.8207\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4756 - accuracy: 0.7798 - val_loss: 0.4307 - val_accuracy: 0.8218\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5410 - accuracy: 0.7883 - val_loss: 0.4402 - val_accuracy: 0.8242\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4783 - accuracy: 0.7781 - val_loss: 0.4466 - val_accuracy: 0.8106\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4770 - accuracy: 0.7876 - val_loss: 0.4447 - val_accuracy: 0.8218\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4871 - accuracy: 0.7830 - val_loss: 0.4581 - val_accuracy: 0.8207\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4927 - accuracy: 0.7836 - val_loss: 0.4507 - val_accuracy: 0.8207\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5341 - accuracy: 0.7746 - val_loss: 0.4534 - val_accuracy: 0.8124\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4843 - accuracy: 0.7710 - val_loss: 0.4422 - val_accuracy: 0.8120\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4430 - val_accuracy: 0.8106\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4801 - accuracy: 0.7758 - val_loss: 0.4268 - val_accuracy: 0.8103\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4845 - accuracy: 0.7797 - val_loss: 0.4343 - val_accuracy: 0.8117\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4683 - accuracy: 0.7816 - val_loss: 0.4251 - val_accuracy: 0.8106\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4665 - accuracy: 0.7837 - val_loss: 0.4211 - val_accuracy: 0.8138\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4747 - accuracy: 0.7857 - val_loss: 0.4432 - val_accuracy: 0.8151\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4818 - accuracy: 0.7808 - val_loss: 0.4314 - val_accuracy: 0.8124\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4816 - accuracy: 0.7799 - val_loss: 0.4355 - val_accuracy: 0.8131\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4692 - accuracy: 0.7776 - val_loss: 0.4341 - val_accuracy: 0.8099\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4792 - accuracy: 0.7779 - val_loss: 0.4486 - val_accuracy: 0.8058\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4721 - accuracy: 0.7771 - val_loss: 0.4367 - val_accuracy: 0.8138\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5083 - accuracy: 0.7815 - val_loss: 0.4384 - val_accuracy: 0.8145\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4727 - accuracy: 0.7760 - val_loss: 0.4399 - val_accuracy: 0.8082\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4690 - accuracy: 0.7783 - val_loss: 0.4394 - val_accuracy: 0.8113\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4814 - accuracy: 0.7715 - val_loss: 0.4383 - val_accuracy: 0.8165\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4680 - accuracy: 0.7814 - val_loss: 0.4379 - val_accuracy: 0.8113\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4667 - accuracy: 0.7777 - val_loss: 0.4377 - val_accuracy: 0.8211\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4788 - accuracy: 0.7818 - val_loss: 0.4371 - val_accuracy: 0.8138\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4725 - accuracy: 0.7793 - val_loss: 0.4413 - val_accuracy: 0.8193\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4681 - accuracy: 0.7817 - val_loss: 0.4354 - val_accuracy: 0.8193\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4341 - val_accuracy: 0.8200\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4668 - accuracy: 0.7843 - val_loss: 0.4227 - val_accuracy: 0.8197\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7864 - val_loss: 0.4502 - val_accuracy: 0.8120\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4683 - accuracy: 0.7821 - val_loss: 0.4277 - val_accuracy: 0.8242\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4567 - accuracy: 0.7945 - val_loss: 0.4231 - val_accuracy: 0.8224\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4679 - accuracy: 0.7866 - val_loss: 0.4282 - val_accuracy: 0.8099\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4647 - accuracy: 0.7856 - val_loss: 0.4179 - val_accuracy: 0.8176\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4122 - val_accuracy: 0.8245\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4698 - accuracy: 0.7885 - val_loss: 0.4287 - val_accuracy: 0.8120\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4823 - accuracy: 0.7855 - val_loss: 0.4339 - val_accuracy: 0.8183\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4768 - accuracy: 0.7898 - val_loss: 0.4290 - val_accuracy: 0.8193\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4652 - accuracy: 0.7853 - val_loss: 0.4439 - val_accuracy: 0.8092\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.4349 - val_accuracy: 0.8186\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4812 - accuracy: 0.7788 - val_loss: 0.4266 - val_accuracy: 0.8151\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4836 - accuracy: 0.7761 - val_loss: 0.4247 - val_accuracy: 0.8155\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4695 - accuracy: 0.7779 - val_loss: 0.4404 - val_accuracy: 0.8138\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4684 - accuracy: 0.7777 - val_loss: 0.4369 - val_accuracy: 0.8124\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4676 - accuracy: 0.7836 - val_loss: 0.4408 - val_accuracy: 0.8162\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4746 - accuracy: 0.7763 - val_loss: 0.4273 - val_accuracy: 0.8190\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4701 - accuracy: 0.7754 - val_loss: 0.4315 - val_accuracy: 0.8207\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5328 - accuracy: 0.7804 - val_loss: 0.4354 - val_accuracy: 0.8127\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4717 - accuracy: 0.7824 - val_loss: 0.4280 - val_accuracy: 0.8155\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4759 - accuracy: 0.7816 - val_loss: 0.4503 - val_accuracy: 0.8183\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4668 - accuracy: 0.7835 - val_loss: 0.4260 - val_accuracy: 0.8172\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4714 - accuracy: 0.7879 - val_loss: 0.4330 - val_accuracy: 0.8134\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4753 - accuracy: 0.7815 - val_loss: 0.4290 - val_accuracy: 0.8103\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4778 - accuracy: 0.7851 - val_loss: 0.4338 - val_accuracy: 0.8089\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4785 - accuracy: 0.7812 - val_loss: 0.4325 - val_accuracy: 0.8120\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4682 - accuracy: 0.7827 - val_loss: 0.4262 - val_accuracy: 0.8134\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4589 - accuracy: 0.7857 - val_loss: 0.4368 - val_accuracy: 0.8197\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4636 - accuracy: 0.7859 - val_loss: 0.4264 - val_accuracy: 0.8148\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4875 - accuracy: 0.7900 - val_loss: 0.4487 - val_accuracy: 0.8151\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4649 - accuracy: 0.7891 - val_loss: 0.4476 - val_accuracy: 0.8148\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4679 - accuracy: 0.7821 - val_loss: 0.4296 - val_accuracy: 0.8145\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4651 - accuracy: 0.7937 - val_loss: 0.4326 - val_accuracy: 0.8124\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4581 - accuracy: 0.7933 - val_loss: 0.4215 - val_accuracy: 0.8075\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4647 - accuracy: 0.7856 - val_loss: 0.4563 - val_accuracy: 0.8019\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4655 - accuracy: 0.7869 - val_loss: 0.4222 - val_accuracy: 0.8238\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4718 - accuracy: 0.7832 - val_loss: 0.4379 - val_accuracy: 0.8134\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4616 - accuracy: 0.7889 - val_loss: 0.4395 - val_accuracy: 0.8193\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4732 - accuracy: 0.7849 - val_loss: 0.4321 - val_accuracy: 0.8162\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4682 - accuracy: 0.7857 - val_loss: 0.4301 - val_accuracy: 0.8238\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4670 - accuracy: 0.7926 - val_loss: 0.4185 - val_accuracy: 0.8242\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4608 - accuracy: 0.7861 - val_loss: 0.4329 - val_accuracy: 0.8218\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4628 - accuracy: 0.7864 - val_loss: 0.4178 - val_accuracy: 0.8214\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4620 - accuracy: 0.7858 - val_loss: 0.4250 - val_accuracy: 0.8165\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4895 - accuracy: 0.7851 - val_loss: 0.4330 - val_accuracy: 0.8158\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4778 - accuracy: 0.7757 - val_loss: 0.4301 - val_accuracy: 0.8148\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4758 - accuracy: 0.7813 - val_loss: 0.4226 - val_accuracy: 0.8079\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4797 - accuracy: 0.7798 - val_loss: 0.4247 - val_accuracy: 0.8145\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4787 - accuracy: 0.7845 - val_loss: 0.4330 - val_accuracy: 0.8148\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4760 - accuracy: 0.7849 - val_loss: 0.4290 - val_accuracy: 0.8099\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4714 - accuracy: 0.7803 - val_loss: 0.4307 - val_accuracy: 0.8169\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4885 - accuracy: 0.7843 - val_loss: 0.4317 - val_accuracy: 0.8092\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4752 - accuracy: 0.7850 - val_loss: 0.4248 - val_accuracy: 0.8151\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4667 - accuracy: 0.7869 - val_loss: 0.4262 - val_accuracy: 0.8155\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4688 - accuracy: 0.7802 - val_loss: 0.4420 - val_accuracy: 0.8110\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.4774 - accuracy: 0.7865 - val_loss: 0.4278 - val_accuracy: 0.8145\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4698 - accuracy: 0.7861 - val_loss: 0.4350 - val_accuracy: 0.8124\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4734 - accuracy: 0.7805 - val_loss: 0.4361 - val_accuracy: 0.8131\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4721 - accuracy: 0.7839 - val_loss: 0.4267 - val_accuracy: 0.8172\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4681 - accuracy: 0.7834 - val_loss: 0.4223 - val_accuracy: 0.8127\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4725 - accuracy: 0.7863 - val_loss: 0.4353 - val_accuracy: 0.8082\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4797 - accuracy: 0.7783 - val_loss: 0.4421 - val_accuracy: 0.8089\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4668 - accuracy: 0.7805 - val_loss: 0.4336 - val_accuracy: 0.8079\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5136 - accuracy: 0.7767 - val_loss: 0.4551 - val_accuracy: 0.7953\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4812 - accuracy: 0.7774 - val_loss: 0.4514 - val_accuracy: 0.8044\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4844 - accuracy: 0.7774 - val_loss: 0.4399 - val_accuracy: 0.8037\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4779 - accuracy: 0.7836 - val_loss: 0.4327 - val_accuracy: 0.8033\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4712 - accuracy: 0.7860 - val_loss: 0.4418 - val_accuracy: 0.8016\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4723 - accuracy: 0.7757 - val_loss: 0.4431 - val_accuracy: 0.8092\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5040 - accuracy: 0.7744 - val_loss: 0.4491 - val_accuracy: 0.8169\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4906 - accuracy: 0.7663 - val_loss: 0.4497 - val_accuracy: 0.8106\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4773 - accuracy: 0.7720 - val_loss: 0.4391 - val_accuracy: 0.8096\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4816 - accuracy: 0.7772 - val_loss: 0.4398 - val_accuracy: 0.8075\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4719 - accuracy: 0.7869 - val_loss: 0.4285 - val_accuracy: 0.8033\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4813 - accuracy: 0.7834 - val_loss: 0.4450 - val_accuracy: 0.8089\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4733 - accuracy: 0.7838 - val_loss: 0.4465 - val_accuracy: 0.8037\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4740 - accuracy: 0.7829 - val_loss: 0.4573 - val_accuracy: 0.7967\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4790 - accuracy: 0.7735 - val_loss: 0.4440 - val_accuracy: 0.7971\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4718 - accuracy: 0.7782 - val_loss: 0.4314 - val_accuracy: 0.8037\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4790 - accuracy: 0.7786 - val_loss: 0.4453 - val_accuracy: 0.8079\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4881 - accuracy: 0.7742 - val_loss: 0.4409 - val_accuracy: 0.8103\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4943 - accuracy: 0.7678 - val_loss: 0.4430 - val_accuracy: 0.8079\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4716 - accuracy: 0.7761 - val_loss: 0.4477 - val_accuracy: 0.8082\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4809 - accuracy: 0.7755 - val_loss: 0.4448 - val_accuracy: 0.8033\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4981 - accuracy: 0.7759 - val_loss: 0.4549 - val_accuracy: 0.8051\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4775 - accuracy: 0.7778 - val_loss: 0.4331 - val_accuracy: 0.8113\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4793 - accuracy: 0.7740 - val_loss: 0.4362 - val_accuracy: 0.8110\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4752 - accuracy: 0.7748 - val_loss: 0.4388 - val_accuracy: 0.8013\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4896 - accuracy: 0.7731 - val_loss: 0.4442 - val_accuracy: 0.8106\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5040 - accuracy: 0.7763 - val_loss: 0.4291 - val_accuracy: 0.8089\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4933 - accuracy: 0.7784 - val_loss: 0.4388 - val_accuracy: 0.8092\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4711 - accuracy: 0.7817 - val_loss: 0.4328 - val_accuracy: 0.8158\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.4416 - val_accuracy: 0.8145\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4777 - accuracy: 0.7790 - val_loss: 0.4513 - val_accuracy: 0.8127\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4716 - accuracy: 0.7830 - val_loss: 0.4420 - val_accuracy: 0.8169\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4765 - accuracy: 0.7696 - val_loss: 0.4311 - val_accuracy: 0.8106\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4680 - accuracy: 0.7796 - val_loss: 0.4393 - val_accuracy: 0.8054\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4767 - accuracy: 0.7757 - val_loss: 0.4412 - val_accuracy: 0.8183\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4659 - accuracy: 0.7823 - val_loss: 0.4441 - val_accuracy: 0.8106\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4621 - accuracy: 0.7816 - val_loss: 0.4430 - val_accuracy: 0.8103\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4704 - accuracy: 0.7775 - val_loss: 0.4427 - val_accuracy: 0.8103\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4706 - accuracy: 0.7782 - val_loss: 0.4534 - val_accuracy: 0.8113\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5324 - accuracy: 0.7770 - val_loss: 0.4507 - val_accuracy: 0.7946\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4791 - accuracy: 0.7770 - val_loss: 0.4458 - val_accuracy: 0.8061\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.4859 - accuracy: 0.7761 - val_loss: 0.4477 - val_accuracy: 0.8079\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4804 - accuracy: 0.7815 - val_loss: 0.4482 - val_accuracy: 0.8127\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4732 - accuracy: 0.7806 - val_loss: 0.4322 - val_accuracy: 0.8113\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4835 - accuracy: 0.7783 - val_loss: 0.4484 - val_accuracy: 0.8085\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4827 - accuracy: 0.7822 - val_loss: 0.4289 - val_accuracy: 0.8134\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4730 - accuracy: 0.7830 - val_loss: 0.4327 - val_accuracy: 0.8110\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4717 - accuracy: 0.7892 - val_loss: 0.4444 - val_accuracy: 0.8110\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4795 - accuracy: 0.7832 - val_loss: 0.4450 - val_accuracy: 0.8072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4096*2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_scaled, y_val_categorical)\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dropouts at a rate at 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1048)              537624    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1048)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2048)              2148352   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 8192)              33562624  \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 57,420,634\n",
      "Trainable params: 57,420,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      " 1/90 [..............................] - ETA: 2s - loss: 0.6950 - accuracy: 0.4609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.6131 - accuracy: 0.7243 - val_loss: 0.5622 - val_accuracy: 0.7345\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5713 - accuracy: 0.7273 - val_loss: 0.5553 - val_accuracy: 0.7345\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5652 - accuracy: 0.7272 - val_loss: 0.5342 - val_accuracy: 0.7349\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5547 - accuracy: 0.7286 - val_loss: 0.5409 - val_accuracy: 0.7345\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5487 - accuracy: 0.7298 - val_loss: 0.5292 - val_accuracy: 0.7345\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5375 - accuracy: 0.7313 - val_loss: 0.5521 - val_accuracy: 0.6942\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5356 - accuracy: 0.7339 - val_loss: 0.5109 - val_accuracy: 0.7543\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5285 - accuracy: 0.7431 - val_loss: 0.4944 - val_accuracy: 0.7780\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5208 - accuracy: 0.7415 - val_loss: 0.4907 - val_accuracy: 0.7516\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.5160 - accuracy: 0.7498 - val_loss: 0.4873 - val_accuracy: 0.7554\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.5075 - accuracy: 0.7540 - val_loss: 0.4687 - val_accuracy: 0.7675\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.5048 - accuracy: 0.7568 - val_loss: 0.4737 - val_accuracy: 0.7842\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5000 - accuracy: 0.7622 - val_loss: 0.4592 - val_accuracy: 0.7887\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4976 - accuracy: 0.7625 - val_loss: 0.4675 - val_accuracy: 0.7856\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4949 - accuracy: 0.7642 - val_loss: 0.4578 - val_accuracy: 0.7814\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4867 - accuracy: 0.7728 - val_loss: 0.4584 - val_accuracy: 0.7887\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4877 - accuracy: 0.7674 - val_loss: 0.4780 - val_accuracy: 0.7585\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4816 - accuracy: 0.7695 - val_loss: 0.4264 - val_accuracy: 0.7960\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4793 - accuracy: 0.7696 - val_loss: 0.4522 - val_accuracy: 0.7988\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4755 - accuracy: 0.7777 - val_loss: 0.4337 - val_accuracy: 0.7999\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4729 - accuracy: 0.7828 - val_loss: 0.4298 - val_accuracy: 0.7995\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4736 - accuracy: 0.7757 - val_loss: 0.4466 - val_accuracy: 0.7992\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4687 - accuracy: 0.7800 - val_loss: 0.4229 - val_accuracy: 0.8044\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4600 - accuracy: 0.7820 - val_loss: 0.4224 - val_accuracy: 0.7995\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4635 - accuracy: 0.7798 - val_loss: 0.4111 - val_accuracy: 0.8079\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4625 - accuracy: 0.7870 - val_loss: 0.4273 - val_accuracy: 0.8068\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4582 - accuracy: 0.7856 - val_loss: 0.4355 - val_accuracy: 0.8037\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4553 - accuracy: 0.7855 - val_loss: 0.4035 - val_accuracy: 0.8030\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.4566 - accuracy: 0.7897 - val_loss: 0.4015 - val_accuracy: 0.8026\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4542 - accuracy: 0.7866 - val_loss: 0.4140 - val_accuracy: 0.8099\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4519 - accuracy: 0.7936 - val_loss: 0.4135 - val_accuracy: 0.8165\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4438 - accuracy: 0.7909 - val_loss: 0.3995 - val_accuracy: 0.8193\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4468 - accuracy: 0.7922 - val_loss: 0.3900 - val_accuracy: 0.8134\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4422 - accuracy: 0.7909 - val_loss: 0.3915 - val_accuracy: 0.8151\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4434 - accuracy: 0.7904 - val_loss: 0.3987 - val_accuracy: 0.8110\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4455 - accuracy: 0.7888 - val_loss: 0.3930 - val_accuracy: 0.8148\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4432 - accuracy: 0.7918 - val_loss: 0.3901 - val_accuracy: 0.8127\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4359 - accuracy: 0.7922 - val_loss: 0.3905 - val_accuracy: 0.8183\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4400 - accuracy: 0.7982 - val_loss: 0.3866 - val_accuracy: 0.8183\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.3883 - val_accuracy: 0.8197\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4377 - accuracy: 0.7947 - val_loss: 0.4123 - val_accuracy: 0.8065\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4371 - accuracy: 0.7967 - val_loss: 0.4010 - val_accuracy: 0.8218\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4306 - accuracy: 0.7989 - val_loss: 0.3878 - val_accuracy: 0.8211\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4321 - accuracy: 0.7978 - val_loss: 0.3911 - val_accuracy: 0.8228\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4268 - accuracy: 0.8019 - val_loss: 0.3873 - val_accuracy: 0.8256\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4264 - accuracy: 0.8049 - val_loss: 0.3804 - val_accuracy: 0.8297\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4247 - accuracy: 0.8035 - val_loss: 0.3817 - val_accuracy: 0.8259\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4272 - accuracy: 0.8023 - val_loss: 0.3940 - val_accuracy: 0.8204\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4261 - accuracy: 0.7975 - val_loss: 0.3914 - val_accuracy: 0.8207\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4295 - accuracy: 0.8035 - val_loss: 0.3776 - val_accuracy: 0.8304\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4222 - accuracy: 0.8095 - val_loss: 0.3850 - val_accuracy: 0.8259\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4188 - accuracy: 0.8051 - val_loss: 0.3830 - val_accuracy: 0.8263\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4261 - accuracy: 0.8068 - val_loss: 0.3766 - val_accuracy: 0.8294\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4217 - accuracy: 0.8078 - val_loss: 0.3697 - val_accuracy: 0.8266\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4241 - accuracy: 0.8008 - val_loss: 0.3829 - val_accuracy: 0.8280\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4209 - accuracy: 0.8062 - val_loss: 0.3725 - val_accuracy: 0.8318\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4247 - accuracy: 0.8030 - val_loss: 0.3777 - val_accuracy: 0.8329\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4202 - accuracy: 0.8035 - val_loss: 0.3720 - val_accuracy: 0.8329\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4143 - accuracy: 0.8098 - val_loss: 0.3703 - val_accuracy: 0.8356\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4130 - accuracy: 0.8086 - val_loss: 0.3739 - val_accuracy: 0.8304\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4121 - accuracy: 0.8101 - val_loss: 0.3790 - val_accuracy: 0.8273\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4153 - accuracy: 0.8099 - val_loss: 0.3860 - val_accuracy: 0.8346\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4138 - accuracy: 0.8096 - val_loss: 0.3760 - val_accuracy: 0.8391\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4143 - accuracy: 0.8094 - val_loss: 0.3711 - val_accuracy: 0.8402\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4121 - accuracy: 0.8110 - val_loss: 0.3711 - val_accuracy: 0.8367\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4047 - accuracy: 0.8174 - val_loss: 0.3654 - val_accuracy: 0.8336\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4081 - accuracy: 0.8131 - val_loss: 0.3609 - val_accuracy: 0.8367\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4052 - accuracy: 0.8170 - val_loss: 0.3594 - val_accuracy: 0.8381\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4033 - accuracy: 0.8174 - val_loss: 0.3658 - val_accuracy: 0.8360\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4061 - accuracy: 0.8168 - val_loss: 0.3614 - val_accuracy: 0.8350\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4074 - accuracy: 0.8160 - val_loss: 0.3748 - val_accuracy: 0.8367\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4040 - accuracy: 0.8146 - val_loss: 0.3789 - val_accuracy: 0.8374\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4081 - accuracy: 0.8141 - val_loss: 0.3593 - val_accuracy: 0.8409\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4100 - accuracy: 0.8168 - val_loss: 0.3650 - val_accuracy: 0.8419\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4133 - accuracy: 0.8184 - val_loss: 0.3618 - val_accuracy: 0.8436\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4067 - accuracy: 0.8141 - val_loss: 0.3674 - val_accuracy: 0.8412\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4031 - accuracy: 0.8201 - val_loss: 0.3639 - val_accuracy: 0.8325\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4036 - accuracy: 0.8154 - val_loss: 0.3526 - val_accuracy: 0.8412\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4003 - accuracy: 0.8154 - val_loss: 0.3643 - val_accuracy: 0.8363\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4052 - accuracy: 0.8147 - val_loss: 0.3607 - val_accuracy: 0.8370\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4069 - accuracy: 0.8226 - val_loss: 0.3629 - val_accuracy: 0.8405\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3970 - accuracy: 0.8175 - val_loss: 0.3572 - val_accuracy: 0.8409\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4020 - accuracy: 0.8211 - val_loss: 0.3608 - val_accuracy: 0.8391\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3987 - accuracy: 0.8220 - val_loss: 0.3592 - val_accuracy: 0.8402\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4014 - accuracy: 0.8188 - val_loss: 0.3531 - val_accuracy: 0.8423\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3992 - accuracy: 0.8187 - val_loss: 0.3618 - val_accuracy: 0.8398\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4005 - accuracy: 0.8164 - val_loss: 0.3645 - val_accuracy: 0.8429\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4081 - accuracy: 0.8141 - val_loss: 0.3511 - val_accuracy: 0.8395\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4002 - accuracy: 0.8227 - val_loss: 0.3607 - val_accuracy: 0.8468\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3930 - accuracy: 0.8175 - val_loss: 0.3552 - val_accuracy: 0.8398\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3970 - accuracy: 0.8217 - val_loss: 0.3545 - val_accuracy: 0.8461\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4013 - accuracy: 0.8189 - val_loss: 0.3549 - val_accuracy: 0.8412\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3987 - accuracy: 0.8235 - val_loss: 0.3522 - val_accuracy: 0.8356\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4022 - accuracy: 0.8232 - val_loss: 0.3580 - val_accuracy: 0.8360\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3994 - accuracy: 0.8198 - val_loss: 0.3537 - val_accuracy: 0.8374\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3968 - accuracy: 0.8242 - val_loss: 0.3632 - val_accuracy: 0.8426\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3939 - accuracy: 0.8244 - val_loss: 0.3496 - val_accuracy: 0.8423\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3896 - accuracy: 0.8241 - val_loss: 0.3520 - val_accuracy: 0.8468\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3935 - accuracy: 0.8253 - val_loss: 0.3557 - val_accuracy: 0.8402\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3916 - accuracy: 0.8248 - val_loss: 0.3601 - val_accuracy: 0.8440\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3978 - accuracy: 0.8254 - val_loss: 0.3571 - val_accuracy: 0.8416\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3912 - accuracy: 0.8243 - val_loss: 0.3531 - val_accuracy: 0.8464\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4148 - accuracy: 0.8249 - val_loss: 0.3532 - val_accuracy: 0.8471\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3904 - accuracy: 0.8246 - val_loss: 0.3504 - val_accuracy: 0.8485\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3849 - accuracy: 0.8275 - val_loss: 0.3450 - val_accuracy: 0.8499\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3919 - accuracy: 0.8249 - val_loss: 0.3510 - val_accuracy: 0.8443\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4056 - accuracy: 0.8228 - val_loss: 0.3560 - val_accuracy: 0.8482\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3933 - accuracy: 0.8275 - val_loss: 0.3487 - val_accuracy: 0.8461\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4027 - accuracy: 0.8195 - val_loss: 0.3463 - val_accuracy: 0.8506\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4044 - accuracy: 0.8184 - val_loss: 0.3671 - val_accuracy: 0.8506\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3971 - accuracy: 0.8200 - val_loss: 0.3552 - val_accuracy: 0.8443\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3934 - accuracy: 0.8218 - val_loss: 0.3503 - val_accuracy: 0.8450\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3870 - accuracy: 0.8261 - val_loss: 0.3488 - val_accuracy: 0.8523\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3885 - accuracy: 0.8241 - val_loss: 0.3501 - val_accuracy: 0.8506\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3891 - accuracy: 0.8246 - val_loss: 0.3504 - val_accuracy: 0.8482\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3918 - accuracy: 0.8210 - val_loss: 0.3528 - val_accuracy: 0.8482\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3863 - accuracy: 0.8264 - val_loss: 0.3501 - val_accuracy: 0.8482\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3924 - accuracy: 0.8208 - val_loss: 0.3602 - val_accuracy: 0.8461\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3890 - accuracy: 0.8200 - val_loss: 0.3484 - val_accuracy: 0.8457\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3833 - accuracy: 0.8270 - val_loss: 0.3530 - val_accuracy: 0.8482\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3832 - accuracy: 0.8289 - val_loss: 0.3908 - val_accuracy: 0.8461\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3941 - accuracy: 0.8275 - val_loss: 0.3512 - val_accuracy: 0.8499\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3849 - accuracy: 0.8242 - val_loss: 0.3516 - val_accuracy: 0.8513\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3925 - accuracy: 0.8282 - val_loss: 0.3488 - val_accuracy: 0.8478\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3877 - accuracy: 0.8272 - val_loss: 0.3455 - val_accuracy: 0.8475\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3825 - accuracy: 0.8275 - val_loss: 0.3468 - val_accuracy: 0.8436\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3804 - accuracy: 0.8236 - val_loss: 0.3512 - val_accuracy: 0.8475\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3800 - accuracy: 0.8305 - val_loss: 0.3447 - val_accuracy: 0.8450\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3773 - accuracy: 0.8294 - val_loss: 0.3463 - val_accuracy: 0.8468\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3859 - accuracy: 0.8254 - val_loss: 0.3501 - val_accuracy: 0.8516\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3859 - accuracy: 0.8229 - val_loss: 0.3487 - val_accuracy: 0.8485\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3870 - accuracy: 0.8279 - val_loss: 0.3483 - val_accuracy: 0.8489\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3983 - accuracy: 0.8268 - val_loss: 0.3554 - val_accuracy: 0.8482\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3922 - accuracy: 0.8236 - val_loss: 0.3637 - val_accuracy: 0.8395\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3946 - accuracy: 0.8260 - val_loss: 0.3483 - val_accuracy: 0.8530\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3885 - accuracy: 0.8254 - val_loss: 0.3480 - val_accuracy: 0.8454\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3900 - accuracy: 0.8251 - val_loss: 0.3469 - val_accuracy: 0.8468\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3812 - accuracy: 0.8301 - val_loss: 0.3441 - val_accuracy: 0.8461\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3908 - accuracy: 0.8254 - val_loss: 0.3675 - val_accuracy: 0.8266\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3982 - accuracy: 0.8182 - val_loss: 0.3534 - val_accuracy: 0.8416\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3895 - accuracy: 0.8279 - val_loss: 0.3536 - val_accuracy: 0.8429\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4189 - accuracy: 0.8207 - val_loss: 0.3469 - val_accuracy: 0.8464\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3938 - accuracy: 0.8250 - val_loss: 0.3676 - val_accuracy: 0.8332\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3957 - accuracy: 0.8176 - val_loss: 0.3611 - val_accuracy: 0.8301\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3898 - accuracy: 0.8249 - val_loss: 0.3582 - val_accuracy: 0.8416\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3965 - accuracy: 0.8245 - val_loss: 0.3522 - val_accuracy: 0.8412\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3840 - accuracy: 0.8294 - val_loss: 0.3524 - val_accuracy: 0.8468\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3828 - accuracy: 0.8274 - val_loss: 0.3442 - val_accuracy: 0.8509\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3885 - accuracy: 0.8266 - val_loss: 0.3505 - val_accuracy: 0.8443\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3882 - accuracy: 0.8289 - val_loss: 0.3556 - val_accuracy: 0.8485\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3820 - accuracy: 0.8249 - val_loss: 0.3580 - val_accuracy: 0.8433\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3896 - accuracy: 0.8267 - val_loss: 0.3501 - val_accuracy: 0.8482\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3852 - accuracy: 0.8307 - val_loss: 0.3574 - val_accuracy: 0.8440\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3891 - accuracy: 0.8272 - val_loss: 0.3473 - val_accuracy: 0.8502\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3888 - accuracy: 0.8232 - val_loss: 0.3523 - val_accuracy: 0.8523\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3804 - accuracy: 0.8288 - val_loss: 0.3556 - val_accuracy: 0.8489\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3849 - accuracy: 0.8291 - val_loss: 0.3460 - val_accuracy: 0.8464\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3775 - accuracy: 0.8263 - val_loss: 0.3517 - val_accuracy: 0.8461\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3752 - accuracy: 0.8316 - val_loss: 0.3446 - val_accuracy: 0.8502\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4164 - accuracy: 0.8287 - val_loss: 0.3549 - val_accuracy: 0.8471\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3848 - accuracy: 0.8332 - val_loss: 0.3473 - val_accuracy: 0.8492\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3892 - accuracy: 0.8283 - val_loss: 0.3485 - val_accuracy: 0.8492\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3823 - accuracy: 0.8274 - val_loss: 0.3481 - val_accuracy: 0.8471\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3848 - accuracy: 0.8294 - val_loss: 0.3550 - val_accuracy: 0.8367\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3765 - accuracy: 0.8303 - val_loss: 0.3539 - val_accuracy: 0.8398\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3853 - accuracy: 0.8255 - val_loss: 0.3485 - val_accuracy: 0.8440\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3806 - accuracy: 0.8295 - val_loss: 0.3544 - val_accuracy: 0.8391\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3879 - accuracy: 0.8283 - val_loss: 0.3450 - val_accuracy: 0.8461\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3868 - accuracy: 0.8269 - val_loss: 0.3473 - val_accuracy: 0.8485\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3784 - accuracy: 0.8336 - val_loss: 0.3460 - val_accuracy: 0.8450\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3878 - accuracy: 0.8276 - val_loss: 0.3513 - val_accuracy: 0.8450\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3774 - accuracy: 0.8282 - val_loss: 0.3482 - val_accuracy: 0.8450\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3863 - accuracy: 0.8247 - val_loss: 0.3611 - val_accuracy: 0.8391\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3806 - accuracy: 0.8294 - val_loss: 0.3440 - val_accuracy: 0.8489\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 0.3849 - accuracy: 0.8307 - val_loss: 0.3466 - val_accuracy: 0.8468\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3916 - accuracy: 0.8274 - val_loss: 0.3522 - val_accuracy: 0.8426\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4072 - accuracy: 0.8248 - val_loss: 0.3538 - val_accuracy: 0.8468\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3857 - accuracy: 0.8277 - val_loss: 0.3484 - val_accuracy: 0.8436\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3880 - accuracy: 0.8304 - val_loss: 0.3455 - val_accuracy: 0.8506\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3781 - accuracy: 0.8316 - val_loss: 0.3509 - val_accuracy: 0.8447\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3868 - accuracy: 0.8341 - val_loss: 0.3531 - val_accuracy: 0.8471\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4001 - accuracy: 0.8288 - val_loss: 0.3524 - val_accuracy: 0.8447\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3769 - accuracy: 0.8306 - val_loss: 0.3549 - val_accuracy: 0.8482\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3940 - accuracy: 0.8302 - val_loss: 0.3390 - val_accuracy: 0.8516\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3873 - accuracy: 0.8234 - val_loss: 0.3451 - val_accuracy: 0.8457\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3901 - accuracy: 0.8312 - val_loss: 0.3682 - val_accuracy: 0.8329\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.3894 - accuracy: 0.8207 - val_loss: 0.3519 - val_accuracy: 0.8409\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3842 - accuracy: 0.8288 - val_loss: 0.3541 - val_accuracy: 0.8374\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3962 - accuracy: 0.8245 - val_loss: 0.3476 - val_accuracy: 0.8468\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3837 - accuracy: 0.8290 - val_loss: 0.3582 - val_accuracy: 0.8429\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3813 - accuracy: 0.8332 - val_loss: 0.3396 - val_accuracy: 0.8461\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.3835 - accuracy: 0.8267 - val_loss: 0.3428 - val_accuracy: 0.8513\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3772 - accuracy: 0.8327 - val_loss: 0.3392 - val_accuracy: 0.8537\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3729 - accuracy: 0.8300 - val_loss: 0.3466 - val_accuracy: 0.8374\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3712 - accuracy: 0.8323 - val_loss: 0.3412 - val_accuracy: 0.8523\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3780 - accuracy: 0.8327 - val_loss: 0.3374 - val_accuracy: 0.8537\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3729 - accuracy: 0.8344 - val_loss: 0.3440 - val_accuracy: 0.8478\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3833 - accuracy: 0.8305 - val_loss: 0.3446 - val_accuracy: 0.8482\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4179 - accuracy: 0.8198 - val_loss: 0.3552 - val_accuracy: 0.8423\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3898 - accuracy: 0.8211 - val_loss: 0.3471 - val_accuracy: 0.8457\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3889 - accuracy: 0.8247 - val_loss: 0.3491 - val_accuracy: 0.8541\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3864 - accuracy: 0.8280 - val_loss: 0.3508 - val_accuracy: 0.8523\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3976 - accuracy: 0.8214 - val_loss: 0.3474 - val_accuracy: 0.8443\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3858 - accuracy: 0.8260 - val_loss: 0.3468 - val_accuracy: 0.8457\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3820 - accuracy: 0.8274 - val_loss: 0.3489 - val_accuracy: 0.8506\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3834 - accuracy: 0.8292 - val_loss: 0.3553 - val_accuracy: 0.8377\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3972 - accuracy: 0.8259 - val_loss: 0.3542 - val_accuracy: 0.8454\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3883 - accuracy: 0.8272 - val_loss: 0.3459 - val_accuracy: 0.8495\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3844 - accuracy: 0.8270 - val_loss: 0.3496 - val_accuracy: 0.8541\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3795 - accuracy: 0.8328 - val_loss: 0.3406 - val_accuracy: 0.8523\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3767 - accuracy: 0.8316 - val_loss: 0.3483 - val_accuracy: 0.8513\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3843 - accuracy: 0.8330 - val_loss: 0.3512 - val_accuracy: 0.8384\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3816 - accuracy: 0.8243 - val_loss: 0.3506 - val_accuracy: 0.8416\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3782 - accuracy: 0.8288 - val_loss: 0.3492 - val_accuracy: 0.8537\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3753 - accuracy: 0.8318 - val_loss: 0.3416 - val_accuracy: 0.8548\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3850 - accuracy: 0.8260 - val_loss: 0.3555 - val_accuracy: 0.8489\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3979 - accuracy: 0.8198 - val_loss: 0.3739 - val_accuracy: 0.8360\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4788 - accuracy: 0.8246 - val_loss: 0.3774 - val_accuracy: 0.8273\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4027 - accuracy: 0.8120 - val_loss: 0.3640 - val_accuracy: 0.8388\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3981 - accuracy: 0.8215 - val_loss: 0.3564 - val_accuracy: 0.8402\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3949 - accuracy: 0.8218 - val_loss: 0.3553 - val_accuracy: 0.8363\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3888 - accuracy: 0.8259 - val_loss: 0.3525 - val_accuracy: 0.8440\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4593 - accuracy: 0.8188 - val_loss: 0.3569 - val_accuracy: 0.8346\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3928 - accuracy: 0.8214 - val_loss: 0.3517 - val_accuracy: 0.8433\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3905 - accuracy: 0.8229 - val_loss: 0.3616 - val_accuracy: 0.8325\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3897 - accuracy: 0.8244 - val_loss: 0.3530 - val_accuracy: 0.8416\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3792 - accuracy: 0.8299 - val_loss: 0.3554 - val_accuracy: 0.8384\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3858 - accuracy: 0.8261 - val_loss: 0.3513 - val_accuracy: 0.8447\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3912 - accuracy: 0.8293 - val_loss: 0.3505 - val_accuracy: 0.8426\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3819 - accuracy: 0.8263 - val_loss: 0.3640 - val_accuracy: 0.8343\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3982 - accuracy: 0.8215 - val_loss: 0.3552 - val_accuracy: 0.8447\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3849 - accuracy: 0.8247 - val_loss: 0.3468 - val_accuracy: 0.8468\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3977 - accuracy: 0.8227 - val_loss: 0.3503 - val_accuracy: 0.8419\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3868 - accuracy: 0.8226 - val_loss: 0.3546 - val_accuracy: 0.8423\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3865 - accuracy: 0.8272 - val_loss: 0.3544 - val_accuracy: 0.8356\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3759 - accuracy: 0.8278 - val_loss: 0.3532 - val_accuracy: 0.8384\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3821 - accuracy: 0.8260 - val_loss: 0.3571 - val_accuracy: 0.8367\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4189 - accuracy: 0.8233 - val_loss: 0.3541 - val_accuracy: 0.8370\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3723 - accuracy: 0.8356 - val_loss: 0.3548 - val_accuracy: 0.8468\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3945 - accuracy: 0.8281 - val_loss: 0.3550 - val_accuracy: 0.8447\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3787 - accuracy: 0.8313 - val_loss: 0.3483 - val_accuracy: 0.8468\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3970 - accuracy: 0.8308 - val_loss: 0.3583 - val_accuracy: 0.8433\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3761 - accuracy: 0.8349 - val_loss: 0.3494 - val_accuracy: 0.8499\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3873 - accuracy: 0.8294 - val_loss: 0.3556 - val_accuracy: 0.8370\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3694 - accuracy: 0.8358 - val_loss: 0.3442 - val_accuracy: 0.8443\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3712 - accuracy: 0.8359 - val_loss: 0.3428 - val_accuracy: 0.8499\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3703 - accuracy: 0.8348 - val_loss: 0.3449 - val_accuracy: 0.8520\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4022 - accuracy: 0.8263 - val_loss: 0.3540 - val_accuracy: 0.8377\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3733 - accuracy: 0.8302 - val_loss: 0.3549 - val_accuracy: 0.8353\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3735 - accuracy: 0.8322 - val_loss: 0.3510 - val_accuracy: 0.8398\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3815 - accuracy: 0.8327 - val_loss: 0.3427 - val_accuracy: 0.8471\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4246 - accuracy: 0.8307 - val_loss: 0.3656 - val_accuracy: 0.8353\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3882 - accuracy: 0.8254 - val_loss: 0.3577 - val_accuracy: 0.8290\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3953 - accuracy: 0.8255 - val_loss: 0.3592 - val_accuracy: 0.8388\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4463 - accuracy: 0.8205 - val_loss: 0.3729 - val_accuracy: 0.8235\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3989 - accuracy: 0.8226 - val_loss: 0.3641 - val_accuracy: 0.8304\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3922 - accuracy: 0.8237 - val_loss: 0.3546 - val_accuracy: 0.8377\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3875 - accuracy: 0.8297 - val_loss: 0.3601 - val_accuracy: 0.8315\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3862 - accuracy: 0.8269 - val_loss: 0.3514 - val_accuracy: 0.8409\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3807 - accuracy: 0.8306 - val_loss: 0.3557 - val_accuracy: 0.8384\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3795 - accuracy: 0.8333 - val_loss: 0.3553 - val_accuracy: 0.8391\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3693 - accuracy: 0.8353 - val_loss: 0.3481 - val_accuracy: 0.8450\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3903 - accuracy: 0.8260 - val_loss: 0.3439 - val_accuracy: 0.8443\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3820 - accuracy: 0.8357 - val_loss: 0.3387 - val_accuracy: 0.8499\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3758 - accuracy: 0.8334 - val_loss: 0.3556 - val_accuracy: 0.8405\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3868 - accuracy: 0.8296 - val_loss: 0.3586 - val_accuracy: 0.8398\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3773 - accuracy: 0.8327 - val_loss: 0.3526 - val_accuracy: 0.8416\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3722 - accuracy: 0.8326 - val_loss: 0.3450 - val_accuracy: 0.8468\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3694 - accuracy: 0.8356 - val_loss: 0.3455 - val_accuracy: 0.8478\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3688 - accuracy: 0.8355 - val_loss: 0.3448 - val_accuracy: 0.8489\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5269 - accuracy: 0.8293 - val_loss: 0.3637 - val_accuracy: 0.8402\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3885 - accuracy: 0.8272 - val_loss: 0.3587 - val_accuracy: 0.8343\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3809 - accuracy: 0.8305 - val_loss: 0.3494 - val_accuracy: 0.8454\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3830 - accuracy: 0.8307 - val_loss: 0.3490 - val_accuracy: 0.8454\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3818 - accuracy: 0.8291 - val_loss: 0.3485 - val_accuracy: 0.8495\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3686 - accuracy: 0.8382 - val_loss: 0.3556 - val_accuracy: 0.8468\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3775 - accuracy: 0.8333 - val_loss: 0.3565 - val_accuracy: 0.8402\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3742 - accuracy: 0.8327 - val_loss: 0.3567 - val_accuracy: 0.8339\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3810 - accuracy: 0.8300 - val_loss: 0.3645 - val_accuracy: 0.8329\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3738 - accuracy: 0.8321 - val_loss: 0.3543 - val_accuracy: 0.8461\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3749 - accuracy: 0.8296 - val_loss: 0.3475 - val_accuracy: 0.8464\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3638 - accuracy: 0.8366 - val_loss: 0.3362 - val_accuracy: 0.8527\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4039 - accuracy: 0.8311 - val_loss: 0.3554 - val_accuracy: 0.8402\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4354 - accuracy: 0.8257 - val_loss: 0.3600 - val_accuracy: 0.8381\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3793 - accuracy: 0.8287 - val_loss: 0.3490 - val_accuracy: 0.8489\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3751 - accuracy: 0.8326 - val_loss: 0.3522 - val_accuracy: 0.8443\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3796 - accuracy: 0.8275 - val_loss: 0.3518 - val_accuracy: 0.8454\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3649 - accuracy: 0.8369 - val_loss: 0.3488 - val_accuracy: 0.8499\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3702 - accuracy: 0.8356 - val_loss: 0.3420 - val_accuracy: 0.8551\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3734 - accuracy: 0.8365 - val_loss: 0.3401 - val_accuracy: 0.8530\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3814 - accuracy: 0.8310 - val_loss: 0.3460 - val_accuracy: 0.8471\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4444 - accuracy: 0.8312 - val_loss: 0.3461 - val_accuracy: 0.8454\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3767 - accuracy: 0.8340 - val_loss: 0.3442 - val_accuracy: 0.8478\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3713 - accuracy: 0.8349 - val_loss: 0.3480 - val_accuracy: 0.8516\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3759 - accuracy: 0.8304 - val_loss: 0.3433 - val_accuracy: 0.8461\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3694 - accuracy: 0.8387 - val_loss: 0.3523 - val_accuracy: 0.8475\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3673 - accuracy: 0.8350 - val_loss: 0.3522 - val_accuracy: 0.8433\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3721 - accuracy: 0.8343 - val_loss: 0.3472 - val_accuracy: 0.8475\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3671 - accuracy: 0.8381 - val_loss: 0.3387 - val_accuracy: 0.8499\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3665 - accuracy: 0.8361 - val_loss: 0.3580 - val_accuracy: 0.8426\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3738 - accuracy: 0.8304 - val_loss: 0.3485 - val_accuracy: 0.8436\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3740 - accuracy: 0.8348 - val_loss: 0.3378 - val_accuracy: 0.8475\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3705 - accuracy: 0.8287 - val_loss: 0.3413 - val_accuracy: 0.8457\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3627 - accuracy: 0.8339 - val_loss: 0.3445 - val_accuracy: 0.8429\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3748 - accuracy: 0.8363 - val_loss: 0.3509 - val_accuracy: 0.8423\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3684 - accuracy: 0.8365 - val_loss: 0.3482 - val_accuracy: 0.8436\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3631 - accuracy: 0.8385 - val_loss: 0.3365 - val_accuracy: 0.8506\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3607 - accuracy: 0.8383 - val_loss: 0.3466 - val_accuracy: 0.8402\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3650 - accuracy: 0.8333 - val_loss: 0.3384 - val_accuracy: 0.8464\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3723 - accuracy: 0.8360 - val_loss: 0.3436 - val_accuracy: 0.8516\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3635 - accuracy: 0.8382 - val_loss: 0.3488 - val_accuracy: 0.8409\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3634 - accuracy: 0.8387 - val_loss: 0.3505 - val_accuracy: 0.8478\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3697 - accuracy: 0.8397 - val_loss: 0.3444 - val_accuracy: 0.8478\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3684 - accuracy: 0.8357 - val_loss: 0.3453 - val_accuracy: 0.8454\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4128 - accuracy: 0.8382 - val_loss: 0.3539 - val_accuracy: 0.8471\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3733 - accuracy: 0.8308 - val_loss: 0.3516 - val_accuracy: 0.8454\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3711 - accuracy: 0.8314 - val_loss: 0.3461 - val_accuracy: 0.8436\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3711 - accuracy: 0.8329 - val_loss: 0.3460 - val_accuracy: 0.8416\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3711 - accuracy: 0.8385 - val_loss: 0.3436 - val_accuracy: 0.8527\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3640 - accuracy: 0.8352 - val_loss: 0.3471 - val_accuracy: 0.8443\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3694 - accuracy: 0.8379 - val_loss: 0.3503 - val_accuracy: 0.8384\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3657 - accuracy: 0.8357 - val_loss: 0.3473 - val_accuracy: 0.8506\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3624 - accuracy: 0.8453 - val_loss: 0.3380 - val_accuracy: 0.8506\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3624 - accuracy: 0.8383 - val_loss: 0.3456 - val_accuracy: 0.8443\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3620 - accuracy: 0.8426 - val_loss: 0.3445 - val_accuracy: 0.8520\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3694 - accuracy: 0.8390 - val_loss: 0.3436 - val_accuracy: 0.8482\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3668 - accuracy: 0.8402 - val_loss: 0.3373 - val_accuracy: 0.8548\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3687 - accuracy: 0.8372 - val_loss: 0.3410 - val_accuracy: 0.8499\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3648 - accuracy: 0.8380 - val_loss: 0.3485 - val_accuracy: 0.8489\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3587 - accuracy: 0.8436 - val_loss: 0.3408 - val_accuracy: 0.8506\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3623 - accuracy: 0.8380 - val_loss: 0.3344 - val_accuracy: 0.8541\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3630 - accuracy: 0.8397 - val_loss: 0.3526 - val_accuracy: 0.8475\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3703 - accuracy: 0.8381 - val_loss: 0.3522 - val_accuracy: 0.8436\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3698 - accuracy: 0.8355 - val_loss: 0.3441 - val_accuracy: 0.8492\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3720 - accuracy: 0.8321 - val_loss: 0.3480 - val_accuracy: 0.8513\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3702 - accuracy: 0.8380 - val_loss: 0.3407 - val_accuracy: 0.8513\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3742 - accuracy: 0.8385 - val_loss: 0.3513 - val_accuracy: 0.8485\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3653 - accuracy: 0.8333 - val_loss: 0.3422 - val_accuracy: 0.8516\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3623 - accuracy: 0.8394 - val_loss: 0.3503 - val_accuracy: 0.8405\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3666 - accuracy: 0.8360 - val_loss: 0.3348 - val_accuracy: 0.8541\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3746 - accuracy: 0.8370 - val_loss: 0.3393 - val_accuracy: 0.8534\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3678 - accuracy: 0.8396 - val_loss: 0.3416 - val_accuracy: 0.8527\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3631 - accuracy: 0.8417 - val_loss: 0.3490 - val_accuracy: 0.8482\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3610 - accuracy: 0.8421 - val_loss: 0.3478 - val_accuracy: 0.8464\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3623 - accuracy: 0.8426 - val_loss: 0.3472 - val_accuracy: 0.8461\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4125 - accuracy: 0.8363 - val_loss: 0.3618 - val_accuracy: 0.8308\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3710 - accuracy: 0.8376 - val_loss: 0.3547 - val_accuracy: 0.8395\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3704 - accuracy: 0.8383 - val_loss: 0.3620 - val_accuracy: 0.8506\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3898 - accuracy: 0.8393 - val_loss: 0.3461 - val_accuracy: 0.8482\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3627 - accuracy: 0.8398 - val_loss: 0.3500 - val_accuracy: 0.8405\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3621 - accuracy: 0.8394 - val_loss: 0.3325 - val_accuracy: 0.8530\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3529 - accuracy: 0.8459 - val_loss: 0.3393 - val_accuracy: 0.8502\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3616 - accuracy: 0.8448 - val_loss: 0.3442 - val_accuracy: 0.8464\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3688 - accuracy: 0.8417 - val_loss: 0.3428 - val_accuracy: 0.8565\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3648 - accuracy: 0.8416 - val_loss: 0.3405 - val_accuracy: 0.8541\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3629 - accuracy: 0.8398 - val_loss: 0.3453 - val_accuracy: 0.8551\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3709 - accuracy: 0.8391 - val_loss: 0.3503 - val_accuracy: 0.8492\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3651 - accuracy: 0.8360 - val_loss: 0.3443 - val_accuracy: 0.8516\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3599 - accuracy: 0.8398 - val_loss: 0.3413 - val_accuracy: 0.8492\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3642 - accuracy: 0.8417 - val_loss: 0.3355 - val_accuracy: 0.8523\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3808 - accuracy: 0.8352 - val_loss: 0.3493 - val_accuracy: 0.8450\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3658 - accuracy: 0.8363 - val_loss: 0.3524 - val_accuracy: 0.8350\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3608 - accuracy: 0.8389 - val_loss: 0.3439 - val_accuracy: 0.8461\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3620 - accuracy: 0.8412 - val_loss: 0.3527 - val_accuracy: 0.8294\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3601 - accuracy: 0.8411 - val_loss: 0.3500 - val_accuracy: 0.8346\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3552 - accuracy: 0.8400 - val_loss: 0.3375 - val_accuracy: 0.8513\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3611 - accuracy: 0.8415 - val_loss: 0.3499 - val_accuracy: 0.8429\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3566 - accuracy: 0.8426 - val_loss: 0.3434 - val_accuracy: 0.8471\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3513 - accuracy: 0.8466 - val_loss: 0.3383 - val_accuracy: 0.8485\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3607 - accuracy: 0.8389 - val_loss: 0.3498 - val_accuracy: 0.8471\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3607 - accuracy: 0.8429 - val_loss: 0.3533 - val_accuracy: 0.8336\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3594 - accuracy: 0.8413 - val_loss: 0.3429 - val_accuracy: 0.8478\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3530 - accuracy: 0.8448 - val_loss: 0.3396 - val_accuracy: 0.8489\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3587 - accuracy: 0.8362 - val_loss: 0.3457 - val_accuracy: 0.8478\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3698 - accuracy: 0.8415 - val_loss: 0.3351 - val_accuracy: 0.8506\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3659 - accuracy: 0.8344 - val_loss: 0.3443 - val_accuracy: 0.8551\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3642 - accuracy: 0.8401 - val_loss: 0.3466 - val_accuracy: 0.8478\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3682 - accuracy: 0.8442 - val_loss: 0.3461 - val_accuracy: 0.8461\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3653 - accuracy: 0.8402 - val_loss: 0.3410 - val_accuracy: 0.8495\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3604 - accuracy: 0.8426 - val_loss: 0.3393 - val_accuracy: 0.8520\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3727 - accuracy: 0.8373 - val_loss: 0.3501 - val_accuracy: 0.8485\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3798 - accuracy: 0.8372 - val_loss: 0.3451 - val_accuracy: 0.8534\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3872 - accuracy: 0.8327 - val_loss: 0.3409 - val_accuracy: 0.8541\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3731 - accuracy: 0.8352 - val_loss: 0.3395 - val_accuracy: 0.8537\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3669 - accuracy: 0.8379 - val_loss: 0.3456 - val_accuracy: 0.8499\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.3800 - accuracy: 0.8351 - val_loss: 0.3676 - val_accuracy: 0.8450\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.4218 - accuracy: 0.8300 - val_loss: 0.3738 - val_accuracy: 0.8412\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.3989 - accuracy: 0.8284 - val_loss: 0.3514 - val_accuracy: 0.8502\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3782 - accuracy: 0.8381 - val_loss: 0.3429 - val_accuracy: 0.8495\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3762 - accuracy: 0.8389 - val_loss: 0.3398 - val_accuracy: 0.8575\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3629 - accuracy: 0.8420 - val_loss: 0.3373 - val_accuracy: 0.8537\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3691 - accuracy: 0.8402 - val_loss: 0.3364 - val_accuracy: 0.8568\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3682 - accuracy: 0.8402 - val_loss: 0.3428 - val_accuracy: 0.8548\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3714 - accuracy: 0.8346 - val_loss: 0.3414 - val_accuracy: 0.8523\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3752 - accuracy: 0.8374 - val_loss: 0.3445 - val_accuracy: 0.8516\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3716 - accuracy: 0.8374 - val_loss: 0.3448 - val_accuracy: 0.8513\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3708 - accuracy: 0.8367 - val_loss: 0.3505 - val_accuracy: 0.8468\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3659 - accuracy: 0.8437 - val_loss: 0.3409 - val_accuracy: 0.8502\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3711 - accuracy: 0.8445 - val_loss: 0.3529 - val_accuracy: 0.8461\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3647 - accuracy: 0.8408 - val_loss: 0.3416 - val_accuracy: 0.8502\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3610 - accuracy: 0.8398 - val_loss: 0.3356 - val_accuracy: 0.8509\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4208 - accuracy: 0.8411 - val_loss: 0.3442 - val_accuracy: 0.8489\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3726 - accuracy: 0.8380 - val_loss: 0.3586 - val_accuracy: 0.8426\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3876 - accuracy: 0.8368 - val_loss: 0.3656 - val_accuracy: 0.8409\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3816 - accuracy: 0.8354 - val_loss: 0.3504 - val_accuracy: 0.8416\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4061 - accuracy: 0.8374 - val_loss: 0.3547 - val_accuracy: 0.8402\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3725 - accuracy: 0.8327 - val_loss: 0.3563 - val_accuracy: 0.8363\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3686 - accuracy: 0.8423 - val_loss: 0.3499 - val_accuracy: 0.8436\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3697 - accuracy: 0.8355 - val_loss: 0.3509 - val_accuracy: 0.8464\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3699 - accuracy: 0.8373 - val_loss: 0.3385 - val_accuracy: 0.8520\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3582 - accuracy: 0.8380 - val_loss: 0.3454 - val_accuracy: 0.8478\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3640 - accuracy: 0.8399 - val_loss: 0.3491 - val_accuracy: 0.8447\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3892 - accuracy: 0.8336 - val_loss: 0.3471 - val_accuracy: 0.8454\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3619 - accuracy: 0.8405 - val_loss: 0.3426 - val_accuracy: 0.8482\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3651 - accuracy: 0.8368 - val_loss: 0.3376 - val_accuracy: 0.8509\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3644 - accuracy: 0.8377 - val_loss: 0.3517 - val_accuracy: 0.8461\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3556 - accuracy: 0.8419 - val_loss: 0.3428 - val_accuracy: 0.8489\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3572 - accuracy: 0.8456 - val_loss: 0.3419 - val_accuracy: 0.8468\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3600 - accuracy: 0.8415 - val_loss: 0.3341 - val_accuracy: 0.8551\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3547 - accuracy: 0.8399 - val_loss: 0.3377 - val_accuracy: 0.8516\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3624 - accuracy: 0.8415 - val_loss: 0.3453 - val_accuracy: 0.8516\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3531 - accuracy: 0.8423 - val_loss: 0.3345 - val_accuracy: 0.8551\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3634 - accuracy: 0.8423 - val_loss: 0.3341 - val_accuracy: 0.8541\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3628 - accuracy: 0.8395 - val_loss: 0.3469 - val_accuracy: 0.8548\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3600 - accuracy: 0.8430 - val_loss: 0.3417 - val_accuracy: 0.8558\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3597 - accuracy: 0.8434 - val_loss: 0.3392 - val_accuracy: 0.8534\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3869 - accuracy: 0.8327 - val_loss: 0.3543 - val_accuracy: 0.8468\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.3656 - accuracy: 0.8383 - val_loss: 0.3410 - val_accuracy: 0.8506\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3572 - accuracy: 0.8406 - val_loss: 0.3395 - val_accuracy: 0.8555\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3535 - accuracy: 0.8439 - val_loss: 0.3481 - val_accuracy: 0.8499\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3577 - accuracy: 0.8418 - val_loss: 0.3411 - val_accuracy: 0.8502\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3572 - accuracy: 0.8453 - val_loss: 0.3448 - val_accuracy: 0.8492\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3536 - accuracy: 0.8451 - val_loss: 0.3494 - val_accuracy: 0.8489\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.3448 - val_accuracy: 0.8482\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3481 - accuracy: 0.8457 - val_loss: 0.3380 - val_accuracy: 0.8537\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3605 - accuracy: 0.8422 - val_loss: 0.3437 - val_accuracy: 0.8558\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3601 - accuracy: 0.8454 - val_loss: 0.3442 - val_accuracy: 0.8575\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3561 - accuracy: 0.8458 - val_loss: 0.3415 - val_accuracy: 0.8548\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3593 - accuracy: 0.8425 - val_loss: 0.3442 - val_accuracy: 0.8537\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4138 - accuracy: 0.8464 - val_loss: 0.3423 - val_accuracy: 0.8516\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3838 - accuracy: 0.8300 - val_loss: 0.3444 - val_accuracy: 0.8454\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 4s 46ms/step - loss: 0.3715 - accuracy: 0.8351 - val_loss: 0.3451 - val_accuracy: 0.8489\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3605 - accuracy: 0.8375 - val_loss: 0.3402 - val_accuracy: 0.8492\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3523 - accuracy: 0.8439 - val_loss: 0.3380 - val_accuracy: 0.8506\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.3748 - accuracy: 0.8406 - val_loss: 0.3546 - val_accuracy: 0.8461\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.3683 - accuracy: 0.8335 - val_loss: 0.3486 - val_accuracy: 0.8495\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3713 - accuracy: 0.8400 - val_loss: 0.3520 - val_accuracy: 0.8464\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4739 - accuracy: 0.8337 - val_loss: 0.3417 - val_accuracy: 0.8471\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3664 - accuracy: 0.8406 - val_loss: 0.3504 - val_accuracy: 0.8433\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3645 - accuracy: 0.8418 - val_loss: 0.3468 - val_accuracy: 0.8436\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3646 - accuracy: 0.8393 - val_loss: 0.3487 - val_accuracy: 0.8436\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3591 - accuracy: 0.8448 - val_loss: 0.3520 - val_accuracy: 0.8436\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3585 - accuracy: 0.8447 - val_loss: 0.3332 - val_accuracy: 0.8551\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3620 - accuracy: 0.8393 - val_loss: 0.3387 - val_accuracy: 0.8499\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3582 - accuracy: 0.8433 - val_loss: 0.3419 - val_accuracy: 0.8475\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3589 - accuracy: 0.8413 - val_loss: 0.3418 - val_accuracy: 0.8523\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3569 - accuracy: 0.8449 - val_loss: 0.3448 - val_accuracy: 0.8509\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.3487 - accuracy: 0.8468 - val_loss: 0.3326 - val_accuracy: 0.8534\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3586 - accuracy: 0.8445 - val_loss: 0.3428 - val_accuracy: 0.8530\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3504 - accuracy: 0.8453 - val_loss: 0.3383 - val_accuracy: 0.8489\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.3584 - accuracy: 0.8424 - val_loss: 0.3304 - val_accuracy: 0.8628\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3562 - accuracy: 0.8417 - val_loss: 0.3294 - val_accuracy: 0.8589\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3585 - accuracy: 0.8411 - val_loss: 0.3371 - val_accuracy: 0.8537\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3580 - accuracy: 0.8426 - val_loss: 0.3370 - val_accuracy: 0.8513\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3530 - accuracy: 0.8443 - val_loss: 0.3453 - val_accuracy: 0.8471\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3547 - accuracy: 0.8414 - val_loss: 0.3492 - val_accuracy: 0.8423\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3481 - accuracy: 0.8489 - val_loss: 0.3335 - val_accuracy: 0.8575\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3517 - accuracy: 0.8419 - val_loss: 0.3354 - val_accuracy: 0.8513\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3513 - accuracy: 0.8488 - val_loss: 0.3364 - val_accuracy: 0.8516\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3612 - accuracy: 0.8448 - val_loss: 0.3422 - val_accuracy: 0.8464\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3544 - accuracy: 0.8458 - val_loss: 0.3395 - val_accuracy: 0.8544\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3580 - accuracy: 0.8444 - val_loss: 0.3415 - val_accuracy: 0.8509\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3563 - accuracy: 0.8428 - val_loss: 0.3325 - val_accuracy: 0.8534\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3586 - accuracy: 0.8445 - val_loss: 0.3434 - val_accuracy: 0.8485\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3649 - accuracy: 0.8429 - val_loss: 0.3496 - val_accuracy: 0.8482\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3698 - accuracy: 0.8356 - val_loss: 0.3439 - val_accuracy: 0.8475\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3627 - accuracy: 0.8383 - val_loss: 0.3500 - val_accuracy: 0.8468\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3619 - accuracy: 0.8411 - val_loss: 0.3382 - val_accuracy: 0.8513\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3619 - accuracy: 0.8426 - val_loss: 0.3433 - val_accuracy: 0.8499\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3818 - accuracy: 0.8406 - val_loss: 0.3524 - val_accuracy: 0.8506\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3543 - accuracy: 0.8442 - val_loss: 0.3508 - val_accuracy: 0.8419\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3612 - accuracy: 0.8440 - val_loss: 0.3448 - val_accuracy: 0.8502\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3608 - accuracy: 0.8388 - val_loss: 0.3430 - val_accuracy: 0.8457\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3556 - accuracy: 0.8422 - val_loss: 0.3406 - val_accuracy: 0.8489\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3575 - accuracy: 0.8409 - val_loss: 0.3616 - val_accuracy: 0.8350\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3670 - accuracy: 0.8407 - val_loss: 0.3556 - val_accuracy: 0.8419\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3578 - accuracy: 0.8454 - val_loss: 0.3499 - val_accuracy: 0.8429\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3815 - accuracy: 0.8326 - val_loss: 0.3475 - val_accuracy: 0.8454\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3713 - accuracy: 0.8351 - val_loss: 0.3506 - val_accuracy: 0.8457\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3762 - accuracy: 0.8404 - val_loss: 0.3474 - val_accuracy: 0.8468\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3591 - accuracy: 0.8380 - val_loss: 0.3485 - val_accuracy: 0.8471\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.3557 - accuracy: 0.8460 - val_loss: 0.3393 - val_accuracy: 0.8461\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3620 - accuracy: 0.8397 - val_loss: 0.3355 - val_accuracy: 0.8499\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3564 - accuracy: 0.8458 - val_loss: 0.3396 - val_accuracy: 0.8482\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3552 - accuracy: 0.8467 - val_loss: 0.3446 - val_accuracy: 0.8530\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.3549 - accuracy: 0.8448 - val_loss: 0.3479 - val_accuracy: 0.8440\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3701 - accuracy: 0.8401 - val_loss: 0.3438 - val_accuracy: 0.8520\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3664 - accuracy: 0.8423 - val_loss: 0.3349 - val_accuracy: 0.8502\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3780 - accuracy: 0.8431 - val_loss: 0.3562 - val_accuracy: 0.8433\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.3800 - accuracy: 0.8332 - val_loss: 0.3586 - val_accuracy: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=4096*2, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_scaled, y_val_categorical)\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to apply a keras hyperperameters to find the perfect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-512cb11a31fd>\", line 47, in <module>\n",
      "    directory = LOG_DIR\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\kerastuner\\tuners\\randomsearch.py\", line 171, in __init__\n",
      "    allow_new_entries=allow_new_entries)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\kerastuner\\tuners\\randomsearch.py\", line 66, in __init__\n",
      "    allow_new_entries=allow_new_entries)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\oracle.py\", line 64, in __init__\n",
      "    self.objective = _format_objective(objective)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\oracle.py\", line 384, in _format_objective\n",
      "    raise ValueError(error_msg)\n",
      "ValueError: Could not infer optimization direction (\"min\" or \"max\") for unknown metric \"val_accuaracy\". Please specify the objective  asa `kerastuner.Objective`, for example `kerastuner.Objective(\"val_accuaracy\", direction=\"min\")`.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Ayman\\anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-512cb11a31fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mexecutions_per_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLOG_DIR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\tuners\\randomsearch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mtune_new_entries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtune_new_entries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             allow_new_entries=allow_new_entries)\n\u001b[0m\u001b[0;32m    172\u001b[0m         super(RandomSearch, self).__init__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\tuners\\randomsearch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objective, max_trials, seed, hyperparameters, allow_new_entries, tune_new_entries)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mtune_new_entries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtune_new_entries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             allow_new_entries=allow_new_entries)\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\oracle.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objective, max_trials, hyperparameters, allow_new_entries, tune_new_entries)\u001b[0m\n\u001b[0;32m     63\u001b[0m                  tune_new_entries=True):\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_format_objective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\oracle.py\u001b[0m in \u001b[0;36m_format_objective\u001b[1;34m(objective)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mObjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not infer optimization direction (\"min\" or \"max\") for unknown metric \"val_accuaracy\". Please specify the objective  asa `kerastuner.Objective`, for example `kerastuner.Objective(\"val_accuaracy\", direction=\"min\")`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ValueError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2047\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1436\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             )\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1193\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameter\n",
    "import time\n",
    "\n",
    "LOG_DIR = f'logs/{int(time.time())}'\n",
    "\n",
    "def build_model(hp):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=128, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=256, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=512, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=1048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2048, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=4096, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=4096*2, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "        \n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = 'val_accuaracy',\n",
    "    max_trials = 1,\n",
    "    executions_per_trials = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.serach(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    epochs = 10,\n",
    "    batch_size = 128,\n",
    "    validation_data=(X_val,y_val)\n",
    ")\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train_scaled,\n",
    "#     y_train_categorical,\n",
    "#     batch_size=128,\n",
    "#     epochs=500,\n",
    "#     shuffle=True,\n",
    "#     verbose=1,\n",
    "#     validation_data=(X_val_scaled, y_val_categorical)\n",
    "# )\n",
    "\n",
    "# history_df = pd.DataFrame(history.history)\n",
    "# history_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
